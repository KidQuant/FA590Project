{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "pd.set_option('display.max_rows', None)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('factors_2002.csv', parse_dates=['DATE'])\n",
    "# df = pd.read_csv('data/features_subset.csv', parse_dates=['DATE'])\n",
    "df = pd.read_csv('factors_1900.csv', parse_dates=['DATE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_dp</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>Date</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>10347.750000</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.348191</td>\n",
       "      <td>8.308599</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>0.179456</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385516</td>\n",
       "      <td>2.68412</td>\n",
       "      <td>0.414971</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>-0.1072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>199004.0</td>\n",
       "      <td>-7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>7196.875000</td>\n",
       "      <td>0.481378</td>\n",
       "      <td>0.231724</td>\n",
       "      <td>-0.268657</td>\n",
       "      <td>6.680698</td>\n",
       "      <td>0.018793</td>\n",
       "      <td>0.127571</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385516</td>\n",
       "      <td>2.68412</td>\n",
       "      <td>0.414971</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>-0.1072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>199004.0</td>\n",
       "      <td>-7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>18649.000000</td>\n",
       "      <td>0.765364</td>\n",
       "      <td>0.585782</td>\n",
       "      <td>-0.281724</td>\n",
       "      <td>9.927838</td>\n",
       "      <td>0.040525</td>\n",
       "      <td>0.127571</td>\n",
       "      <td>-0.260870</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385516</td>\n",
       "      <td>2.68412</td>\n",
       "      <td>0.414971</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>-0.1072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>199004.0</td>\n",
       "      <td>-7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>2043.505859</td>\n",
       "      <td>0.980050</td>\n",
       "      <td>0.960498</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>5.100628</td>\n",
       "      <td>0.148197</td>\n",
       "      <td>0.336596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385516</td>\n",
       "      <td>2.68412</td>\n",
       "      <td>0.414971</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>-0.1072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>199004.0</td>\n",
       "      <td>-7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>28196.250000</td>\n",
       "      <td>1.672263</td>\n",
       "      <td>2.796464</td>\n",
       "      <td>1.210168</td>\n",
       "      <td>11.458924</td>\n",
       "      <td>0.188345</td>\n",
       "      <td>0.174430</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385516</td>\n",
       "      <td>2.68412</td>\n",
       "      <td>0.414971</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>-0.1072</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>199004.0</td>\n",
       "      <td>-7.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE         mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10001 1990-01-31  10347.750000  0.021663  0.000469  0.348191   8.308599   \n",
       "1   10002 1990-01-31   7196.875000  0.481378  0.231724 -0.268657   6.680698   \n",
       "2   10003 1990-01-31  18649.000000  0.765364  0.585782 -0.281724   9.927838   \n",
       "3   10005 1990-01-31   2043.505859  0.980050  0.960498 -0.033333   5.100628   \n",
       "4   10007 1990-01-31  28196.250000  1.672263  2.796464  1.210168  11.458924   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_dp  macro_ep  macro_bm  \\\n",
       "0  0.037859  0.179456  0.037975  ...  3.385516   2.68412  0.414971   \n",
       "1  0.018793  0.127571 -0.039216  ...  3.385516   2.68412  0.414971   \n",
       "2  0.040525  0.127571 -0.260870  ...  3.385516   2.68412  0.414971   \n",
       "3  0.148197  0.336596  0.000000  ...  3.385516   2.68412  0.414971   \n",
       "4  0.188345  0.174430  0.450331  ...  3.385516   2.68412  0.414971   \n",
       "\n",
       "   macro_ntis  macro_tbl  macro_tms  macro_dfy  macro_svar      Date  \\\n",
       "0   -0.013897     0.0764    -0.1072     0.0095    0.002892  199004.0   \n",
       "1   -0.013897     0.0764    -0.1072     0.0095    0.002892  199004.0   \n",
       "2   -0.013897     0.0764    -0.1072     0.0095    0.002892  199004.0   \n",
       "3   -0.013897     0.0764    -0.1072     0.0095    0.002892  199004.0   \n",
       "4   -0.013897     0.0764    -0.1072     0.0095    0.002892  199004.0   \n",
       "\n",
       "   macro_mkt-rf  \n",
       "0         -7.85  \n",
       "1         -7.85  \n",
       "2         -7.85  \n",
       "3         -7.85  \n",
       "4         -7.85  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df= df[~np.isnan(df['bm'])]\n",
    "df =df[~np.isnan(df['mvel1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "df['mvel12'] = df['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_39752\\2840026024.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n",
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_39752\\2840026024.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize all independent variables\n",
    "\n",
    "stdSc = StandardScaler()\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', 'mvel1', 'mvel12', 'permno', 'permno2', 'risk_premium'])].tolist()\n",
    "df[features] = stdSc.fit_transform(df[features].astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 424371 ,# val records 202339 , # test records 117085\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 441982 ,# val records 221030 , # test records 106363\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 466137 ,# val records 223448 , # test records 92348\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 494688 ,# val records 198711 , # test records 98810\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 521423 ,# val records 191158 , # test records 92269\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 518135 ,# val records 191079 , # test records 85997\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 518551 ,# val records 178266 , # test records 87780\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 506875 ,# val records 173777 , # test records 73273\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 475787 ,# val records 161053 , # test records 80320\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 457204 ,# val records 153593 , # test records 80634\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 438129 ,# val records 160954 , # test records 81731\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 419639 ,# val records 162365 , # test records 84440\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 408004 ,# val records 166171 , # test records 69948\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 403738 ,# val records 154388 , # test records 62639\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 400398 ,# val records 132587 , # test records 67560\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 397073 ,# val records 130199 , # test records 66484\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 379392 ,# val records 134044 , # test records 65823\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 366318 ,# val records 132307 , # test records 73469\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 351071 ,# val records 139292 , # test records 69164\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 332454 ,# val records 142633 , # test records 62651\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 335975 ,# val records 131815 , # test records 68180\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 342500 ,# val records 130831 , # test records 68797\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 337591 ,# val records 136977 , # test records 68962\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 339287 ,# val records 137759 , # test records 75775\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "X = df[['DATE', 'macro_mkt-rf', 'macro_tbl', 'mvel1', 'bm']]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1995,1,31), second_split_date= datetime.date(1997,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "    y_pred_val = lm.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "# predictions_all= np.concatenate(predictions, axis=0)\n",
    "# y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "# dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "# R2OOS_LR = 1-sum(pow(y_test_list_all-predictions_all,2))/sum(pow(y_test_list_all,2))\n",
    "# print(\"R2OOS Huber Regression: \", R2OOS_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02851388869981164,\n",
       " 0.03897198427655235,\n",
       " 0.07668141337841594,\n",
       " 0.06639710866742043,\n",
       " 0.043995405466819903,\n",
       " 0.08372081716793045,\n",
       " 0.09571086166087939,\n",
       " 0.10824770316262411,\n",
       " 0.06444195540920461,\n",
       " 0.05848049114320364,\n",
       " 0.05589692618388287,\n",
       " 0.009295466972519262,\n",
       " 0.09027796978096048,\n",
       " 0.1921132437836005,\n",
       " 0.16157648015808534,\n",
       " 0.1819455383769929,\n",
       " 0.1362504982670245,\n",
       " 0.07092569824664108,\n",
       " 0.049540233797152444,\n",
       " 0.06183973424653155,\n",
       " 0.07551049943868704,\n",
       " 0.03114938391260813,\n",
       " 0.03407622585163328,\n",
       " 0.11838974997038243]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 127287 ,# val records 60692 , # test records 35119\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 132570 ,# val records 66297 , # test records 31901\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 139816 ,# val records 67020 , # test records 27698\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 148379 ,# val records 59599 , # test records 29639\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 156397 ,# val records 57337 , # test records 27676\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 155410 ,# val records 57315 , # test records 25794\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 155535 ,# val records 53470 , # test records 26331\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 152033 ,# val records 52125 , # test records 21976\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 142708 ,# val records 48307 , # test records 24090\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 137138 ,# val records 46066 , # test records 24186\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 131416 ,# val records 48276 , # test records 24514\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 125867 ,# val records 48700 , # test records 25327\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 122377 ,# val records 49841 , # test records 20979\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 121097 ,# val records 46306 , # test records 18787\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 120093 ,# val records 39766 , # test records 20261\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 119096 ,# val records 39048 , # test records 19940\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 113793 ,# val records 40201 , # test records 19740\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 109868 ,# val records 39680 , # test records 22034\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 105294 ,# val records 41774 , # test records 20742\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 99707 ,# val records 42776 , # test records 18791\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 100762 ,# val records 39533 , # test records 20448\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 102717 ,# val records 39239 , # test records 20633\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 101247 ,# val records 41081 , # test records 20683\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 101755 ,# val records 41316 , # test records 22726\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "X = df_large[['DATE', 'macro_mkt-rf', 'macro_tbl', 'mvel1', 'bm']]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1995,1,31), second_split_date= datetime.date(1997,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "    y_pred_val = lm.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "# predictions_all= np.concatenate(predictions, axis=0)\n",
    "# y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "# dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "# R2OOS_LR = 1-sum(pow(y_test_list_all-predictions_all,2))/sum(pow(y_test_list_all,2))\n",
    "# print(\"R2OOS Huber Regression: \", R2OOS_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 127287 ,# val records 60692 , # test records 35119\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 132570 ,# val records 66297 , # test records 31901\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 139816 ,# val records 67020 , # test records 27698\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 148379 ,# val records 59599 , # test records 29639\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 156397 ,# val records 57337 , # test records 27676\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 155410 ,# val records 57315 , # test records 25794\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 155535 ,# val records 53470 , # test records 26331\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 152033 ,# val records 52125 , # test records 21976\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 142708 ,# val records 48307 , # test records 24090\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 137138 ,# val records 46066 , # test records 24186\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 131416 ,# val records 48276 , # test records 24514\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 125867 ,# val records 48700 , # test records 25327\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 122377 ,# val records 49841 , # test records 20979\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 121097 ,# val records 46306 , # test records 18787\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 120093 ,# val records 39766 , # test records 20261\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 119096 ,# val records 39048 , # test records 19940\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 113793 ,# val records 40201 , # test records 19740\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 109868 ,# val records 39680 , # test records 22034\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 105294 ,# val records 41774 , # test records 20742\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 99707 ,# val records 42776 , # test records 18791\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 100762 ,# val records 39533 , # test records 20448\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 102717 ,# val records 39239 , # test records 20633\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 101247 ,# val records 41081 , # test records 20683\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 101755 ,# val records 41316 , # test records 22726\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "X = df_small[['DATE', 'macro_mkt-rf', 'macro_tbl', 'mvel1', 'bm']]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1995,1,31), second_split_date= datetime.date(1997,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "    y_pred_val = lm.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "# predictions_all= np.concatenate(predictions, axis=0)\n",
    "# y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "# dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "# R2OOS_LR = 1-sum(pow(y_test_list_all-predictions_all,2))/sum(pow(y_test_list_all,2))\n",
    "# print(\"R2OOS Huber Regression: \", R2OOS_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005734610789250083,\n",
       " 0.015300596373754916,\n",
       " 0.032773325597783454,\n",
       " 0.030929975427823275,\n",
       " 0.02584453168765999,\n",
       " 0.061932216127773665,\n",
       " 0.04467546584204518,\n",
       " 0.07335300997397365,\n",
       " 0.032431027445364746,\n",
       " 0.02680421077790729,\n",
       " 0.02742491357052912,\n",
       " -0.02147780690255341,\n",
       " 0.019380193296187453,\n",
       " 0.11672741918184737,\n",
       " 0.08343769392665568,\n",
       " 0.08525002622243538,\n",
       " 0.06681913434125386,\n",
       " 0.04318338214076556,\n",
       " 0.013910283311432625,\n",
       " 0.00871773837534795,\n",
       " 0.02089629957259853,\n",
       " 0.007490697533350521,\n",
       " 0.05388564930531747,\n",
       " 0.07048617187392159]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
