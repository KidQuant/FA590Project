{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import pickle\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "pd.set_option('display.max_rows', None)\n",
    "# more\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/factors_1965.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "df['mvel12'] = df['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize all independent variables\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "\n",
    "df[features] = 2*df[features] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "X = df[['DATE', 'macro_mkt-rf', 'macro_tbl', 'mvel1', 'bm']]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    lm = LinearRegression()\n",
    "   \n",
    "    lm.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    #Use test set to generate final predictions \n",
    "    preds = lm.predict(X_test)\n",
    "\n",
    "    #Save predictions, dates and the true values of the dependent variable to list  \n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test-preds,2))/np.sum(pow(y_test,2))\n",
    "\n",
    "    #Save OOS model performance and the respective month to dictionary\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "#Calculate OOS model performance over the entire test period in line with Gu et al (2020)\n",
    "R2OOS_LR = 1-np.sum(pow(y_test_list_all-predictions_all,2))/np.sum(pow(y_test_list_all,2))\n",
    "print(\"R2OOS Linear Regression Full: \", R2OOS_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "X = df_large[['DATE', 'macro_mkt-rf', 'macro_tbl', 'mvel1', 'bm']]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions_top = []\n",
    "y_test_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_all_top = {}\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = lm.predict(X_test) \n",
    "    predictions_top.append(preds)\n",
    "    dates_top.append(y_test.index)\n",
    "    y_test_list_top.append(y_test)\n",
    "    \n",
    "    r2_top = 1-np.sum(pow(y_test-preds,2))/np.sum(pow(y_test,2))\n",
    "    dic_r2_all_top[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_top= np.concatenate(predictions_top, axis=0)\n",
    "y_test_list_all_top= np.concatenate(y_test_list_top, axis=0) \n",
    "dates_all_top= np.concatenate(dates_top, axis=0)\n",
    "\n",
    "R2OOS_LR_top = 1-np.sum(pow(y_test_list_all_top-predictions_all_top,2))/np.sum(pow(y_test_list_all_top,2))\n",
    "print(\"R2OOS Linear Regression Top: \", R2OOS_LR_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "X = df_small[['DATE', 'macro_mkt-rf', 'macro_tbl', 'mvel1', 'bm']]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions_bottom = []\n",
    "y_test_list_bottom =[]\n",
    "dates_bottom = []\n",
    "dic_r2_all_bottom = {}\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = lm.predict(X_test) \n",
    "    predictions_bottom.append(preds)\n",
    "    dates_bottom.append(y_test.index)\n",
    "    y_test_list_bottom.append(y_test)\n",
    "    \n",
    "    r2_bottom = 1-np.sum(pow(y_test-preds,2))/np.sum(pow(y_test,2))\n",
    "    dic_r2_all_bottom[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_bottom= np.concatenate(predictions_bottom, axis=0)\n",
    "y_test_list_all_bottom= np.concatenate(y_test_list_bottom, axis=0) \n",
    "dates_all_bottom= np.concatenate(dates_bottom, axis=0)\n",
    "\n",
    "R2OOS_LR_bottom = 1-np.sum(pow(y_test_list_all_bottom-predictions_all_bottom,2))/np.sum(pow(y_test_list_all_bottom,2))\n",
    "print(\"R2OOS Linear Regression Bottom: \", R2OOS_LR_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chart = np.array([[R2OOS_LR],\n",
    "                  [R2OOS_LR_top],\n",
    "                  [R2OOS_LR_bottom]])\n",
    "\n",
    "r2_lm = pd.DataFrame(chart, columns=['Linear Regression (Fama-French)'],\n",
    "                     index=['Full Sample', 'Large Firms', 'Small Firms'])\n",
    "\n",
    "r2_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lm.to_csv(r'r2_linear_model_FF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predictions_all.tolist()\n",
    "y_true = y_test_list_all.tolist()\n",
    "i = dates_all.tolist()\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'identifier': i,\n",
    "     'yhat': yhat,\n",
    "     'y_true': y_true\n",
    "    })\n",
    "\n",
    "results[\"identifier\"]= results[\"identifier\"].astype(\"str\")\n",
    "results[\"date\"] = results[\"identifier\"].str[12:22]\n",
    "results[\"id\"] = results[\"identifier\"].str[36:51]\n",
    "results.drop([\"identifier\"],axis = 1, inplace=True)\n",
    "results['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n",
    "results['MonthYear'] = results['date'].dt.to_period('M')\n",
    "results = results.sort_values(by = ['date', 'id'], ascending = True)\n",
    "results = results.set_index(['MonthYear','id'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = results.reset_index()\n",
    "lm.to_csv('predictions/lm_ff.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
