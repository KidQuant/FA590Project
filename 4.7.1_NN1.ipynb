{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/factors_1965.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546907   \n",
      "1   10401 1965-02-26  35392058.00  0.780829  0.609694 -0.063768  12.240330   \n",
      "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
      "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
      "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240330   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
      "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
      "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
      "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
      "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "\n",
      "   macro_smb  \n",
      "0       3.55  \n",
      "1       3.55  \n",
      "2       3.55  \n",
      "3       3.55  \n",
      "4       3.55  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "      <th>macro_hml</th>\n",
       "      <th>macro_smb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10145</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1498872.00</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>11.546906</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10401</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>35392056.00</td>\n",
       "      <td>0.780829</td>\n",
       "      <td>0.609694</td>\n",
       "      <td>-0.063768</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10786</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1695284.75</td>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.649827</td>\n",
       "      <td>-0.130519</td>\n",
       "      <td>12.005040</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10989</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1295887.75</td>\n",
       "      <td>1.199748</td>\n",
       "      <td>1.439395</td>\n",
       "      <td>0.073609</td>\n",
       "      <td>11.756961</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11260</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>2302001.25</td>\n",
       "      <td>1.257269</td>\n",
       "      <td>1.580725</td>\n",
       "      <td>-0.167320</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.185424</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546906   \n",
       "1   10401 1965-02-26  35392056.00  0.780829  0.609694 -0.063768  12.240331   \n",
       "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
       "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
       "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240331   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
       "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
       "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
       "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
       "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
       "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
       "\n",
       "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
       "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "\n",
       "   macro_smb  \n",
       "0       3.55  \n",
       "1       3.55  \n",
       "2       3.55  \n",
       "3       3.55  \n",
       "4       3.55  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "df['mvel12'] = df['mvel1'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "df[features] = 2*df[features] - 1\n",
    "\n",
    "df_large[features]=df_large.groupby('DATE')[features].rank(pct=True)\n",
    "df_large[features] = 2*df_large[features] - 1\n",
    "\n",
    "df_small[features]=df_small.groupby('DATE')[features].rank(pct=True)\n",
    "df_small[features] = 2*df_small[features] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 13670 ,# val records 3499 , # test records 1941\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 14434 ,# val records 3708 , # test records 2030\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 15118 ,# val records 3971 , # test records 2358\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 15843 ,# val records 4388 , # test records 3334\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 16573 ,# val records 5692 , # test records 3578\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 17432 ,# val records 6912 , # test records 2893\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 19634 ,# val records 6471 , # test records 4416\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 21888 ,# val records 7309 , # test records 4368\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 23087 ,# val records 8784 , # test records 4870\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 25581 ,# val records 9238 , # test records 6416\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 28417 ,# val records 11286 , # test records 6641\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 31555 ,# val records 13057 , # test records 5931\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 36204 ,# val records 12572 , # test records 6850\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 40904 ,# val records 12781 , # test records 6553\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 44805 ,# val records 13403 , # test records 7063\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 49297 ,# val records 13616 , # test records 8743\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 52516 ,# val records 15806 , # test records 8628\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 56001 ,# val records 17371 , # test records 10193\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 61851 ,# val records 18821 , # test records 11176\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 66063 ,# val records 21369 , # test records 12945\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 71888 ,# val records 24121 , # test records 16010\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 78194 ,# val records 28955 , # test records 15949\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 84723 ,# val records 31959 , # test records 14847\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 94092 ,# val records 30796 , # test records 18389\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 104110 ,# val records 33236 , # test records 16233\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 112107 ,# val records 34622 , # test records 15449\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 123943 ,# val records 31682 , # test records 17642\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 133113 ,# val records 33091 , # test records 17980\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 139819 ,# val records 35622 , # test records 21590\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 148833 ,# val records 39570 , # test records 23521\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 156620 ,# val records 45111 , # test records 24470\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 167034 ,# val records 47991 , # test records 21949\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 177610 ,# val records 46419 , # test records 16767\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 186070 ,# val records 38716 , # test records 18170\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 192070 ,# val records 34937 , # test records 21578\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 193990 ,# val records 39748 , # test records 21516\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 193771 ,# val records 43094 , # test records 23877\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 199116 ,# val records 45393 , # test records 28640\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 205183 ,# val records 52517 , # test records 26461\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 211418 ,# val records 55101 , # test records 23187\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 222078 ,# val records 49648 , # test records 27102\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 226949 ,# val records 50289 , # test records 28421\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 226615 ,# val records 55523 , # test records 27271\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 229247 ,# val records 55692 , # test records 29168\n",
      "-------\n",
      "R2 1965-02-26 - 1974-12-31 training set 0.3892149192114981\n",
      "R2 1977-01-31 - 1977-12-30 validation set 0.5299087399651635\n",
      "-------\n",
      "R2 1966-01-31 - 1976-01-30 training set 0.3386990356696662\n",
      "R2 1978-01-31 - 1978-12-29 validation set 0.464268925194225\n",
      "-------\n",
      "R2 1967-01-31 - 1976-12-31 training set 0.34335093399079497\n",
      "R2 1979-01-31 - 1979-12-31 validation set 0.5172368003421477\n",
      "-------\n",
      "R2 1968-01-31 - 1977-12-30 training set 0.36871730483957554\n",
      "R2 1980-01-31 - 1981-01-30 validation set 0.41512176702339054\n",
      "-------\n",
      "R2 1969-01-31 - 1978-12-29 training set 0.38748844876094046\n",
      "R2 1981-02-27 - 1982-01-29 validation set 0.5205022690479797\n",
      "-------\n",
      "R2 1970-02-27 - 1979-12-31 training set 0.3980159954927127\n",
      "R2 1982-02-26 - 1982-12-31 validation set 0.4120711786186225\n",
      "-------\n",
      "R2 1971-02-26 - 1981-01-30 training set 0.4296641284095777\n",
      "R2 1983-01-31 - 1983-12-30 validation set 0.44667182026013874\n",
      "-------\n",
      "R2 1972-01-31 - 1982-01-29 training set 0.49154387784580234\n",
      "R2 1984-01-31 - 1984-12-31 validation set 0.5616258559821818\n",
      "-------\n",
      "R2 1973-01-31 - 1982-12-31 training set 0.5049639381691376\n",
      "R2 1985-01-31 - 1985-12-31 validation set 0.19169095378926937\n",
      "-------\n",
      "R2 1974-01-31 - 1983-12-30 training set 0.5011707419331102\n",
      "R2 1986-01-31 - 1987-01-30 validation set -0.03533807141585421\n",
      "-------\n",
      "R2 1975-01-31 - 1984-12-31 training set 0.5135913583489727\n",
      "R2 1987-02-27 - 1988-01-29 validation set 0.22499280084226114\n",
      "-------\n",
      "R2 1976-02-27 - 1985-12-31 training set 0.5150561140388838\n",
      "R2 1988-02-29 - 1988-12-30 validation set 0.415992514016145\n",
      "-------\n",
      "R2 1977-01-31 - 1987-01-30 training set 0.47268969883126033\n",
      "R2 1989-01-31 - 1989-12-29 validation set 0.4174511736266484\n",
      "-------\n",
      "R2 1978-01-31 - 1988-01-29 training set 0.4362132997948598\n",
      "R2 1990-01-31 - 1990-12-31 validation set 0.423290281118358\n",
      "-------\n",
      "R2 1979-01-31 - 1988-12-30 training set 0.42367663017529533\n",
      "R2 1991-01-31 - 1991-12-31 validation set -0.18388921331505936\n",
      "-------\n",
      "R2 1980-01-31 - 1989-12-29 training set 0.43061670966689225\n",
      "R2 1992-01-31 - 1993-01-29 validation set -0.06926415771131467\n",
      "-------\n",
      "R2 1981-02-27 - 1990-12-31 training set 0.42855406426268816\n",
      "R2 1993-02-26 - 1993-12-31 validation set -0.07314516343491495\n",
      "-------\n",
      "R2 1982-02-26 - 1991-12-31 training set 0.35051137276154\n",
      "R2 1994-01-31 - 1994-12-30 validation set 0.25871040036291626\n",
      "-------\n",
      "R2 1983-01-31 - 1993-01-29 training set 0.31882115474060746\n",
      "R2 1995-01-31 - 1995-12-29 validation set 0.09998520195439065\n",
      "-------\n",
      "R2 1984-01-31 - 1993-12-31 training set 0.29116296742266523\n",
      "R2 1996-01-31 - 1996-12-31 validation set 0.12879806087038026\n",
      "-------\n",
      "R2 1985-01-31 - 1994-12-30 training set 0.266602901577496\n",
      "R2 1997-01-31 - 1998-01-30 validation set 0.11759714424801393\n",
      "-------\n",
      "R2 1986-01-31 - 1995-12-29 training set 0.24171245448198164\n",
      "R2 1998-02-27 - 1999-01-29 validation set 0.0978654794893874\n",
      "-------\n",
      "R2 1987-02-27 - 1996-12-31 training set 0.23958882793133818\n",
      "R2 1999-02-26 - 1999-12-31 validation set 0.0607349923772883\n",
      "-------\n",
      "R2 1988-02-29 - 1998-01-30 training set 0.21924368332214572\n",
      "R2 2000-01-31 - 2000-12-29 validation set 0.08934824262613494\n",
      "-------\n",
      "R2 1989-01-31 - 1999-01-29 training set 0.1792953593458897\n",
      "R2 2001-01-31 - 2001-12-31 validation set 0.08174873999103605\n",
      "-------\n",
      "R2 1990-01-31 - 1999-12-31 training set 0.1427024090250827\n",
      "R2 2002-01-31 - 2002-12-31 validation set 0.08820762121853798\n",
      "-------\n",
      "R2 1991-01-31 - 2000-12-29 training set 0.12510938969830432\n",
      "R2 2003-01-31 - 2004-01-30 validation set -0.36081937528664687\n",
      "-------\n",
      "R2 1992-01-31 - 2001-12-31 training set 0.12131928507487488\n",
      "R2 2004-02-27 - 2004-12-31 validation set -0.14510327765412567\n",
      "-------\n",
      "R2 1993-02-26 - 2002-12-31 training set 0.11681576446779629\n",
      "R2 2005-01-31 - 2005-12-30 validation set 0.05583024006769188\n",
      "-------\n",
      "R2 1994-01-31 - 2004-01-30 training set 0.10440557565781639\n",
      "R2 2006-01-31 - 2006-12-29 validation set 0.13426614347509402\n",
      "-------\n",
      "R2 1995-01-31 - 2004-12-31 training set 0.08923306085940241\n",
      "R2 2007-01-31 - 2007-12-31 validation set 0.1568770877842084\n",
      "-------\n",
      "R2 1996-01-31 - 2005-12-30 training set 0.08248237442608708\n",
      "R2 2008-01-31 - 2009-01-30 validation set 0.10957303497139448\n",
      "-------\n",
      "R2 1997-01-31 - 2006-12-29 training set 0.09032063053234674\n",
      "R2 2009-02-27 - 2010-01-29 validation set -0.2228641915059968\n",
      "-------\n",
      "R2 1998-02-27 - 2007-12-31 training set 0.0935984095289547\n",
      "R2 2010-02-26 - 2010-12-31 validation set -0.15886718686907209\n",
      "-------\n",
      "R2 1999-02-26 - 2009-01-30 training set 0.101092640136205\n",
      "R2 2011-01-31 - 2011-12-30 validation set -0.03021668244081055\n",
      "-------\n",
      "R2 2000-01-31 - 2010-01-29 training set 0.09022643741883174\n",
      "R2 2012-01-31 - 2012-12-31 validation set -0.14449005670260195\n",
      "-------\n",
      "R2 2001-01-31 - 2010-12-31 training set 0.07242200015879086\n",
      "R2 2013-01-31 - 2013-12-31 validation set -0.13290293755761118\n",
      "-------\n",
      "R2 2002-01-31 - 2011-12-30 training set 0.06494834771910218\n",
      "R2 2014-01-31 - 2015-01-30 validation set -0.03551790210853367\n",
      "-------\n",
      "R2 2003-01-31 - 2012-12-31 training set 0.05156168498823299\n",
      "R2 2015-02-27 - 2016-01-29 validation set -0.0033644363312292924\n",
      "-------\n",
      "R2 2004-02-27 - 2013-12-31 training set 0.048384317480755556\n",
      "R2 2016-02-29 - 2016-12-30 validation set -0.06720600971772472\n",
      "-------\n",
      "R2 2005-01-31 - 2015-01-30 training set 0.04750877565773892\n",
      "R2 2017-01-31 - 2017-12-29 validation set -0.03703623488169838\n",
      "-------\n",
      "R2 2006-01-31 - 2016-01-29 training set 0.03754802965651227\n",
      "R2 2018-01-31 - 2018-12-31 validation set 0.006695226820880418\n",
      "-------\n",
      "R2 2007-01-31 - 2016-12-30 training set 0.03036378202252943\n",
      "R2 2019-01-31 - 2019-12-31 validation set -0.017458781202785545\n",
      "-------\n",
      "R2 2008-01-31 - 2017-12-29 training set 0.019194407560266247\n",
      "R2 2020-01-31 - 2021-01-29 validation set -0.006672322155517607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.018925321114587113"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'sic2', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.01, 0.001],  # Learning rate for the MLP\n",
    "    'alpha': np.linspace(start=0.00001,stop=0.001,num=10) \n",
    "}\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val = []\n",
    "y_val_list =[]\n",
    "r2_list = []\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "\n",
    "param_combinations =list(product(param_grid['learning_rate_init'],  param_grid['alpha']))\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "    print('-------')\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    for lr, alpha in param_combinations:\n",
    "        \n",
    "        test_results = pd.DataFrame(columns=[\"model\", \"learning rate\", \"alpha\"])\n",
    "\n",
    "        nn_model = MLPRegressor( learning_rate_init=lr, alpha=alpha, activation='relu', max_iter=1000, \n",
    "                            batch_size = 5000, early_stopping = True, n_iter_no_change = 10, random_state=42)\n",
    "\n",
    "\n",
    "        nn_model.fit(X_train,y_train)\n",
    "        Yval_predict = nn_model.predict(X_val)\n",
    "        mse = np.sqrt(mean_squared_error(y_val,Yval_predict))\n",
    "\n",
    "        test_results = pd.concat([test_results, pd.DataFrame([{\n",
    "            \"model\":\"MLPRegressor\",\n",
    "            \"learning rate\": lr,\n",
    "            \"alpha\": alpha,\n",
    "            \"mse\": mse\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        lr = test_results[test_results['mse']==test_results['mse'].min()]['learning rate'].values[0]\n",
    "        act = test_results[test_results['mse']==test_results['mse'].min()]['alpha'].values[0]\n",
    "    \n",
    "\n",
    "    model = MLPRegressor(learning_rate_init=lr, alpha=alpha, hidden_layer_sizes=32, activation='relu',\n",
    "                            batch_size=5000, early_stopping=True, n_iter_no_change=10, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_preds = model.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list.append(r2_train)\n",
    "    \n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=model.predict(X_test)\n",
    "\n",
    "    print(f'R2 {y_train.index[0][0].date()} - {y_train.index[-1][0].date()} training set {r2_train}')\n",
    "\n",
    "\n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 {y_test.index[0][0].date()} - {y_test.index[-1][0].date()} validation set {r2}')\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_full= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all_full= np.concatenate(y_test_list, axis=0) \n",
    "dates_all_full= np.concatenate(dates, axis=0)\n",
    "\n",
    "# R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "# print(\"R2OOS Linear Regression: \", R2FULL)\n",
    "R2FULL = r2_score(y_test_list_all_full, predictions_all_full)\n",
    "R2FULL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1970-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 2251 ,# val records 1040 , # test records 577\n",
      "Train period: 1971-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 2430 ,# val records 1103 , # test records 603\n",
      "Train period: 1972-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 2563 ,# val records 1180 , # test records 704\n",
      "Train period: 1973-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 2639 ,# val records 1307 , # test records 995\n",
      "Train period: 1974-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 2673 ,# val records 1699 , # test records 1068\n",
      "Train period: 1975-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 2924 ,# val records 2063 , # test records 862\n",
      "Train period: 1976-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 3405 ,# val records 1930 , # test records 1320\n",
      "Train period: 1977-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 3947 ,# val records 2182 , # test records 1304\n",
      "Train period: 1978-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 4232 ,# val records 2624 , # test records 1458\n",
      "Train period: 1979-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 4949 ,# val records 2762 , # test records 1919\n",
      "Train period: 1980-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 5549 ,# val records 3377 , # test records 1987\n",
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 6012 ,# val records 3906 , # test records 1777\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 6863 ,# val records 3764 , # test records 2049\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 7988 ,# val records 3826 , # test records 1959\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 8445 ,# val records 4008 , # test records 2113\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 9190 ,# val records 4072 , # test records 2619\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 9691 ,# val records 4732 , # test records 2583\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 9885 ,# val records 5202 , # test records 3051\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 10517 ,# val records 5634 , # test records 3348\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 11323 ,# val records 6399 , # test records 3879\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 12325 ,# val records 7227 , # test records 4797\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 13714 ,# val records 8676 , # test records 4780\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 15480 ,# val records 9577 , # test records 4451\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 17658 ,# val records 9231 , # test records 5511\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 19855 ,# val records 9962 , # test records 4865\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 21255 ,# val records 10376 , # test records 4631\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 23418 ,# val records 9496 , # test records 5287\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 24404 ,# val records 9918 , # test records 5390\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 24238 ,# val records 10677 , # test records 6472\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 24745 ,# val records 11862 , # test records 7051\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 25684 ,# val records 13523 , # test records 7335\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 26645 ,# val records 14386 , # test records 6578\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 28831 ,# val records 13913 , # test records 5023\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 31535 ,# val records 11601 , # test records 5446\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 32826 ,# val records 10469 , # test records 6469\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 32459 ,# val records 11915 , # test records 6450\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 31433 ,# val records 12919 , # test records 7158\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 30851 ,# val records 13608 , # test records 8585\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 29966 ,# val records 15743 , # test records 7934\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 30546 ,# val records 16519 , # test records 6952\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 34108 ,# val records 14886 , # test records 8126\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 36596 ,# val records 15078 , # test records 8521\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 37079 ,# val records 16647 , # test records 8175\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 38755 ,# val records 16696 , # test records 8745\n",
      "-------\n",
      "R2 training set 0.4244518671730211\n",
      "R2 validation set 0.5192608014237826\n",
      "-------\n",
      "R2 training set 0.36547026109652414\n",
      "R2 validation set 0.4793590852431726\n",
      "-------\n",
      "R2 training set 0.3834547140263467\n",
      "R2 validation set 0.5513520461725733\n",
      "-------\n",
      "R2 training set 0.44875843039975905\n",
      "R2 validation set 0.39483983593043814\n",
      "-------\n",
      "R2 training set 0.44181894532861143\n",
      "R2 validation set 0.5020646465537797\n",
      "-------\n",
      "R2 training set 0.4710300408226892\n",
      "R2 validation set 0.4315923134185602\n",
      "-------\n",
      "R2 training set 0.4940230150673003\n",
      "R2 validation set 0.45427609991869555\n",
      "-------\n",
      "R2 training set 0.5412932645354683\n",
      "R2 validation set 0.6079886416543702\n",
      "-------\n",
      "R2 training set 0.5271483864240204\n",
      "R2 validation set 0.21023154781646103\n",
      "-------\n",
      "R2 training set 0.5126275317759619\n",
      "R2 validation set -0.09292003190843645\n",
      "-------\n",
      "R2 training set 0.5170242203168137\n",
      "R2 validation set 0.26922042607790464\n",
      "-------\n",
      "R2 training set 0.5490149927284594\n",
      "R2 validation set 0.5096446374585792\n",
      "-------\n",
      "R2 training set 0.4123328408128005\n",
      "R2 validation set 0.45268128831106313\n",
      "-------\n",
      "R2 training set 0.3811756557770204\n",
      "R2 validation set 0.47210935954676414\n",
      "-------\n",
      "R2 training set 0.38215834759504264\n",
      "R2 validation set -0.022678274530059328\n",
      "-------\n",
      "R2 training set 0.34414939906874975\n",
      "R2 validation set 0.03965826970097419\n",
      "-------\n",
      "R2 training set 0.37998619358607\n",
      "R2 validation set -0.010200705940882182\n",
      "-------\n",
      "R2 training set 0.3748906404178868\n",
      "R2 validation set 0.3034064650367999\n",
      "-------\n",
      "R2 training set 0.38153331369992116\n",
      "R2 validation set 0.12537239593097205\n",
      "-------\n",
      "R2 training set 0.3034828636879\n",
      "R2 validation set 0.17675467061565997\n",
      "-------\n",
      "R2 training set 0.2851843513812665\n",
      "R2 validation set 0.1159021913087448\n",
      "-------\n",
      "R2 training set 0.21109973902998402\n",
      "R2 validation set 0.07215721118139584\n",
      "-------\n",
      "R2 training set 0.22155696424544424\n",
      "R2 validation set 0.08719143443462196\n",
      "-------\n",
      "R2 training set 0.18812621220426518\n",
      "R2 validation set 0.08138419678531639\n",
      "-------\n",
      "R2 training set 0.15015279758236955\n",
      "R2 validation set 0.12125193866211437\n",
      "-------\n",
      "R2 training set 0.1271450320073534\n",
      "R2 validation set 0.11062979088282698\n",
      "-------\n",
      "R2 training set 0.11723127755263318\n",
      "R2 validation set -0.4499178318168764\n",
      "-------\n",
      "R2 training set 0.1317306010397491\n",
      "R2 validation set -0.18867613834722574\n",
      "-------\n",
      "R2 training set 0.11209607472682404\n",
      "R2 validation set 0.08442697385294307\n",
      "-------\n",
      "R2 training set 0.11583250270289969\n",
      "R2 validation set 0.14167493406082243\n",
      "-------\n",
      "R2 training set 0.10901879681780435\n",
      "R2 validation set 0.16821301784487985\n",
      "-------\n",
      "R2 training set 0.09642227215385235\n",
      "R2 validation set 0.1276472960395595\n",
      "-------\n",
      "R2 training set 0.09972881889126795\n",
      "R2 validation set -0.2609811222628815\n",
      "-------\n",
      "R2 training set 0.12743571054731007\n",
      "R2 validation set -0.1279938569621455\n",
      "-------\n",
      "R2 training set 0.15546785944791408\n",
      "R2 validation set -0.0334774569078522\n",
      "-------\n",
      "R2 training set 0.1400280079055286\n",
      "R2 validation set -0.17002550189019217\n",
      "-------\n",
      "R2 training set 0.12444070895373605\n",
      "R2 validation set -0.19091470522168263\n",
      "-------\n",
      "R2 training set 0.1001305391945535\n",
      "R2 validation set -0.019975592876422255\n",
      "-------\n",
      "R2 training set 0.030242377733627923\n",
      "R2 validation set -0.008262928782701406\n",
      "-------\n",
      "R2 training set 0.039689428926931614\n",
      "R2 validation set -0.015412976379730381\n",
      "-------\n",
      "R2 training set 0.027203147840916597\n",
      "R2 validation set -0.0030082869658261124\n",
      "-------\n",
      "R2 training set 0.05059739523623008\n",
      "R2 validation set -0.03578357768371454\n",
      "-------\n",
      "R2 training set 0.03976732815504369\n",
      "R2 validation set -0.013020884287177514\n",
      "-------\n",
      "R2 training set 0.03001026381523808\n",
      "R2 validation set -0.0010445847107136697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03054756197216446"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'sic2', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df_large[features]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.01, 0.001],  # Learning rate for the MLP\n",
    "    'alpha': np.linspace(start=0.00001,stop=0.001,num=10) \n",
    "}\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val = []\n",
    "y_val_list =[]\n",
    "r2_list_top = []\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions_top = []\n",
    "y_test_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_all_top = {}\n",
    "\n",
    "\n",
    "param_combinations =list(product(param_grid['learning_rate_init'],  param_grid['alpha']))\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "    print('-------')\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    for lr, alpha in param_combinations:\n",
    "        \n",
    "        test_results = pd.DataFrame(columns=[\"model\", \"learning rate\", \"alpha\"])\n",
    "\n",
    "        nn_model = MLPRegressor( learning_rate_init=lr, alpha=alpha, activation='relu', max_iter=1000, \n",
    "                            batch_size = 5000, early_stopping = True, n_iter_no_change = 10, random_state=42)\n",
    "\n",
    "\n",
    "        nn_model.fit(X_train,y_train)\n",
    "        Yval_predict = nn_model.predict(X_val)\n",
    "        mse = np.sqrt(mean_squared_error(y_val,Yval_predict))\n",
    "\n",
    "        test_results = pd.concat([test_results, pd.DataFrame([{\n",
    "            \"model\":\"MLPRegressor\",\n",
    "            \"learning rate\": lr,\n",
    "            \"alpha\": alpha,\n",
    "            \"mse\": mse\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        lr = test_results[test_results['mse']==test_results['mse'].min()]['learning rate'].values[0]\n",
    "        act = test_results[test_results['mse']==test_results['mse'].min()]['alpha'].values[0]\n",
    "    \n",
    "\n",
    "    model = MLPRegressor(learning_rate_init=lr, alpha=alpha, hidden_layer_sizes=32, activation='relu',\n",
    "                            batch_size=5000, early_stopping=True, n_iter_no_change=10, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_preds = model.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list_top.append(r2_train)\n",
    "    \n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=model.predict(X_test)\n",
    "\n",
    "    print(f'R2 training set {r2_train}')\n",
    "\n",
    "\n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    predictions_top.append(preds)\n",
    "    dates_top.append(y_test.index)\n",
    "    y_test_list_top.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 validation set {r2}')\n",
    "    dic_r2_all_top[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_top= np.concatenate(predictions_top, axis=0)\n",
    "y_test_list_all_top= np.concatenate(y_test_list_top, axis=0) \n",
    "dates_all_top= np.concatenate(dates_top, axis=0)\n",
    "\n",
    "# R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "# print(\"R2OOS Linear Regression: \", R2FULL)\n",
    "R2TOP = r2_score(y_test_list_all_top, predictions_all_top)\n",
    "R2TOP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1970-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 2251 ,# val records 1040 , # test records 577\n",
      "Train period: 1971-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 2430 ,# val records 1103 , # test records 603\n",
      "Train period: 1972-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 2563 ,# val records 1180 , # test records 704\n",
      "Train period: 1973-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 2639 ,# val records 1307 , # test records 995\n",
      "Train period: 1974-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 2673 ,# val records 1699 , # test records 1068\n",
      "Train period: 1975-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 2924 ,# val records 2063 , # test records 862\n",
      "Train period: 1976-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 3405 ,# val records 1930 , # test records 1320\n",
      "Train period: 1977-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 3947 ,# val records 2182 , # test records 1304\n",
      "Train period: 1978-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 4232 ,# val records 2624 , # test records 1458\n",
      "Train period: 1979-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 4949 ,# val records 2762 , # test records 1919\n",
      "Train period: 1980-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 5549 ,# val records 3377 , # test records 1987\n",
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 6012 ,# val records 3906 , # test records 1777\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 6863 ,# val records 3764 , # test records 2049\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 7988 ,# val records 3826 , # test records 1959\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 8445 ,# val records 4008 , # test records 2113\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 9190 ,# val records 4072 , # test records 2619\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 9691 ,# val records 4732 , # test records 2583\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 9885 ,# val records 5202 , # test records 3051\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 10517 ,# val records 5634 , # test records 3348\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 11323 ,# val records 6399 , # test records 3879\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 12325 ,# val records 7227 , # test records 4797\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 13714 ,# val records 8676 , # test records 4780\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 15480 ,# val records 9577 , # test records 4451\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 17658 ,# val records 9231 , # test records 5511\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 19855 ,# val records 9962 , # test records 4865\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 21255 ,# val records 10376 , # test records 4631\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 23418 ,# val records 9496 , # test records 5287\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 24404 ,# val records 9918 , # test records 5390\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 24238 ,# val records 10677 , # test records 6472\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 24745 ,# val records 11862 , # test records 7051\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 25684 ,# val records 13523 , # test records 7335\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 26645 ,# val records 14386 , # test records 6578\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 28831 ,# val records 13913 , # test records 5023\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 31535 ,# val records 11601 , # test records 5446\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 32826 ,# val records 10469 , # test records 6469\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 32459 ,# val records 11915 , # test records 6450\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 31433 ,# val records 12919 , # test records 7158\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 30851 ,# val records 13608 , # test records 8585\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 29966 ,# val records 15743 , # test records 7934\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 30546 ,# val records 16519 , # test records 6952\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 34108 ,# val records 14886 , # test records 8126\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 36596 ,# val records 15078 , # test records 8521\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 37079 ,# val records 16647 , # test records 8175\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 38755 ,# val records 16696 , # test records 8745\n",
      "-------\n",
      "R2 training set 0.3659592277019119\n",
      "R2 validation set 0.47532183207286594\n",
      "-------\n",
      "R2 training set 0.29709215278766654\n",
      "R2 validation set 0.39693156119099715\n",
      "-------\n",
      "R2 training set 0.32196014823961383\n",
      "R2 validation set 0.4580570775320163\n",
      "-------\n",
      "R2 training set 0.3661407217755479\n",
      "R2 validation set 0.3827662363813199\n",
      "-------\n",
      "R2 training set 0.3648093661678896\n",
      "R2 validation set 0.5003773488614827\n",
      "-------\n",
      "R2 training set 0.40262343409835644\n",
      "R2 validation set 0.37641237503278047\n",
      "-------\n",
      "R2 training set 0.4498387485972558\n",
      "R2 validation set 0.37104422076890153\n",
      "-------\n",
      "R2 training set 0.5024087249987845\n",
      "R2 validation set 0.526749070156912\n",
      "-------\n",
      "R2 training set 0.4813111076285215\n",
      "R2 validation set 0.2376279597429084\n",
      "-------\n",
      "R2 training set 0.46477530621593066\n",
      "R2 validation set -0.04369636717096692\n",
      "-------\n",
      "R2 training set 0.46976093224480764\n",
      "R2 validation set 0.1857158075049402\n",
      "-------\n",
      "R2 training set 0.4662310147004812\n",
      "R2 validation set 0.3532144065206445\n",
      "-------\n",
      "R2 training set 0.35853536696972677\n",
      "R2 validation set 0.4223934579692259\n",
      "-------\n",
      "R2 training set 0.30133449032605153\n",
      "R2 validation set 0.3533941129882189\n",
      "-------\n",
      "R2 training set 0.2986717888467083\n",
      "R2 validation set -0.05667465518119874\n",
      "-------\n",
      "R2 training set 0.29230786352815685\n",
      "R2 validation set -0.0222918337338327\n",
      "-------\n",
      "R2 training set 0.3268863522801576\n",
      "R2 validation set -0.057632656617269795\n",
      "-------\n",
      "R2 training set 0.2993296528879532\n",
      "R2 validation set 0.23688254857371183\n",
      "-------\n",
      "R2 training set 0.28261314750538635\n",
      "R2 validation set 0.10168523184866829\n",
      "-------\n",
      "R2 training set 0.19886313537080869\n",
      "R2 validation set 0.10076650655468566\n",
      "-------\n",
      "R2 training set 0.18203488095628195\n",
      "R2 validation set 0.12139852304092269\n",
      "-------\n",
      "R2 training set 0.14793061864455004\n",
      "R2 validation set 0.09818963119928625\n",
      "-------\n",
      "R2 training set 0.13169768766712586\n",
      "R2 validation set 0.0517202902086934\n",
      "-------\n",
      "R2 training set 0.1429354139066047\n",
      "R2 validation set 0.08189830771639184\n",
      "-------\n",
      "R2 training set 0.14194806138540517\n",
      "R2 validation set 0.05896676119751221\n",
      "-------\n",
      "R2 training set 0.11069858434864743\n",
      "R2 validation set 0.06868231816543235\n",
      "-------\n",
      "R2 training set 0.11474410222076425\n",
      "R2 validation set -0.33859928585781973\n",
      "-------\n",
      "R2 training set 0.11185508664759569\n",
      "R2 validation set -0.14011553354841233\n",
      "-------\n",
      "R2 training set 0.1014668368425401\n",
      "R2 validation set 0.05298131463858213\n",
      "-------\n",
      "R2 training set 0.07633935183425222\n",
      "R2 validation set 0.09087223354985574\n",
      "-------\n",
      "R2 training set 0.07846376892382045\n",
      "R2 validation set 0.135111923919495\n",
      "-------\n",
      "R2 training set 0.036301336311392984\n",
      "R2 validation set 0.0858936242422359\n",
      "-------\n",
      "R2 training set 0.0392702961893171\n",
      "R2 validation set -0.16950281561167113\n",
      "-------\n",
      "R2 training set 0.09185140935397118\n",
      "R2 validation set -0.098587901686926\n",
      "-------\n",
      "R2 training set 0.11219152043930947\n",
      "R2 validation set -0.010416229845362945\n",
      "-------\n",
      "R2 training set 0.10321744848779246\n",
      "R2 validation set -0.10891942762873486\n",
      "-------\n",
      "R2 training set 0.08211846557354607\n",
      "R2 validation set -0.10112031559230017\n",
      "-------\n",
      "R2 training set 0.06398160991530666\n",
      "R2 validation set -0.0006042932045764449\n",
      "-------\n",
      "R2 training set 0.02255683774560291\n",
      "R2 validation set 0.0001697805553805276\n",
      "-------\n",
      "R2 training set 0.0431105063967584\n",
      "R2 validation set 0.011979600261060153\n",
      "-------\n",
      "R2 training set 0.015976959565281\n",
      "R2 validation set -0.008636347593017568\n",
      "-------\n",
      "R2 training set 0.011506687784841874\n",
      "R2 validation set -0.021050400936728497\n",
      "-------\n",
      "R2 training set 0.015672459001815908\n",
      "R2 validation set -0.004031586263437026\n",
      "-------\n",
      "R2 training set 0.01889135805208575\n",
      "R2 validation set -0.00029992067266793043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017735426602415894"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'sic2', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df_small[features]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.01, 0.001],  # Learning rate for the MLP\n",
    "    'alpha': np.linspace(start=0.00001,stop=0.001,num=10) \n",
    "}\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val = []\n",
    "y_val_list =[]\n",
    "r2_list_bottom = []\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions_bottom = []\n",
    "y_test_list_bottom =[]\n",
    "dates_bottom = []\n",
    "dic_r2_all_bottom = {}\n",
    "\n",
    "\n",
    "param_combinations =list(product(param_grid['learning_rate_init'],  param_grid['alpha']))\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "    print('-------')\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    for lr, alpha in param_combinations:\n",
    "        \n",
    "        test_results = pd.DataFrame(columns=[\"model\", \"learning rate\", \"alpha\"])\n",
    "\n",
    "        nn_model = MLPRegressor( learning_rate_init=lr, alpha=alpha, activation='relu', max_iter=1000, \n",
    "                            batch_size = 5000, early_stopping = True, n_iter_no_change = 10, random_state=42)\n",
    "\n",
    "\n",
    "        nn_model.fit(X_train,y_train)\n",
    "        Yval_predict = nn_model.predict(X_val)\n",
    "        mse = np.sqrt(mean_squared_error(y_val,Yval_predict))\n",
    "\n",
    "        test_results = pd.concat([test_results, pd.DataFrame([{\n",
    "            \"model\":\"MLPRegressor\",\n",
    "            \"learning rate\": lr,\n",
    "            \"alpha\": alpha,\n",
    "            \"mse\": mse\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "        lr = test_results[test_results['mse']==test_results['mse'].min()]['learning rate'].values[0]\n",
    "        act = test_results[test_results['mse']==test_results['mse'].min()]['alpha'].values[0]\n",
    "    \n",
    "\n",
    "    model = MLPRegressor(learning_rate_init=lr, alpha=alpha, hidden_layer_sizes=32, activation='relu',\n",
    "                            batch_size=5000, early_stopping=True, n_iter_no_change=10, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_preds = model.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list_bottom.append(r2_train)\n",
    "    \n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=model.predict(X_test)\n",
    "\n",
    "    print(f'R2 training set {r2_train}')\n",
    "\n",
    "\n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    predictions_bottom.append(preds)\n",
    "    dates_bottom.append(y_test.index)\n",
    "    y_test_list_bottom.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 validation set {r2}')\n",
    "    dic_r2_all_top[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_bottom= np.concatenate(predictions_bottom, axis=0)\n",
    "y_test_list_all_bottom= np.concatenate(y_test_list_bottom, axis=0) \n",
    "dates_all_bottom= np.concatenate(dates_bottom, axis=0)\n",
    "\n",
    "# R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "# print(\"R2OOS Linear Regression: \", R2FULL)\n",
    "R2BOTTOM = r2_score(y_test_list_all_bottom, predictions_all_bottom)\n",
    "R2BOTTOM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Sample</th>\n",
       "      <td>0.018925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Large Firms</th>\n",
       "      <td>0.030548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Small Firms</th>\n",
       "      <td>0.017735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NN-1\n",
       "Full Sample  0.018925\n",
       "Large Firms  0.030548\n",
       "Small Firms  0.017735"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chart = np.array([[R2FULL],\n",
    "                  [R2TOP],\n",
    "                  [R2BOTTOM]])\n",
    "\n",
    "NN1 = pd.DataFrame(chart, columns=['NN-1'],\n",
    "                     index=['Full Sample', 'Large Firms', 'Small Firms'])\n",
    "\n",
    "NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN1.to_csv(r'r2_NN1_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12','sic2' , 'DATE2', 'DATE', 'risk_premium', 'year'])].tolist()\n",
    "df['year'] = df['DATE'].dt.year\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.01, 0.005, 0.001],  # Learning rate for the MLP\n",
    "    'activation': ['relu', 'logistic']  # Activation functions to try\n",
    "}\n",
    "test_results = pd.DataFrame(columns=[\"model\", \"learning rate\", \"activation\"])\n",
    "\n",
    "X_train = df[features].loc[(df[\"year\"]>=2008) & (df[\"year\"]<=2018)]\n",
    "y_train = df[\"risk_premium\"].loc[(df[\"year\"]>=2008) & (df[\"year\"]<=2018)]\n",
    "\n",
    "X_val = df[features].loc[(df[\"year\"]>=2018) & (df[\"year\"]<=2020)]\n",
    "y_val = df[\"risk_premium\"].loc[(df[\"year\"]>=2018) & (df[\"year\"]<=2020)]\n",
    "\n",
    "\n",
    "param_combinations =list(product(param_grid['learning_rate_init'],  param_grid['activation']))\n",
    "\n",
    "for lr, activation in param_combinations:\n",
    "    nn_model = MLPRegressor( learning_rate_init=lr, activation=activation, max_iter=1000, \n",
    "                            batch_size = 128, early_stopping = True, n_iter_no_change = 10, random_state=42)\n",
    "\n",
    "\n",
    "    nn_model.fit(X_train,y_train)\n",
    "    Yval_predict = nn_model.predict(X_val)\n",
    "    mse = np.sqrt(mean_squared_error(y_val,Yval_predict))\n",
    "    print(mse)\n",
    "\n",
    "\n",
    "    test_results = pd.concat([test_results, pd.DataFrame([{\n",
    "        \"model\":\"MLPRegressor\",\n",
    "        \"learning rate\": lr,\n",
    "        \"activation\": activation,\n",
    "        \"mse\": mse\n",
    "    }])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = predictions_all_full.tolist()\n",
    "y_true = y_test_list_all_full.tolist()\n",
    "i = dates_all_full.tolist()\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'identifier': i,\n",
    "     'yhat': yhat,\n",
    "     'y_true': y_true\n",
    "    })\n",
    "\n",
    "results[\"identifier\"]= results[\"identifier\"].astype(\"str\")\n",
    "results[\"date\"] = results[\"identifier\"].str[12:22]\n",
    "results[\"id\"] = results[\"identifier\"].str[35:40]\n",
    "results.drop([\"identifier\"],axis = 1, inplace=True)\n",
    "results['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n",
    "results['MonthYear'] = results['date'].dt.to_period('M')\n",
    "results = results.sort_values(by = ['date', 'id'], ascending = True)\n",
    "results = results.set_index(['MonthYear','id'])\n",
    "results\n",
    "\n",
    "# results['yhat'] = results['yhat'].apply(lambda x: x[0])\n",
    "results['y_true'] = results['y_true'].apply(lambda x: x[0])\n",
    "\n",
    "data = df[['mvel12', 'macro_tbl', 'macro_svar']].copy()\n",
    "data.reset_index(inplace=True)\n",
    "data['permno2'] = data['permno2'].astype('str')\n",
    "data['MonthYear'] = data['DATE2'].dt.to_period('M')\n",
    "data.drop('DATE2', axis=1, inplace=True)\n",
    "data.rename(columns={'permno2': 'id'}, inplace=True)\n",
    "data.rename(columns={'mvel12': 'market_cap'}, inplace=True)\n",
    "data.rename(columns={'macro_tbl': 'risk_free_rate'}, inplace=True)\n",
    "data = data.set_index(['MonthYear','id'])\n",
    "\n",
    "bigdata = pd.merge(results, data,left_index=True, right_index=True)\n",
    "bigdata.reset_index(inplace=True)\n",
    "bigdata\n",
    "bigdata['returns'] = bigdata['y_true'] + bigdata['risk_free_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "       508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n",
       "       521, 522, 523, 524, 525, 526, 527, 528, 529], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata['MonthYear1'] = bigdata['MonthYear'].copy()\n",
    "bigdata['MonthYear'] = bigdata['MonthYear'].astype('int64')\n",
    "bigdata['NumMonth'] = bigdata['MonthYear'] - 83\n",
    "bigdata['NumMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata.to_csv('predictions/nnet1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = pd.read_csv('predictions/nnet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = bigdata.sort_values(['NumMonth','yhat'], ascending=[True, True]).groupby(['MonthYear'],\n",
    "                                                                  as_index=False,\n",
    "                                                                  sort=False).tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = top_100[['date', 'NumMonth','MonthYear', 'id', 'yhat', 'y_true', 'risk_free_rate', 'MonthYear1']]\n",
    "portfolio.reset_index(inplace=True)\n",
    "portfolio.drop(columns=['index'],inplace=True)\n",
    "portfolio['eq_weights'] = 1/portfolio.groupby('MonthYear')['id'].transform('size')\n",
    "portfolio['excess_return_stock_ew'] = portfolio['y_true'] *portfolio['eq_weights']\n",
    "portfolio['pred_excess_return_stock_ew'] = portfolio[\"yhat\"]*portfolio[\"eq_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred_return = portfolio.groupby('MonthYear')['pred_excess_return_stock_ew'].transform('sum').mean()\n",
    "mean_port_return = portfolio.groupby('MonthYear')['excess_return_stock_ew'].transform('sum').mean()\n",
    "port_vol =  portfolio.groupby('MonthYear')[\"pred_excess_return_stock_ew\"].transform('sum').std()\n",
    "sharp_ratio = (mean_pred_return/port_vol)*np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN-1</th>\n",
       "      <td>-3.40%</td>\n",
       "      <td>-1.74%</td>\n",
       "      <td>2.98%</td>\n",
       "      <td>-2.02%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Real    Pred    Std  Sharpe\n",
       "NN-1  -3.40%  -1.74%  2.98%  -2.02%"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_np = np.array([[mean_port_return, mean_pred_return, port_vol, sharp_ratio]])\n",
    "\n",
    "ew_df = pd.DataFrame(chart_np, columns=['Real', 'Pred', 'Std', 'Sharpe'],\n",
    "                                index=['NN-1'])\n",
    "\n",
    "ew_df['Real'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Real']], index= ew_df.index)\n",
    "ew_df['Pred'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Pred']], index= ew_df.index)\n",
    "ew_df['Std'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Std']], index= ew_df.index)\n",
    "ew_df['Sharpe'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Sharpe']], index= ew_df.index)\n",
    "ew_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
