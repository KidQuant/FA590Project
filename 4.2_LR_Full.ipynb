{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "pd.set_option('display.max_rows', None)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/factors_2002.csv', parse_dates=['DATE'])\n",
    "# df = pd.read_csv('data/features_subset.csv', parse_dates=['DATE'])\n",
    "# df = pd.read_csv('factors_1900.csv', parse_dates=['DATE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_dp</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>Date</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>29380.699219</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.246853</td>\n",
       "      <td>9.020208</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>-0.032968</td>\n",
       "      <td>6.956505e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.274154</td>\n",
       "      <td>3.823618</td>\n",
       "      <td>0.132561</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>200202.0</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>84361.703125</td>\n",
       "      <td>0.149783</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>-0.356072</td>\n",
       "      <td>8.509161</td>\n",
       "      <td>0.058969</td>\n",
       "      <td>0.290509</td>\n",
       "      <td>3.427267e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>4.274154</td>\n",
       "      <td>3.823618</td>\n",
       "      <td>0.132561</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>200202.0</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>65282.878906</td>\n",
       "      <td>2.408649</td>\n",
       "      <td>5.801589</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>9.949011</td>\n",
       "      <td>0.138741</td>\n",
       "      <td>-0.123827</td>\n",
       "      <td>4.471088e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.274154</td>\n",
       "      <td>3.823618</td>\n",
       "      <td>0.132561</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>200202.0</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10019</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>10352.500000</td>\n",
       "      <td>1.991428</td>\n",
       "      <td>3.965783</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>7.429473</td>\n",
       "      <td>0.159603</td>\n",
       "      <td>0.039784</td>\n",
       "      <td>4.471088e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.274154</td>\n",
       "      <td>3.823618</td>\n",
       "      <td>0.132561</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>200202.0</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10025</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>186744.234375</td>\n",
       "      <td>0.138594</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>-0.112840</td>\n",
       "      <td>10.115205</td>\n",
       "      <td>0.070544</td>\n",
       "      <td>0.083402</td>\n",
       "      <td>6.441576e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.274154</td>\n",
       "      <td>3.823618</td>\n",
       "      <td>0.132561</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>200202.0</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE          mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10001 2002-01-31   29380.699219  0.024547  0.000603 -0.246853   9.020208   \n",
       "1   10002 2002-01-31   84361.703125  0.149783  0.022435 -0.356072   8.509161   \n",
       "2   10012 2002-01-31   65282.878906  2.408649  5.801589 -0.285714   9.949011   \n",
       "3   10019 2002-01-31   10352.500000  1.991428  3.965783  0.214286   7.429473   \n",
       "4   10025 2002-01-31  186744.234375  0.138594  0.019208 -0.112840  10.115205   \n",
       "\n",
       "    idiovol    indmom         mom1m  ...  macro_dp  macro_ep  macro_bm  \\\n",
       "0  0.029936 -0.032968  6.956505e-03  ...  4.274154  3.823618  0.132561   \n",
       "1  0.058969  0.290509  3.427267e-08  ...  4.274154  3.823618  0.132561   \n",
       "2  0.138741 -0.123827  4.471088e-01  ...  4.274154  3.823618  0.132561   \n",
       "3  0.159603  0.039784  4.471088e-01  ...  4.274154  3.823618  0.132561   \n",
       "4  0.070544  0.083402  6.441576e-02  ...  4.274154  3.823618  0.132561   \n",
       "\n",
       "   macro_ntis  macro_tbl  macro_tms  macro_dfy  macro_svar      Date  \\\n",
       "0    0.011191     0.0165    -0.0027     0.0132    0.002184  200202.0   \n",
       "1    0.011191     0.0165    -0.0027     0.0132    0.002184  200202.0   \n",
       "2    0.011191     0.0165    -0.0027     0.0132    0.002184  200202.0   \n",
       "3    0.011191     0.0165    -0.0027     0.0132    0.002184  200202.0   \n",
       "4    0.011191     0.0165    -0.0027     0.0132    0.002184  200202.0   \n",
       "\n",
       "   macro_mkt-rf  \n",
       "0         -1.44  \n",
       "1         -1.44  \n",
       "2         -1.44  \n",
       "3         -1.44  \n",
       "4         -1.44  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= df[~np.isnan(df['bm'])]\n",
    "# df =df[~np.isnan(df['mvel1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "df['mvel12'] = df['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_2560\\2840026024.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n",
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_2560\\2840026024.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize all independent variables\n",
    "\n",
    "stdSc = StandardScaler()\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', 'mvel1', 'mvel12', 'permno', 'permno2', 'risk_premium'])].tolist()\n",
    "df[features] = stdSc.fit_transform(df[features].astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 407907 ,# val records 166149 , # test records 69933\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 403677 ,# val records 154356 , # test records 62636\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 400348 ,# val records 132569 , # test records 67553\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 397015 ,# val records 130189 , # test records 66481\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 379345 ,# val records 134034 , # test records 65816\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 366271 ,# val records 132297 , # test records 73459\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 351026 ,# val records 139275 , # test records 69143\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 332419 ,# val records 142602 , # test records 62620\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 335945 ,# val records 131763 , # test records 68169\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 342452 ,# val records 130789 , # test records 68789\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 337519 ,# val records 136958 , # test records 68931\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 339207 ,# val records 137720 , # test records 75768\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(2007,1,31), second_split_date= datetime.date(2009,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    lm = LinearRegression()\n",
    "   \n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "    \n",
    "    y_pred_val = lm.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "r2_val_full = np.mean(y_val_list)\n",
    "print(np.mean(r2_val_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 122347 ,# val records 49836 , # test records 20976\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 121078 ,# val records 46299 , # test records 18787\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 120082 ,# val records 39763 , # test records 20259\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 119083 ,# val records 39046 , # test records 19940\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 113784 ,# val records 40199 , # test records 19738\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 109858 ,# val records 39678 , # test records 22032\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 105285 ,# val records 41770 , # test records 20737\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 99700 ,# val records 42769 , # test records 18780\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 100756 ,# val records 39517 , # test records 20445\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 102706 ,# val records 39225 , # test records 20630\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 101227 ,# val records 41075 , # test records 20674\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 101732 ,# val records 41304 , # test records 22724\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df_large[features]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(2007,1,31), second_split_date= datetime.date(2009,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "\n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    lm = LinearRegression()\n",
    "   \n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "    \n",
    "    y_pred_val = lm.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "r2_val_large = np.mean(y_val_list)\n",
    "print(np.mean(r2_val_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 122347 ,# val records 49836 , # test records 20976\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 121078 ,# val records 46299 , # test records 18787\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 120082 ,# val records 39763 , # test records 20259\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 119083 ,# val records 39046 , # test records 19940\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 113784 ,# val records 40199 , # test records 19738\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 109858 ,# val records 39678 , # test records 22032\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 105285 ,# val records 41770 , # test records 20737\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 99700 ,# val records 42769 , # test records 18780\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 100756 ,# val records 39517 , # test records 20445\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 102706 ,# val records 39225 , # test records 20630\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 101227 ,# val records 41075 , # test records 20674\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 101732 ,# val records 41304 , # test records 22724\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'DATE2', 'risk_premium'])].tolist()\n",
    "X = df_small[features]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "predictions_top = []\n",
    "y_train_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_all_top = {}\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(2007,1,31), second_split_date= datetime.date(2009,1,31)):\n",
    "\n",
    "    X_train = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "\n",
    "    X_val = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test = y.loc[test_index]\n",
    "\n",
    "    lm = LinearRegression()\n",
    "   \n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "    \n",
    "    y_pred_val = lm.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "\n",
    "r2_val_small = np.mean(y_val_list)\n",
    "print(np.mean(r2_val_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Sample</th>\n",
       "      <td>0.055453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Large Firms</th>\n",
       "      <td>0.152238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Small Firms</th>\n",
       "      <td>0.013234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Linear Regression\n",
       "Full Sample           0.055453\n",
       "Large Firms           0.152238\n",
       "Small Firms           0.013234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = np.array([[r2_val_full],\n",
    "                  [r2_val_large ],\n",
    "                  [r2_val_small]])\n",
    "\n",
    "r2_lm = pd.DataFrame(chart, columns=['Linear Regression'],\n",
    "                     index=['Full Sample', 'Large Firms', 'Small Firms'])\n",
    "\n",
    "r2_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lm.to_csv(r'r2_linear_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set: 0.0847830125924195\n",
      "R2 score on validation set: -0.0781892069613277\n"
     ]
    }
   ],
   "source": [
    "features = df.columns[~df.columns.isin(['permno','permno','DATE','DATE2','mvel12','risk_premium', 'year'])].tolist()\n",
    "df['YEAR'] = df['DATE'].dt.year\n",
    "\n",
    "X_train = df[features].loc[(df['YEAR']>=2012) & (df['YEAR']<=2016)]\n",
    "y_train = df['risk_premium'].loc[(df['YEAR']>=2012) & (df['YEAR']<=2016)]\n",
    "\n",
    "X_val = df[features].loc[(df['YEAR']>=2017) & (df['YEAR']<=2018)]\n",
    "y_val = df['risk_premium'].loc[(df['YEAR']>=2017) & (df['YEAR']<=2018)]\n",
    "\n",
    "\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X_train, y_train)\n",
    "y_pred_train = lm_model.predict(X_train) \n",
    "\n",
    "y_pred_val = lm_model.predict(X_val) \n",
    "\n",
    "r2_score_train = r2_score(y_train, y_pred_train)\n",
    "r2_score_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "print(f'R2 score on training set: {r2_score_train}')\n",
    "print(f'R2 score on validation set: {r2_score_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 924. MiB for an array with shape (83, 1458469) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j)] \u001b[38;5;241m=\u001b[39m  df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j)][\u001b[38;5;28mstr\u001b[39m(j)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\pandas\\core\\generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[0;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6815\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:604\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    601\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 604\u001b[0m     res\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2270\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2271\u001b[0m     )\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2287\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2294\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([b\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks])  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2296\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 924. MiB for an array with shape (83, 1458469) and data type float64"
     ]
    }
   ],
   "source": [
    "for j in features:\n",
    "    globals()['df_' + str(j)] =  df.copy()\n",
    "    globals()['df_' + str(j)][str(j)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_mvel1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m dic \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m----> 5\u001b[0m     df_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j)]\n\u001b[0;32m      7\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m df_var[features]\u001b[38;5;241m.\u001b[39mloc[(df_var[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2012\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_var[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2016\u001b[39m)]\n\u001b[0;32m      8\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m df_var[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisk_premium\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[(df_var[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2012\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_var[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2016\u001b[39m)]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'df_mvel1'"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "\n",
    "    \n",
    "for j in features:\n",
    "    df_var = globals()['df_' + str(j)]\n",
    "    \n",
    "    X_train = df_var[features].loc[(df_var[\"year\"]>=2012) & (df_var[\"year\"]<=2016)]\n",
    "    y_train = df_var['risk_premium'].loc[(df_var[\"year\"]>=2012) & (df_var[\"year\"]<=2016)]\n",
    "\n",
    "    X_val = df_var[features].loc[(df_var[\"year\"]>=2017) & (df_var[\"year\"]<=2018)]\n",
    "    y_val = df_var['risk_premium'].loc[(df_var[\"year\"]>=2017) & (df_var[\"year\"]<=2018)]\n",
    "    \n",
    "    lm_model = LinearRegression()\n",
    "    lm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = lm_model.predict(X_train) \n",
    "\n",
    "    y_pred_val = lm_model.predict(X_val) \n",
    "\n",
    "    r2_score_train = r2_score(y_train, y_pred_train)\n",
    "    r2_score_val = r2_score(y_val, y_pred_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
