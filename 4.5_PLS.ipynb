{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import pickle \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('factors_2002.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE       mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10401 1970-02-27  26227356.0  0.253755  0.064391 -0.057929  13.348086   \n",
      "1   10604 1970-02-27   3196008.0  0.743947  0.553457 -0.228256  13.348086   \n",
      "2   10786 1970-02-27   1133566.5  0.608122  0.369813 -0.046833  12.456023   \n",
      "3   10890 1970-02-27   2662344.0  0.833271  0.694341  0.001993  13.348086   \n",
      "4   11260 1970-02-27   1342376.0  1.059627  1.122808  0.034205  13.348086   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.019852 -0.112202 -0.017995  ...  2.757287  0.670148    0.035855   \n",
      "1  0.044046 -0.252877 -0.164006  ...  2.757287  0.670148    0.035855   \n",
      "2  0.025765 -0.302840 -0.050691  ...  2.757287  0.670148    0.035855   \n",
      "3  0.035138 -0.127664 -0.018268  ...  2.757287  0.670148    0.035855   \n",
      "4  0.032067 -0.349402 -0.185455  ...  2.757287  0.670148    0.035855   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
      "1     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
      "2     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
      "3     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
      "4     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
      "\n",
      "   macro_smb  \n",
      "0      -2.58  \n",
      "1      -2.58  \n",
      "2      -2.58  \n",
      "3      -2.58  \n",
      "4      -2.58  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df[\"DATE\"].dt.year<2014 ]\n",
    "test = df.loc[df['DATE'].dt.year>=2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asealy\\AppData\\Local\\Temp\\ipykernel_18808\\1940433511.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[train.columns[2:]] = train[train.columns[2:]].astype('float32')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "      <th>macro_hml</th>\n",
       "      <th>macro_smb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10401</td>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>26227356.0</td>\n",
       "      <td>0.253755</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>-0.057929</td>\n",
       "      <td>13.348085</td>\n",
       "      <td>0.019852</td>\n",
       "      <td>-0.112202</td>\n",
       "      <td>-0.017995</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757288</td>\n",
       "      <td>0.670147</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10604</td>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>3196008.0</td>\n",
       "      <td>0.743947</td>\n",
       "      <td>0.553457</td>\n",
       "      <td>-0.228256</td>\n",
       "      <td>13.348085</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.164006</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757288</td>\n",
       "      <td>0.670147</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10786</td>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>1133566.5</td>\n",
       "      <td>0.608122</td>\n",
       "      <td>0.369813</td>\n",
       "      <td>-0.046833</td>\n",
       "      <td>12.456023</td>\n",
       "      <td>0.025765</td>\n",
       "      <td>-0.302840</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757288</td>\n",
       "      <td>0.670147</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10890</td>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>2662344.0</td>\n",
       "      <td>0.833271</td>\n",
       "      <td>0.694341</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>13.348085</td>\n",
       "      <td>0.035138</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.018268</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757288</td>\n",
       "      <td>0.670147</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11260</td>\n",
       "      <td>1970-02-27</td>\n",
       "      <td>1342376.0</td>\n",
       "      <td>1.059626</td>\n",
       "      <td>1.122808</td>\n",
       "      <td>0.034205</td>\n",
       "      <td>13.348085</td>\n",
       "      <td>0.032067</td>\n",
       "      <td>-0.349402</td>\n",
       "      <td>-0.185455</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757288</td>\n",
       "      <td>0.670147</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-2.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE       mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10401 1970-02-27  26227356.0  0.253755  0.064391 -0.057929  13.348085   \n",
       "1   10604 1970-02-27   3196008.0  0.743947  0.553457 -0.228256  13.348085   \n",
       "2   10786 1970-02-27   1133566.5  0.608122  0.369813 -0.046833  12.456023   \n",
       "3   10890 1970-02-27   2662344.0  0.833271  0.694341  0.001993  13.348085   \n",
       "4   11260 1970-02-27   1342376.0  1.059626  1.122808  0.034205  13.348085   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
       "0  0.019852 -0.112202 -0.017995  ...  2.757288  0.670147    0.035855   \n",
       "1  0.044046 -0.252877 -0.164006  ...  2.757288  0.670147    0.035855   \n",
       "2  0.025765 -0.302840 -0.050691  ...  2.757288  0.670147    0.035855   \n",
       "3  0.035138 -0.127664 -0.018268  ...  2.757288  0.670147    0.035855   \n",
       "4  0.032067 -0.349402 -0.185455  ...  2.757288  0.670147    0.035855   \n",
       "\n",
       "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
       "0     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
       "1     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
       "2     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
       "3     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
       "4     0.0713    -0.0126     0.0085    0.001059          5.13       3.93   \n",
       "\n",
       "   macro_smb  \n",
       "0      -2.58  \n",
       "1      -2.58  \n",
       "2      -2.58  \n",
       "3      -2.58  \n",
       "4      -2.58  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "train[train.columns[2:]] = train[train.columns[2:]].astype('float32')\n",
    "train = train.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['permno2'] = train['permno'].copy()\n",
    "train['DATE2'] = train['DATE'].copy()\n",
    "train = train.set_index(['DATE2','permno2'])\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "train['mvel12'] = train['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asealy\\AppData\\Local\\Temp\\ipykernel_18808\\1162568465.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_large= train.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n",
      "C:\\Users\\asealy\\AppData\\Local\\Temp\\ipykernel_18808\\1162568465.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_small = train.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "p=0.2 \n",
    "train_large= train.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "train_small = train.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asealy\\AppData\\Local\\Temp\\ipykernel_18808\\1884498540.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[features]=test.groupby('DATE')[features].rank(pct=True)\n",
      "C:\\Users\\asealy\\AppData\\Local\\Temp\\ipykernel_18808\\1884498540.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[features] = 2*test[features] - 1\n"
     ]
    }
   ],
   "source": [
    "features = train.columns[~train.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "train[features]=train.groupby('DATE')[features].rank(pct=True)\n",
    "\n",
    "train[features] = 2*train[features] - 1\n",
    "\n",
    "features = test.columns[~test.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "test[features]=test.groupby('DATE')[features].rank(pct=True)\n",
    "\n",
    "test[features] = 2*test[features] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 # train records 20125 ,# val records 13057\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 # train records 22963 ,# val records 12572\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 # train records 26711 ,# val records 12781\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 # train records 28226 ,# val records 13403\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 # train records 30708 ,# val records 13616\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 # train records 32391 ,# val records 15806\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 # train records 33038 ,# val records 17371\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 # train records 35140 ,# val records 18821\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 # train records 37837 ,# val records 21369\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 # train records 41180 ,# val records 24121\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 # train records 45803 ,# val records 28955\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 # train records 51685 ,# val records 31959\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 # train records 58952 ,# val records 30796\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 # train records 66273 ,# val records 33236\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 # train records 70927 ,# val records 34622\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 # train records 78140 ,# val records 31682\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 # train records 81428 ,# val records 33091\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 # train records 80867 ,# val records 35622\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 # train records 82560 ,# val records 39570\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 # train records 85693 ,# val records 45111\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 # train records 88894 ,# val records 47991\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 # train records 96182 ,# val records 46419\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 # train records 105203 ,# val records 38716\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 # train records 109510 ,# val records 34937\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 # train records 108297 ,# val records 39748\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 # train records 104877 ,# val records 43094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\asealy\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m predictions_all_full \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     56\u001b[0m y_test_list_all_full \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(y_val_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m dates_all_full \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(dates, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     59\u001b[0m R2FULL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mpow\u001b[39m(y_test_list_all_full\u001b[38;5;241m-\u001b[39mpredictions_all_full,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mpow\u001b[39m(y_test_list_all_full,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2OOS Huber Regression: \u001b[39m\u001b[38;5;124m\"\u001b[39m, R2FULL)\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   freq='months')\n",
    "\n",
    "features = train.columns[~train.columns.isin(['permno', 'permno2', 'mvel12', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = train[features]\n",
    "y = train[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions = []\n",
    "y_val_list = []\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "\n",
    "numpc_time = {}\n",
    "\n",
    "numpc = np.arange(1, 20, 1).tolist()\n",
    "mse = np.full((len(numpc),1), np.nan, dtype=np.float32)\n",
    "\n",
    "for train_index, val_index  in tscv.split(X, first_split_date= datetime.date(1986,1,31), second_split_date= datetime.date(1988,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "    \n",
    "    for i in range(len(numpc)):\n",
    "        pls_val = PLSRegression(n_components = numpc[i], scale = False)\n",
    "        pls_val.fit(X_train, y_train)\n",
    "        Yval_predict=pls_val.predict(X_val)\n",
    "        Yval_predict = Yval_predict.ravel()\n",
    "        mse[i,0] = np.sqrt(mean_squared_error(y_val, Yval_predict))\n",
    "      \n",
    "    optim_numpc = numpc[np.argmin(mse)]\n",
    "    \n",
    "    pls = PLSRegression(n_components=35, scale = False)\n",
    "    pls.fit(X_train, y_train)\n",
    "    \n",
    "    preds_train = pls.predict(X_train)\n",
    "    preds_val = pls.predict(X_val)\n",
    "    predictions.append(preds_val)\n",
    "    y_val_list.append(y_val)\n",
    "\n",
    "    dates.append(y_val.index)\n",
    "\n",
    "    r2_train = 1-np.sum(pow(y_train-preds_train,2))/np.sum(pow(y_train,2))\n",
    "    r2_val = 1-np.sum(pow(y_val-preds_val,2))/np.sum(pow(y_val,2))\n",
    "    dic_r2_all[\"r2.\" + str(y_val.index)] = r2_val\n",
    "\n",
    "\n",
    "predictions_all_full = np.concatenate(predictions, axis=0)\n",
    "y_test_list_all_full = np.concatenate(y_val_list, axis=0)\n",
    "dates_all_full = np.concatenate(dates, axis=0)\n",
    "\n",
    "R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "print(\"R2OOS Huber Regression: \", R2FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 121078 ,# val records 46299 , # test records 18787\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 120082 ,# val records 39763 , # test records 20259\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 119083 ,# val records 39046 , # test records 19940\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 113784 ,# val records 40199 , # test records 19738\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 109858 ,# val records 39678 , # test records 22032\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 105285 ,# val records 41770 , # test records 20737\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 99700 ,# val records 42769 , # test records 18780\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 100756 ,# val records 39517 , # test records 20445\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 102706 ,# val records 39225 , # test records 20630\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 101227 ,# val records 41075 , # test records 20674\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 101732 ,# val records 41304 , # test records 22724\n",
      "0.13533430572155447\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df_large[features]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "numpc_time = {}\n",
    "\n",
    "numpc = np.arange(1, 20, 1).tolist()\n",
    "mse = np.full((len(numpc),1), np.nan, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(2008,1,31), second_split_date= datetime.date(2010,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "    \n",
    "    # for i in range(len(numpc)):\n",
    "    #     pls_val = PLSRegression(n_components = numpc[i], scale = False)\n",
    "    #     pls_val.fit(X_train, y_train)\n",
    "    #     Yval_predict=pls_val.predict(X_val)\n",
    "    #     Yval_predict = Yval_predict.ravel()\n",
    "    #     mse[i,0] = np.sqrt(mean_squared_error(y_val, Yval_predict))\n",
    "       \n",
    "       \n",
    "      \n",
    "    # optim_numpc = numpc[np.argmin(mse)]\n",
    "    \n",
    "    pls = PLSRegression(n_components=35, scale = False)\n",
    "    pls.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "\n",
    "    pls.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = pls.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "    \n",
    "    y_pred_val = pls.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = pls.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "r2_val_large = np.mean(y_val_list)\n",
    "print(r2_val_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 121078 ,# val records 46299 , # test records 18787\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 120082 ,# val records 39763 , # test records 20259\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 119083 ,# val records 39046 , # test records 19940\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 113784 ,# val records 40199 , # test records 19738\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 109858 ,# val records 39678 , # test records 22032\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 105285 ,# val records 41770 , # test records 20737\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 99700 ,# val records 42769 , # test records 18780\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 100756 ,# val records 39517 , # test records 20445\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 102706 ,# val records 39225 , # test records 20630\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 101227 ,# val records 41075 , # test records 20674\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 101732 ,# val records 41304 , # test records 22724\n",
      "0.014686458473153115\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df_small[features]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "numpc_time = {}\n",
    "\n",
    "numpc = np.arange(1, 20, 1).tolist()\n",
    "mse = np.full((len(numpc),1), np.nan, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(2008,1,31), second_split_date= datetime.date(2010,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "    \n",
    "    # for i in range(len(numpc)):\n",
    "    #     pls_val = PLSRegression(n_components = numpc[i], scale = False)\n",
    "    #     pls_val.fit(X_train, y_train)\n",
    "    #     Yval_predict=pls_val.predict(X_val)\n",
    "    #     Yval_predict = Yval_predict.ravel()\n",
    "    #     mse[i,0] = np.sqrt(mean_squared_error(y_val, Yval_predict))\n",
    "       \n",
    "       \n",
    "      \n",
    "    # optim_numpc = numpc[np.argmin(mse)]\n",
    "    \n",
    "    pls = PLSRegression(n_components=35, scale = False)\n",
    "    pls.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "\n",
    "    pls.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = pls.predict(X_train)\n",
    "    y_train_list.append(r2_score(y_train, y_pred_train))\n",
    "    \n",
    "    y_pred_val = pls.predict(X_val)\n",
    "    y_val_list.append(r2_score(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = pls.predict(X_test)\n",
    "    y_test_list.append(r2_score(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "r2_val_small = np.mean(y_val_list)\n",
    "print(r2_val_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLS Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Sample</th>\n",
       "      <td>0.054138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Large Firms</th>\n",
       "      <td>0.135334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Small Firms</th>\n",
       "      <td>0.014686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLS Regression\n",
       "Full Sample        0.054138\n",
       "Large Firms        0.135334\n",
       "Small Firms        0.014686"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = np.array([[r2_val_full],\n",
    "                  [r2_val_large ],\n",
    "                  [r2_val_small]])\n",
    "\n",
    "r2_lm = pd.DataFrame(chart, columns=['PLS Regression'],\n",
    "                     index=['Full Sample', 'Large Firms', 'Small Firms'])\n",
    "\n",
    "r2_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lm.to_csv(r'r2_PLSReg_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
