{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('factors_2002.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546907   \n",
      "1   10401 1965-02-26  35392058.00  0.780829  0.609694 -0.063768  12.240330   \n",
      "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
      "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
      "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240330   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
      "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
      "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
      "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
      "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "\n",
      "   macro_smb  \n",
      "0       3.55  \n",
      "1       3.55  \n",
      "2       3.55  \n",
      "3       3.55  \n",
      "4       3.55  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "      <th>macro_hml</th>\n",
       "      <th>macro_smb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10145</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1498872.00</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>11.546906</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10401</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>35392056.00</td>\n",
       "      <td>0.780829</td>\n",
       "      <td>0.609694</td>\n",
       "      <td>-0.063768</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10786</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1695284.75</td>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.649827</td>\n",
       "      <td>-0.130519</td>\n",
       "      <td>12.005040</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10989</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1295887.75</td>\n",
       "      <td>1.199748</td>\n",
       "      <td>1.439395</td>\n",
       "      <td>0.073609</td>\n",
       "      <td>11.756961</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11260</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>2302001.25</td>\n",
       "      <td>1.257269</td>\n",
       "      <td>1.580725</td>\n",
       "      <td>-0.167320</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.185424</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546906   \n",
       "1   10401 1965-02-26  35392056.00  0.780829  0.609694 -0.063768  12.240331   \n",
       "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
       "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
       "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240331   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
       "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
       "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
       "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
       "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
       "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
       "\n",
       "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
       "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "\n",
       "   macro_smb  \n",
       "0       3.55  \n",
       "1       3.55  \n",
       "2       3.55  \n",
       "3       3.55  \n",
       "4       3.55  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "\n",
    "df['mvel12'] = df['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "df[features]= 2*df[features] -1\n",
    "\n",
    "df_large[features]=df_large.groupby(\"DATE\")[features].rank(pct=True)\n",
    "df_large[features]= 2*df_large[features] -1\n",
    "\n",
    "df_small[features]=df_small.groupby(\"DATE\")[features].rank(pct=True)\n",
    "df_small[features]= 2*df_small[features] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss_error(y_true, y_pred, delta=1.35):\n",
    "    res = []\n",
    "    for i in zip(y_true, y_pred):\n",
    "        if abs(i[0]-i[1])<=delta:\n",
    "            res.append(0.5*((i[0]-i[1])**2))\n",
    "        else:\n",
    "            res.append(delta*((abs(i[0]-i[1]) )-0.5*(delta**2)))\n",
    "    return np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 13670 ,# val records 3499 , # test records 1941\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 14434 ,# val records 3708 , # test records 2030\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 15118 ,# val records 3971 , # test records 2358\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 15843 ,# val records 4388 , # test records 3334\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 16573 ,# val records 5692 , # test records 3578\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 17432 ,# val records 6912 , # test records 2893\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 19634 ,# val records 6471 , # test records 4416\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 21888 ,# val records 7309 , # test records 4368\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 23087 ,# val records 8784 , # test records 4870\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 25581 ,# val records 9238 , # test records 6416\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 28417 ,# val records 11286 , # test records 6641\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 31555 ,# val records 13057 , # test records 5931\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 36204 ,# val records 12572 , # test records 6850\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 40904 ,# val records 12781 , # test records 6553\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 44805 ,# val records 13403 , # test records 7063\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 49297 ,# val records 13616 , # test records 8743\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 52516 ,# val records 15806 , # test records 8628\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 56001 ,# val records 17371 , # test records 10193\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 61851 ,# val records 18821 , # test records 11176\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 66063 ,# val records 21369 , # test records 12945\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 71888 ,# val records 24121 , # test records 16010\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 78194 ,# val records 28955 , # test records 15949\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 84723 ,# val records 31959 , # test records 14847\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 94092 ,# val records 30796 , # test records 18389\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 104110 ,# val records 33236 , # test records 16233\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 112107 ,# val records 34622 , # test records 15449\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 123943 ,# val records 31682 , # test records 17642\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 133113 ,# val records 33091 , # test records 17980\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 139819 ,# val records 35622 , # test records 21590\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 148833 ,# val records 39570 , # test records 23521\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 156620 ,# val records 45111 , # test records 24470\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 167034 ,# val records 47991 , # test records 21949\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 177610 ,# val records 46419 , # test records 16767\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 186070 ,# val records 38716 , # test records 18170\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 192070 ,# val records 34937 , # test records 21578\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 193990 ,# val records 39748 , # test records 21516\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 193771 ,# val records 43094 , # test records 23877\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 199116 ,# val records 45393 , # test records 28640\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 205183 ,# val records 52517 , # test records 26461\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 211418 ,# val records 55101 , # test records 23187\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 222078 ,# val records 49648 , # test records 27102\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 226949 ,# val records 50289 , # test records 28421\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 226615 ,# val records 55523 , # test records 27271\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 229247 ,# val records 55692 , # test records 29168\n",
      "-------\n",
      "R2 1971-05-28 - 1970-12-31 training set 0.3982237613274271\n",
      "R2 1977-01-31 - 1977-12-30 validation set 0.5402560142809175\n",
      "-------\n",
      "R2 1975-12-31 - 1970-03-31 training set 0.35326393732366135\n",
      "R2 1978-01-31 - 1978-12-29 validation set 0.4879912378193869\n",
      "-------\n",
      "R2 1971-09-30 - 1967-10-31 training set 0.3504149308660276\n",
      "R2 1979-01-31 - 1979-12-31 validation set 0.6099396609710944\n",
      "-------\n",
      "R2 1969-12-31 - 1971-02-26 training set 0.40718067720733975\n",
      "R2 1980-01-31 - 1981-01-30 validation set 0.49173312029473026\n",
      "-------\n",
      "R2 1976-02-27 - 1976-02-27 training set 0.4517000544928571\n",
      "R2 1981-02-27 - 1982-01-29 validation set 0.7299480509384109\n",
      "-------\n",
      "R2 1973-12-31 - 1977-03-31 training set 0.5094230138690381\n",
      "R2 1982-02-26 - 1982-12-31 validation set 0.29930870512495733\n",
      "-------\n",
      "R2 1975-11-28 - 1973-11-30 training set 0.49705308223689115\n",
      "R2 1983-01-31 - 1983-12-30 validation set 0.43468040776983896\n",
      "-------\n",
      "R2 1976-03-31 - 1980-05-30 training set 0.556540836172753\n",
      "R2 1984-01-31 - 1984-12-31 validation set 0.5549440360459514\n",
      "-------\n",
      "R2 1974-10-31 - 1980-02-29 training set 0.5602058024683831\n",
      "R2 1985-01-31 - 1985-12-31 validation set 0.048485986646515156\n",
      "-------\n",
      "R2 1980-07-31 - 1980-02-29 training set 0.5225664307218871\n",
      "R2 1986-01-31 - 1987-01-30 validation set -0.055838755219900005\n",
      "-------\n",
      "R2 1980-10-31 - 1975-08-29 training set 0.5337878006216326\n",
      "R2 1987-02-27 - 1988-01-29 validation set 0.24852250969288736\n",
      "-------\n",
      "R2 1978-07-31 - 1982-11-30 training set 0.5860803949486303\n",
      "R2 1988-02-29 - 1988-12-30 validation set 0.32288528346978795\n",
      "-------\n",
      "R2 1977-06-30 - 1983-05-31 training set 0.4677967686875474\n",
      "R2 1989-01-31 - 1989-12-29 validation set 0.45321350072178335\n",
      "-------\n",
      "R2 1982-09-30 - 1982-07-30 training set 0.4542040549788374\n",
      "R2 1990-01-31 - 1990-12-31 validation set 0.4222382684279965\n",
      "-------\n",
      "R2 1987-05-29 - 1984-04-30 training set 0.4650410903324623\n",
      "R2 1991-01-31 - 1991-12-31 validation set -0.44242575774801307\n",
      "-------\n",
      "R2 1985-05-31 - 1988-08-31 training set 0.4181976735999726\n",
      "R2 1992-01-31 - 1993-01-29 validation set -0.08773188661035047\n",
      "-------\n",
      "R2 1985-10-31 - 1986-02-28 training set 0.420921176449214\n",
      "R2 1993-02-26 - 1993-12-31 validation set -0.03497104093538361\n",
      "-------\n",
      "R2 1991-07-31 - 1984-10-31 training set 0.3519557911712736\n",
      "R2 1994-01-31 - 1994-12-30 validation set 0.23671632699340506\n",
      "-------\n",
      "R2 1993-01-29 - 1987-12-31 training set 0.3241218751073005\n",
      "R2 1995-01-31 - 1995-12-29 validation set 0.12174167718799989\n",
      "-------\n",
      "R2 1985-12-31 - 1992-09-30 training set 0.2790577277351587\n",
      "R2 1996-01-31 - 1996-12-31 validation set 0.14569398974452874\n",
      "-------\n",
      "R2 1992-01-31 - 1993-05-28 training set 0.2631667247950358\n",
      "R2 1997-01-31 - 1998-01-30 validation set 0.11895709181688408\n",
      "-------\n",
      "R2 1990-03-30 - 1992-02-28 training set 0.3060322435558124\n",
      "R2 1998-02-27 - 1999-01-29 validation set 0.10111791219595911\n",
      "-------\n",
      "R2 1991-09-30 - 1994-02-28 training set 0.2644889124982731\n",
      "R2 1999-02-26 - 1999-12-31 validation set 0.04760120529802858\n",
      "-------\n",
      "R2 1988-09-30 - 1997-01-31 training set 0.2377643560656315\n",
      "R2 2000-01-31 - 2000-12-29 validation set 0.08371360953224549\n",
      "-------\n",
      "R2 1998-11-30 - 1997-04-30 training set 0.20587944281191506\n",
      "R2 2001-01-31 - 2001-12-31 validation set 0.08222768116557211\n",
      "-------\n",
      "R2 1993-02-26 - 1998-05-29 training set 0.15788844557344162\n",
      "R2 2002-01-31 - 2002-12-31 validation set 0.0885737821173781\n",
      "-------\n",
      "R2 1996-06-28 - 1998-07-31 training set 0.1380077085658512\n",
      "R2 2003-01-31 - 2004-01-30 validation set -0.38689076438173386\n",
      "-------\n",
      "R2 1995-04-28 - 1995-07-31 training set 0.22479790821310408\n",
      "R2 2004-02-27 - 2004-12-31 validation set -0.3275714406673933\n",
      "-------\n",
      "R2 2000-04-28 - 1998-05-29 training set 0.1263861840841798\n",
      "R2 2005-01-31 - 2005-12-30 validation set 0.06816830126823115\n",
      "-------\n",
      "R2 2003-08-29 - 2003-09-30 training set 0.12546474374696304\n",
      "R2 2006-01-31 - 2006-12-29 validation set 0.15355546003883347\n",
      "-------\n",
      "R2 1995-05-31 - 2004-09-30 training set 0.11506814168145163\n",
      "R2 2007-01-31 - 2007-12-31 validation set 0.1702121295468536\n",
      "-------\n",
      "R2 2003-01-31 - 1996-11-29 training set 0.12719419734260107\n",
      "R2 2008-01-31 - 2009-01-30 validation set 0.15552091222260112\n",
      "-------\n",
      "R2 1997-11-28 - 2005-08-31 training set 0.1062991529890559\n",
      "R2 2009-02-27 - 2010-01-29 validation set -0.29267236358560744\n",
      "-------\n",
      "R2 2006-08-31 - 2006-04-28 training set 0.14827264375424343\n",
      "R2 2010-02-26 - 2010-12-31 validation set -0.17667901381876172\n",
      "-------\n",
      "R2 2000-03-31 - 2008-07-31 training set 0.1657099276647075\n",
      "R2 2011-01-31 - 2011-12-30 validation set -0.08479872920789222\n",
      "-------\n",
      "R2 2004-02-27 - 2000-10-31 training set 0.08647638033461591\n",
      "R2 2012-01-31 - 2012-12-31 validation set -0.1497586656741552\n",
      "-------\n",
      "R2 2002-11-29 - 2009-01-30 training set 0.0955372540572107\n",
      "R2 2013-01-31 - 2013-12-31 validation set -0.2728410750673451\n",
      "-------\n",
      "R2 2005-02-28 - 2009-04-30 training set 0.0622301628708396\n",
      "R2 2014-01-31 - 2015-01-30 validation set -0.0038523226245934516\n",
      "-------\n",
      "R2 2009-10-30 - 2011-05-31 training set 0.05958500602572203\n",
      "R2 2015-02-27 - 2016-01-29 validation set 0.007681710682224563\n",
      "-------\n",
      "R2 2013-08-30 - 2008-06-30 training set 0.17668262149512204\n",
      "R2 2016-02-29 - 2016-12-30 validation set -0.1720612476518839\n",
      "-------\n",
      "R2 2011-02-28 - 2012-10-31 training set 0.07920793663859305\n",
      "R2 2017-01-31 - 2017-12-29 validation set -0.002582610255607465\n",
      "-------\n",
      "R2 2007-12-31 - 2009-07-31 training set 0.07515168434165409\n",
      "R2 2018-01-31 - 2018-12-31 validation set 0.006975961713844292\n",
      "-------\n",
      "R2 2008-01-31 - 2008-07-31 training set 0.13253815127894808\n",
      "R2 2019-01-31 - 2019-12-31 validation set -0.07602057024961084\n",
      "-------\n",
      "R2 2009-11-30 - 2010-09-30 training set 0.11694223225051725\n",
      "R2 2020-01-31 - 2021-01-29 validation set -0.09023377156207246\n",
      "R2OOS gradient boosted regression tree:  0.00205670715874251\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val = []\n",
    "y_val_list =[]\n",
    "r2_list = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "dic_max_depth_all = {}\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              }\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.8, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.8, replace=False, random_state=42)\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            n_iter_no_change=3,\n",
    "                                            tol=0.01,\n",
    "                                            validation_fraction=0.2)\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    n_iter_no_change=3,\n",
    "                                    tol=0.01)\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 {y_train.index[0][0].date()} - {y_train.index[-1][0].date()} training set {r2_train}')\n",
    "    \n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "\n",
    "    print(f'R2 {y_test.index[0][0].date()} - {y_test.index[-1][0].date()} validation set {r2}')\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "    dic_max_depth_all[\"feat.\" + str(y_test.index)]= optim_param[\"max_depth\"]\n",
    "\n",
    "    \n",
    "    \n",
    "predictions_all= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "#Calculate OOS model performance over the entire test period in line with Gu et al (2020)\n",
    "R2OOS_GBR = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/R200S_GBR', 'wb') as f:\n",
    "    pickle.dump(R2OOS_GBR, f)\n",
    "\n",
    "with open('pickles/predictions', 'wb') as f:\n",
    "    pickle.dump(predictions_all, f)\n",
    "\n",
    "with open('pickles/y_test_list_all', 'wb') as f:\n",
    "    pickle.dump(y_test_list_all, f)\n",
    "\n",
    "with open('pickles/dates_all', 'wb') as f:\n",
    "    pickle.dump(dates_all, f)\n",
    "\n",
    "with open('pickles/dic_max_depth_all', 'wb') as f:\n",
    "    pickle.dump(dic_max_depth_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 4042 ,# val records 1040 , # test records 577\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 4271 ,# val records 1103 , # test records 603\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 4478 ,# val records 1180 , # test records 704\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 4696 ,# val records 1307 , # test records 995\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 4915 ,# val records 1699 , # test records 1068\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 5175 ,# val records 2063 , # test records 862\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 5835 ,# val records 1930 , # test records 1320\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 6510 ,# val records 2182 , # test records 1304\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 6871 ,# val records 2624 , # test records 1458\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 7622 ,# val records 2762 , # test records 1919\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 8473 ,# val records 3377 , # test records 1987\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 9417 ,# val records 3906 , # test records 1777\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 10810 ,# val records 3764 , # test records 2049\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 12220 ,# val records 3826 , # test records 1959\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 13394 ,# val records 4008 , # test records 2113\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 14739 ,# val records 4072 , # test records 2619\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 15703 ,# val records 4732 , # test records 2583\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 16748 ,# val records 5202 , # test records 3051\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 18505 ,# val records 5634 , # test records 3348\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 19768 ,# val records 6399 , # test records 3879\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 21515 ,# val records 7227 , # test records 4797\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 23405 ,# val records 8676 , # test records 4780\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 25365 ,# val records 9577 , # test records 4451\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 28175 ,# val records 9231 , # test records 5511\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 31178 ,# val records 9962 , # test records 4865\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 33580 ,# val records 10376 , # test records 4631\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 37132 ,# val records 9496 , # test records 5287\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 39884 ,# val records 9918 , # test records 5390\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 41896 ,# val records 10677 , # test records 6472\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 44600 ,# val records 11862 , # test records 7051\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 46939 ,# val records 13523 , # test records 7335\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 50063 ,# val records 14386 , # test records 6578\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 53235 ,# val records 13913 , # test records 5023\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 55773 ,# val records 11601 , # test records 5446\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 57571 ,# val records 10469 , # test records 6469\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 58143 ,# val records 11915 , # test records 6450\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 58078 ,# val records 12919 , # test records 7158\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 59682 ,# val records 13608 , # test records 8585\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 61501 ,# val records 15743 , # test records 7934\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 63372 ,# val records 16519 , # test records 6952\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 66567 ,# val records 14886 , # test records 8126\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 68029 ,# val records 15078 , # test records 8521\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 67930 ,# val records 16647 , # test records 8175\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 68721 ,# val records 16696 , # test records 8745\n",
      "-------\n",
      "R2 training set 0.44248558732247323\n",
      "R2 validation set 0.6045918563629227\n",
      "-------\n",
      "R2 training set 0.3843124741065659\n",
      "R2 validation set 0.5106142544560531\n",
      "-------\n",
      "R2 training set 0.42099380310068846\n",
      "R2 validation set 0.621076152815722\n",
      "-------\n",
      "R2 training set 0.5213249104319002\n",
      "R2 validation set 0.4805882217910451\n",
      "-------\n",
      "R2 training set 0.44574969607175075\n",
      "R2 validation set 0.718573674331959\n",
      "-------\n",
      "R2 training set 0.5127001842695479\n",
      "R2 validation set 0.4929797723782603\n",
      "-------\n",
      "R2 training set 0.5151608881219514\n",
      "R2 validation set 0.4103873138855093\n",
      "-------\n",
      "R2 training set 0.5608586188659912\n",
      "R2 validation set 0.6228362443066153\n",
      "-------\n",
      "R2 training set 0.624986895665004\n",
      "R2 validation set 0.10026683669677461\n",
      "-------\n",
      "R2 training set 0.5663748462467936\n",
      "R2 validation set 0.005061870026246695\n",
      "-------\n",
      "R2 training set 0.5654056514392501\n",
      "R2 validation set 0.3105079557430914\n",
      "-------\n",
      "R2 training set 0.6084671354869926\n",
      "R2 validation set 0.5352178976208989\n",
      "-------\n",
      "R2 training set 0.5383665329956395\n",
      "R2 validation set 0.4680814482523262\n",
      "-------\n",
      "R2 training set 0.4967941188935353\n",
      "R2 validation set 0.5123833253746956\n",
      "-------\n",
      "R2 training set 0.4883771841610296\n",
      "R2 validation set -0.0740711794942801\n",
      "-------\n",
      "R2 training set 0.44740038926060277\n",
      "R2 validation set -0.03778067733229418\n",
      "-------\n",
      "R2 training set 0.5569746654465677\n",
      "R2 validation set -0.0005695965962029259\n",
      "-------\n",
      "R2 training set 0.43846728105151067\n",
      "R2 validation set 0.2977649905894426\n",
      "-------\n",
      "R2 training set 0.389636646584988\n",
      "R2 validation set 0.09614983876375371\n",
      "-------\n",
      "R2 training set 0.36676456862398155\n",
      "R2 validation set 0.18778838954866817\n",
      "-------\n",
      "R2 training set 0.30140166238213806\n",
      "R2 validation set 0.09560390966004217\n",
      "-------\n",
      "R2 training set 0.37796993148305835\n",
      "R2 validation set 0.06907829716111336\n",
      "-------\n",
      "R2 training set 0.2841727011584383\n",
      "R2 validation set 0.07040350511065463\n",
      "-------\n",
      "R2 training set 0.2662758072644641\n",
      "R2 validation set 0.12390910265168797\n",
      "-------\n",
      "R2 training set 0.21475625466864667\n",
      "R2 validation set 0.13695648538221605\n",
      "-------\n",
      "R2 training set 0.18547659715703113\n",
      "R2 validation set 0.09986795080096578\n",
      "-------\n",
      "R2 training set 0.1718389966935676\n",
      "R2 validation set -0.635182978503898\n",
      "-------\n",
      "R2 training set 0.14452283654664788\n",
      "R2 validation set -0.23397725231147848\n",
      "-------\n",
      "R2 training set 0.13753258563219573\n",
      "R2 validation set 0.0977288285307697\n",
      "-------\n",
      "R2 training set 0.1282932908329274\n",
      "R2 validation set 0.1926189403890819\n",
      "-------\n",
      "R2 training set 0.08956754474053863\n",
      "R2 validation set 0.18323125302520427\n",
      "-------\n",
      "R2 training set 0.13765536099767384\n",
      "R2 validation set 0.15719001899154394\n",
      "-------\n",
      "R2 training set 0.14216641046226441\n",
      "R2 validation set -0.22366977314390368\n",
      "-------\n",
      "R2 training set 0.16369035157476042\n",
      "R2 validation set -0.22137822896473835\n",
      "-------\n",
      "R2 training set 0.27205192294566083\n",
      "R2 validation set -0.29194903081541623\n",
      "-------\n",
      "R2 training set 0.15179689684549602\n",
      "R2 validation set -0.08725623359035262\n",
      "-------\n",
      "R2 training set 0.14297618394978606\n",
      "R2 validation set -0.3547320337240334\n",
      "-------\n",
      "R2 training set 0.14232144666495283\n",
      "R2 validation set -0.012663213931354944\n",
      "-------\n",
      "R2 training set 0.24194847842976863\n",
      "R2 validation set -0.015565995273935762\n",
      "-------\n",
      "R2 training set 0.14477501704349383\n",
      "R2 validation set -0.133438412776977\n",
      "-------\n",
      "R2 training set 0.05081740209024055\n",
      "R2 validation set -0.028954999871475096\n",
      "-------\n",
      "R2 training set 0.044267253736056666\n",
      "R2 validation set 0.020592900478007437\n",
      "-------\n",
      "R2 training set 0.16370209071622088\n",
      "R2 validation set -0.010423287420857852\n",
      "-------\n",
      "R2 training set 0.11540063936811629\n",
      "R2 validation set -0.0016365315661019952\n",
      "R2OOS gradient boosted regression tree:  0.00205670715874251\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "\n",
    "X = df_large[features]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val_top = []\n",
    "y_val_list =[]\n",
    "r2_list_top = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions_top = []\n",
    "y_test_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_all_top = {}\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              \"max_features\": [\"sqrt\"]\n",
    "              }\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "\n",
    "    X_test  = X.loc[test_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_test  = y.loc[test_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=10, random_state=42)\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=10, random_state=42)\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list_top.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 training set {r2_train}')\n",
    "    \n",
    "    predictions_top.append(preds)\n",
    "    dates_top.append(y_test.index)\n",
    "    y_test_list_top.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 validation set {r2}')\n",
    "    \n",
    "predictions_all_top = np.concatenate(predictions_top, axis=0)\n",
    "y_test_list_all_top = np.concatenate(y_test_list_top, axis=0) \n",
    "dates_all= np.concatenate(dates_top, axis=0)\n",
    "\n",
    "R2OOS_GBR_Top = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR_Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/R200S_GBR_Top', 'wb') as f:\n",
    "    pickle.dump(R2OOS_GBR_Top, f)\n",
    "\n",
    "with open('pickles/predictions_top', 'wb') as f:\n",
    "    pickle.dump(predictions_all_top, f)\n",
    "\n",
    "with open('pickles/y_test_list_all_top', 'wb') as f:\n",
    "    pickle.dump(y_test_list_all_top, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 4042 ,# val records 1040 , # test records 577\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 4271 ,# val records 1103 , # test records 603\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 4478 ,# val records 1180 , # test records 704\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 4696 ,# val records 1307 , # test records 995\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 4915 ,# val records 1699 , # test records 1068\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 5175 ,# val records 2063 , # test records 862\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 5835 ,# val records 1930 , # test records 1320\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 6510 ,# val records 2182 , # test records 1304\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 6871 ,# val records 2624 , # test records 1458\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 7622 ,# val records 2762 , # test records 1919\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 8473 ,# val records 3377 , # test records 1987\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 9417 ,# val records 3906 , # test records 1777\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 10810 ,# val records 3764 , # test records 2049\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 12220 ,# val records 3826 , # test records 1959\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 13394 ,# val records 4008 , # test records 2113\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 14739 ,# val records 4072 , # test records 2619\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 15703 ,# val records 4732 , # test records 2583\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 16748 ,# val records 5202 , # test records 3051\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 18505 ,# val records 5634 , # test records 3348\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 19768 ,# val records 6399 , # test records 3879\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 21515 ,# val records 7227 , # test records 4797\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 23405 ,# val records 8676 , # test records 4780\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 25365 ,# val records 9577 , # test records 4451\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 28175 ,# val records 9231 , # test records 5511\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 31178 ,# val records 9962 , # test records 4865\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 33580 ,# val records 10376 , # test records 4631\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 37132 ,# val records 9496 , # test records 5287\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 39884 ,# val records 9918 , # test records 5390\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 41896 ,# val records 10677 , # test records 6472\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 44600 ,# val records 11862 , # test records 7051\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 46939 ,# val records 13523 , # test records 7335\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 50063 ,# val records 14386 , # test records 6578\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 53235 ,# val records 13913 , # test records 5023\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 55773 ,# val records 11601 , # test records 5446\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 57571 ,# val records 10469 , # test records 6469\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 58143 ,# val records 11915 , # test records 6450\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 58078 ,# val records 12919 , # test records 7158\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 59682 ,# val records 13608 , # test records 8585\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 61501 ,# val records 15743 , # test records 7934\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 63372 ,# val records 16519 , # test records 6952\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 66567 ,# val records 14886 , # test records 8126\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 68029 ,# val records 15078 , # test records 8521\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 67930 ,# val records 16647 , # test records 8175\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 68721 ,# val records 16696 , # test records 8745\n",
      "-------\n",
      "R2 training set 0.38647019315535913\n",
      "R2 validation set 0.49598372796308254\n",
      "-------\n",
      "R2 training set 0.3457815234214774\n",
      "R2 validation set 0.45017759638705424\n",
      "-------\n",
      "R2 training set 0.3467076701842825\n",
      "R2 validation set 0.525910878405517\n",
      "-------\n",
      "R2 training set 0.37408204510303233\n",
      "R2 validation set 0.46409206970422046\n",
      "-------\n",
      "R2 training set 0.36599361793009266\n",
      "R2 validation set 0.673862030043332\n",
      "-------\n",
      "R2 training set 0.38344982045530784\n",
      "R2 validation set 0.4988552850606285\n",
      "-------\n",
      "R2 training set 0.4904226086883302\n",
      "R2 validation set 0.36548966707895214\n",
      "-------\n",
      "R2 training set 0.488143685127031\n",
      "R2 validation set 0.5593942132618072\n",
      "-------\n",
      "R2 training set 0.5534864064681546\n",
      "R2 validation set 0.1744753005331392\n",
      "-------\n",
      "R2 training set 0.5033379899442767\n",
      "R2 validation set -0.05388381935027042\n",
      "-------\n",
      "R2 training set 0.516458210462207\n",
      "R2 validation set 0.23171274120111818\n",
      "-------\n",
      "R2 training set 0.5731151925110507\n",
      "R2 validation set 0.3899623676692634\n",
      "-------\n",
      "R2 training set 0.46685030056461796\n",
      "R2 validation set 0.498083477213883\n",
      "-------\n",
      "R2 training set 0.4359363460506912\n",
      "R2 validation set 0.39315991766038505\n",
      "-------\n",
      "R2 training set 0.4147330782556481\n",
      "R2 validation set -0.259768100142318\n",
      "-------\n",
      "R2 training set 0.3956853712664721\n",
      "R2 validation set -0.12819931976670862\n",
      "-------\n",
      "R2 training set 0.4934039438338683\n",
      "R2 validation set 0.0012352503895960432\n",
      "-------\n",
      "R2 training set 0.3797464064975761\n",
      "R2 validation set 0.22440031714625053\n",
      "-------\n",
      "R2 training set 0.28790353215677755\n",
      "R2 validation set 0.09255745593869213\n",
      "-------\n",
      "R2 training set 0.30381083588216207\n",
      "R2 validation set 0.12689265169544284\n",
      "-------\n",
      "R2 training set 0.2272178926043552\n",
      "R2 validation set 0.13957465067567043\n",
      "-------\n",
      "R2 training set 0.2102235158114868\n",
      "R2 validation set 0.11010757135956284\n",
      "-------\n",
      "R2 training set 0.21131335408817542\n",
      "R2 validation set 0.021051221318050595\n",
      "-------\n",
      "R2 training set 0.22386110894490518\n",
      "R2 validation set 0.16028731349483205\n",
      "-------\n",
      "R2 training set 0.17819073813141795\n",
      "R2 validation set 0.06514202853239592\n",
      "-------\n",
      "R2 training set 0.2072408269655972\n",
      "R2 validation set 0.060796205837761685\n",
      "-------\n",
      "R2 training set 0.22388404333298018\n",
      "R2 validation set -0.4870367688889734\n",
      "-------\n",
      "R2 training set 0.14281669755952175\n",
      "R2 validation set -0.3051137685144718\n",
      "-------\n",
      "R2 training set 0.11333834444409063\n",
      "R2 validation set 0.06540464088543718\n",
      "-------\n",
      "R2 training set 0.0831105970926237\n",
      "R2 validation set 0.10995607966397336\n",
      "-------\n",
      "R2 training set 0.07003369663168502\n",
      "R2 validation set 0.17125107717081256\n",
      "-------\n",
      "R2 training set 0.11992540107708805\n",
      "R2 validation set 0.10824086785673193\n",
      "-------\n",
      "R2 training set 0.12317020791622524\n",
      "R2 validation set -0.16704127439661942\n",
      "-------\n",
      "R2 training set 0.13369254552737486\n",
      "R2 validation set -0.07943967253197282\n",
      "-------\n",
      "R2 training set 0.09287978910664263\n",
      "R2 validation set -0.0045096122902603675\n",
      "-------\n",
      "R2 training set 0.14246448729252126\n",
      "R2 validation set -0.11952651940134928\n",
      "-------\n",
      "R2 training set 0.07269826774923316\n",
      "R2 validation set -0.2596891392498015\n",
      "-------\n",
      "R2 training set 0.18084070853900658\n",
      "R2 validation set 0.002300322071749128\n",
      "-------\n",
      "R2 training set 0.04878064616589228\n",
      "R2 validation set 0.010122610694735967\n",
      "-------\n",
      "R2 training set 0.03646911199664926\n",
      "R2 validation set -0.05126981234682404\n",
      "-------\n",
      "R2 training set 0.03268291439422155\n",
      "R2 validation set -0.0077302938782877195\n",
      "-------\n",
      "R2 training set 0.05176429301072005\n",
      "R2 validation set 0.011653187241589591\n",
      "-------\n",
      "R2 training set 0.050475394358487136\n",
      "R2 validation set 0.0015569964747751408\n",
      "-------\n",
      "R2 training set 0.060469039122176604\n",
      "R2 validation set -0.02557896172776153\n",
      "R2OOS gradient boosted regression tree:  0.00205670715874251\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "\n",
    "X = df_small[features]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val_bottom = []\n",
    "y_val_list =[]\n",
    "r2_list_bottom = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions_bottom = []\n",
    "y_test_list_bottom =[]\n",
    "dates_bottom = []\n",
    "dic_r2_all_bottom = {}\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              \"max_features\": [\"sqrt\"]\n",
    "              }\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "\n",
    "    X_test  = X.loc[test_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_test  = y.loc[test_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=3, random_state=42)\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=3, random_state=42)\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list_bottom.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 training set {r2_train}')\n",
    "    \n",
    "    predictions_bottom.append(preds)\n",
    "    dates_bottom.append(y_test.index)\n",
    "    y_test_list_bottom.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 validation set {r2}')\n",
    "    \n",
    "predictions_all_bottom = np.concatenate(predictions, axis=0)\n",
    "y_test_list_all_bottom = np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "R2OOS_GBR_bottom = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [44, 95457]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m R2OOS_GBR_Top \u001b[38;5;241m=\u001b[39m r2_score(y_test_list_top, predictions_all_top)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2OOS gradient boosted regression tree: \u001b[39m\u001b[38;5;124m\"\u001b[39m, R2OOS_GBR_Top)\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1204\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m   1198\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[0;32m   1199\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[0;32m   1200\u001b[0m )\n\u001b[0;32m   1202\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1204\u001b[0m _, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m   1205\u001b[0m     y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m   1206\u001b[0m )\n\u001b[0;32m   1207\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [44, 95457]"
     ]
    }
   ],
   "source": [
    "R2OOS_GBR_Top = r2_score(y_test_list_top, predictions_top)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR_Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02286083808281225\n"
     ]
    }
   ],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium', 'year'])].tolist()\n",
    "df['year'] = df['DATE'].dt.year\n",
    "\n",
    "X_train = df[features].loc[(df[\"year\"]>=2013) & (df[\"year\"]<=2018)]\n",
    "y_train = df[\"risk_premium\"].loc[(df[\"year\"]>=2013) & (df[\"year\"]<=2018)]\n",
    "\n",
    "X_val = df[features].loc[(df[\"year\"]>=2019) & (df[\"year\"]<=2021)]\n",
    "y_val = df[\"risk_premium\"].loc[(df[\"year\"]>=2019) & (df[\"year\"]<=2021)]\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 100], \n",
    "              \"learning_rate\": [0.01, 0.1], \n",
    "              \"max_features\": [\"sqrt\"]}\n",
    "\n",
    "\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(grid)):\n",
    "    GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=3)\n",
    "    \n",
    "    \n",
    "    GBR_val.fit(X_train, y_train)\n",
    "    Ypred_val=GBR_val.predict(X_val)\n",
    "    huber_loss[i,0]= huber_loss_error(y_val,Ypred_val, delta=1.35)\n",
    "\n",
    "optim_param = grid[np.argmin(huber_loss)]\n",
    "GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=3)\n",
    "\n",
    "GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "preds = GBR.predict(np.concatenate((X_train, X_val)))\n",
    "R2OOS_all = 1-sum(pow(np.concatenate((y_train, y_val))-preds,2))/sum(pow(np.concatenate((y_train, y_val)),2))\n",
    "print(R2OOS_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in features:\n",
    "    globals()['df_' + str(j)] =  df.copy()\n",
    "    globals()['df_' + str(j)][str(j)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mvel1\n",
      "beta\n",
      "betasq\n",
      "chmom\n",
      "dolvol\n",
      "idiovol\n",
      "indmom\n",
      "mom1m\n",
      "mom6m\n",
      "mom12m\n",
      "mom36m\n",
      "pricedelay\n",
      "turn\n",
      "absacc\n",
      "acc\n",
      "age\n",
      "agr\n",
      "bm\n",
      "bm_ia\n",
      "cashdebt\n",
      "cashpr\n",
      "cfp\n",
      "cfp_ia\n",
      "chatoia\n",
      "chcsho\n",
      "chempia\n",
      "chinv\n",
      "chpmia\n",
      "convind\n",
      "currat\n",
      "depr\n",
      "divi\n",
      "divo\n",
      "dy\n",
      "egr\n",
      "ep\n",
      "gma\n",
      "grcapx\n",
      "grltnoa\n",
      "herf\n",
      "hire\n",
      "invest\n",
      "lev\n",
      "lgr\n",
      "mve_ia\n",
      "operprof\n",
      "orgcap\n",
      "pchcapx_ia\n",
      "pchcurrat\n",
      "pchdepr\n",
      "pchgm_pchsale\n",
      "pchquick\n",
      "pchsale_pchinvt\n",
      "pchsale_pchrect\n",
      "pchsale_pchxsga\n",
      "pchsaleinv\n",
      "pctacc\n",
      "ps\n",
      "quick\n",
      "rd\n",
      "roic\n",
      "salecash\n",
      "saleinv\n",
      "salerec\n",
      "securedind\n",
      "sgr\n",
      "sin\n",
      "sp\n",
      "tang\n",
      "tb\n",
      "baspread\n",
      "ill\n",
      "maxret\n",
      "retvol\n",
      "std_dolvol\n",
      "std_turn\n",
      "zerotrade\n",
      "macro_dp\n",
      "macro_ep\n",
      "macro_bm\n",
      "macro_ntis\n",
      "macro_tbl\n",
      "macro_tms\n",
      "macro_dfy\n",
      "macro_svar\n",
      "macro_mkt-rf\n",
      "macro_hml\n",
      "macro_smb\n",
      "mvel12\n"
     ]
    }
   ],
   "source": [
    "dic = {}    \n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 100], \n",
    "              \"learning_rate\": [0.01, 0.1], \n",
    "              \"max_features\": [\"sqrt\"]}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "    \n",
    "for j in features:\n",
    "    print(j)\n",
    "    df_var = globals()['df_' + str(j)]\n",
    "    \n",
    "    X_train = df[features].loc[(df[\"year\"]>=2013) & (df[\"year\"]<=2018)]\n",
    "    y_train = df[\"risk_premium\"].loc[(df[\"year\"]>=2013) & (df[\"year\"]<=2018)]\n",
    "\n",
    "    X_val = df[features].loc[(df[\"year\"]>=2019) & (df[\"year\"]<=2021)]\n",
    "    y_val = df[\"risk_premium\"].loc[(df[\"year\"]>=2019) & (df[\"year\"]<=2021)]\n",
    " \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=3)\n",
    "\n",
    "\n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Ypred_val=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val,Ypred_val, delta=1.35)\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=3)\n",
    "\n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = GBR.predict(np.concatenate((X_train, X_val)))\n",
    "    R2OOS_var = 1-sum(pow(np.concatenate((y_train, y_val))-preds,2))/sum(pow(np.concatenate((y_train, y_val)),2))\n",
    "    dic['R2OOS_' + str(j)] = R2OOS_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>R2OOS</th>\n",
       "      <th>red_R2OOS</th>\n",
       "      <th>var_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tb</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>-0.001450</td>\n",
       "      <td>0.162158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>grcapx</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.104990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>maxret</td>\n",
       "      <td>0.023783</td>\n",
       "      <td>-0.000922</td>\n",
       "      <td>0.103126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>convind</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>0.097986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ep</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>0.096516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.022110</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.083999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>quick</td>\n",
       "      <td>0.021983</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-0.098142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beta</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>-0.100459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chcsho</td>\n",
       "      <td>0.021557</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>-0.145855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chatoia</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>-0.159005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature     R2OOS  red_R2OOS   var_imp\n",
       "69       tb  0.024311  -0.001450  0.162158\n",
       "37   grcapx  0.023800  -0.000939  0.104990\n",
       "72   maxret  0.023783  -0.000922  0.103126\n",
       "28  convind  0.023737  -0.000876  0.097986\n",
       "35       ep  0.023724  -0.000863  0.096516\n",
       "..      ...       ...        ...       ...\n",
       "14      acc  0.022110   0.000751 -0.083999\n",
       "58    quick  0.021983   0.000878 -0.098142\n",
       "1      beta  0.021963   0.000898 -0.100459\n",
       "24   chcsho  0.021557   0.001304 -0.145855\n",
       "23  chatoia  0.021439   0.001422 -0.159005\n",
       "\n",
       "[89 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic.items())\n",
    "imp=pd.DataFrame(dic.items(), columns=['Feature', 'R2OOS'])\n",
    "imp[\"Feature\"] = imp[\"Feature\"].str[6:]\n",
    "\n",
    "imp[\"red_R2OOS\"] = R2OOS_all -imp[\"R2OOS\"]\n",
    "imp[\"var_imp\"] = imp[\"red_R2OOS\"]/sum(imp[\"red_R2OOS\"])\n",
    "imp=imp.sort_values(by = ['var_imp'], ascending = False)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fea_imp_graph = imp.sort_values(['var_imp', 'Feature'], ascending=[True, False]).iloc[-20:]\n",
    "_ = fea_imp_graph.plot(kind='barh', x='Feature', y='var_imp', figsize=(20, 10))\n",
    "plt.title('GBRT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_net=imp[[\"Feature\", \"var_imp\"]]\n",
    "var_imp_net.to_csv(r'var_imp_GBRT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predictions_all.tolist()\n",
    "y_true = y_test_list_all.tolist()\n",
    "i = dates_all.tolist()\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'identifier': i,\n",
    "     'yhat': yhat,\n",
    "     'y_true': y_true\n",
    "    })\n",
    "\n",
    "results[\"identifier\"]= results[\"identifier\"].astype(\"str\")\n",
    "results[\"date\"] = results[\"identifier\"].str[12:22]\n",
    "results[\"id\"] = results[\"identifier\"].str[35:40]\n",
    "results.drop([\"identifier\"],axis = 1, inplace=True)\n",
    "results['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n",
    "results['MonthYear'] = results['date'].dt.to_period('M')\n",
    "results = results.sort_values(by = ['date', 'id'], ascending = True)\n",
    "results = results.set_index(['MonthYear','id'])\n",
    "results\n",
    "\n",
    "# results['yhat'] = results['yhat'].apply(lambda x: x[0])\n",
    "results['y_true'] = results['y_true'].apply(lambda x: x[0])\n",
    "\n",
    "data = df[['mvel12', 'macro_tbl', 'macro_svar']].copy()\n",
    "data.reset_index(inplace=True)\n",
    "data['permno2'] = data['permno2'].astype('str')\n",
    "data['MonthYear'] = data['DATE2'].dt.to_period('M')\n",
    "data.drop('DATE2', axis=1, inplace=True)\n",
    "data.rename(columns={'permno2': 'id'}, inplace=True)\n",
    "data.rename(columns={'mvel12': 'market_cap'}, inplace=True)\n",
    "data.rename(columns={'macro_tbl': 'risk_free_rate'}, inplace=True)\n",
    "data = data.set_index(['MonthYear','id'])\n",
    "\n",
    "bigdata = pd.merge(results, data,left_index=True, right_index=True)\n",
    "bigdata.reset_index(inplace=True)\n",
    "bigdata\n",
    "bigdata['returns'] = bigdata['y_true'] + bigdata['risk_free_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "       508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n",
       "       521, 522, 523, 524, 525, 526, 527, 528, 529], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata['MonthYear1'] = bigdata['MonthYear'].copy()\n",
    "bigdata['MonthYear'] = bigdata['MonthYear'].astype('int64')\n",
    "bigdata['NumMonth'] = bigdata['MonthYear'] - 83\n",
    "bigdata['NumMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata.to_csv('predictions/GBR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bigdata = pd.read_csv('predictions/GBR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = bigdata.sort_values(['NumMonth','yhat'], ascending=[True, True]).groupby(['MonthYear'],\n",
    "                                                                  as_index=False,\n",
    "                                                                  sort=False).tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = top_100[['date', 'NumMonth','MonthYear', 'id', 'yhat', 'y_true', 'risk_free_rate', 'MonthYear1']]\n",
    "portfolio.reset_index(inplace=True)\n",
    "portfolio.drop(columns=['index'],inplace=True)\n",
    "portfolio['eq_weights'] = 1/portfolio.groupby('MonthYear')['id'].transform('size')\n",
    "portfolio['excess_return_stock_ew'] = portfolio['y_true'] *portfolio['eq_weights']\n",
    "portfolio['pred_excess_return_stock_ew'] = portfolio[\"yhat\"]*portfolio[\"eq_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred_return = portfolio.groupby('MonthYear')['pred_excess_return_stock_ew'].transform('sum').mean()\n",
    "mean_port_return = portfolio.groupby('MonthYear')['excess_return_stock_ew'].transform('sum').mean()\n",
    "port_vol =  portfolio.groupby('MonthYear')[\"pred_excess_return_stock_ew\"].transform('sum').std()\n",
    "sharp_ratio = (mean_pred_return/port_vol)*np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS Regression</th>\n",
       "      <td>-3.57%</td>\n",
       "      <td>-4.38%</td>\n",
       "      <td>3.64%</td>\n",
       "      <td>-4.17%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Real    Pred    Std  Sharpe\n",
       "PLS Regression  -3.57%  -4.38%  3.64%  -4.17%"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_np = np.array([[mean_port_return, mean_pred_return, port_vol, sharp_ratio]])\n",
    "\n",
    "ew_df = pd.DataFrame(chart_np, columns=['Real', 'Pred', 'Std', 'Sharpe'],\n",
    "                                index=['PLS Regression'])\n",
    "\n",
    "ew_df['Real'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Real']], index= ew_df.index)\n",
    "ew_df['Pred'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Pred']], index= ew_df.index)\n",
    "ew_df['Std'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Std']], index= ew_df.index)\n",
    "ew_df['Sharpe'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Sharpe']], index= ew_df.index)\n",
    "ew_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1977-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1978-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1980-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1981-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1982-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1983-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1984-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1985-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1986-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1987-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1988-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1989-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1990-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1991-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1992-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1993-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1994-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1996-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1997-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1998-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1999-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2002-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2004-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2005-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth        time\n",
       "0           1  1977-01-31\n",
       "1           1  1978-01-31\n",
       "2           1  1979-01-31\n",
       "3           1  1980-01-31\n",
       "4           1  1981-02-27\n",
       "5           2  1982-02-26\n",
       "6           1  1983-01-31\n",
       "7           2  1984-01-31\n",
       "8           2  1985-01-31\n",
       "9           1  1986-01-31\n",
       "10          1  1987-02-27\n",
       "11          1  1988-02-29\n",
       "12          1  1989-01-31\n",
       "13          1  1990-01-31\n",
       "14          2  1991-01-31\n",
       "15          1  1992-01-31\n",
       "16          1  1993-02-26\n",
       "17          1  1994-01-31\n",
       "18          1  1995-01-31\n",
       "19          1  1996-01-31\n",
       "20          1  1997-01-31\n",
       "21          2  1998-02-27\n",
       "22          2  1999-02-26\n",
       "23          2  2000-01-31\n",
       "24          1  2001-01-31\n",
       "25          1  2002-01-31\n",
       "26          1  2003-01-31\n",
       "27          2  2004-02-27\n",
       "28          1  2005-01-31\n",
       "29          2  2006-01-31\n",
       "30          2  2007-01-31\n",
       "31          1  2008-01-31\n",
       "32          1  2009-02-27\n",
       "33          1  2010-02-26\n",
       "34          1  2011-01-31\n",
       "35          1  2012-01-31\n",
       "36          1  2013-01-31\n",
       "37          1  2014-01-31\n",
       "38          1  2015-02-27\n",
       "39          2  2016-02-29\n",
       "40          1  2017-01-31\n",
       "41          2  2018-01-31\n",
       "42          1  2019-01-31\n",
       "43          1  2020-01-31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert dictionary containing the Number of predictors randomly considered as potential split variables over time in dataframe\n",
    "pd.DataFrame(dic_max_depth_all.items())\n",
    "max_depth =pd.DataFrame(dic_max_depth_all.items(), columns=['Identifier', 'max_depth'])\n",
    "max_depth['Identifier'] = max_depth['Identifier'].astype(str)\n",
    "max_depth[\"time\"] = max_depth[\"Identifier\"].str[19:29]\n",
    "max_depth.drop([\"Identifier\"], axis = 1, inplace = True)\n",
    "\n",
    "# #Plot time-varying model complexity\n",
    "max_depth.set_index('time').plot();\n",
    "plt.xticks(rotation=45);\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth.to_csv('comp_grbt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
