{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('factors_2002.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546907   \n",
      "1   10401 1965-02-26  35392058.00  0.780829  0.609694 -0.063768  12.240330   \n",
      "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
      "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
      "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240330   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
      "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
      "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
      "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
      "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "\n",
      "   macro_smb  \n",
      "0       3.55  \n",
      "1       3.55  \n",
      "2       3.55  \n",
      "3       3.55  \n",
      "4       3.55  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "      <th>macro_hml</th>\n",
       "      <th>macro_smb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10145</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1498872.00</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>11.546906</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10401</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>35392056.00</td>\n",
       "      <td>0.780829</td>\n",
       "      <td>0.609694</td>\n",
       "      <td>-0.063768</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10786</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1695284.75</td>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.649827</td>\n",
       "      <td>-0.130519</td>\n",
       "      <td>12.005040</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10989</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1295887.75</td>\n",
       "      <td>1.199748</td>\n",
       "      <td>1.439395</td>\n",
       "      <td>0.073609</td>\n",
       "      <td>11.756961</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11260</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>2302001.25</td>\n",
       "      <td>1.257269</td>\n",
       "      <td>1.580725</td>\n",
       "      <td>-0.167320</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.185424</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546906   \n",
       "1   10401 1965-02-26  35392056.00  0.780829  0.609694 -0.063768  12.240331   \n",
       "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
       "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
       "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240331   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
       "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
       "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
       "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
       "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
       "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
       "\n",
       "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
       "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "\n",
       "   macro_smb  \n",
       "0       3.55  \n",
       "1       3.55  \n",
       "2       3.55  \n",
       "3       3.55  \n",
       "4       3.55  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "df['mvel12'] = df['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "df[features]= 2*df[features] -1\n",
    "\n",
    "df_large[features]=df_large.groupby(\"DATE\")[features].rank(pct=True)\n",
    "df_large[features]= 2*df_large[features] -1\n",
    "\n",
    "df_small[features]=df_small.groupby(\"DATE\")[features].rank(pct=True)\n",
    "df_small[features]= 2*df_small[features] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define huber loss function to minimize in the validation step\n",
    "def huber_loss_error(y_true, y_pred, delta=1.35):\n",
    "    res = []\n",
    "    for i in zip(y_true, y_pred):\n",
    "        if abs(i[0]-i[1])<=delta:\n",
    "            res.append(0.5*((i[0]-i[1])**2))\n",
    "        else:\n",
    "            res.append(delta*((abs(i[0]-i[1]) )-0.5*(delta**2)))\n",
    "    return np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 13670 ,# val records 3499 , # test records 1941\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 14434 ,# val records 3708 , # test records 2030\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 15118 ,# val records 3971 , # test records 2358\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 15843 ,# val records 4388 , # test records 3334\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 16573 ,# val records 5692 , # test records 3578\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 17432 ,# val records 6912 , # test records 2893\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 19634 ,# val records 6471 , # test records 4416\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 21888 ,# val records 7309 , # test records 4368\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 23087 ,# val records 8784 , # test records 4870\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 25581 ,# val records 9238 , # test records 6416\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 28417 ,# val records 11286 , # test records 6641\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 31555 ,# val records 13057 , # test records 5931\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 36204 ,# val records 12572 , # test records 6850\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 40904 ,# val records 12781 , # test records 6553\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 44805 ,# val records 13403 , # test records 7063\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 49297 ,# val records 13616 , # test records 8743\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 52516 ,# val records 15806 , # test records 8628\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 56001 ,# val records 17371 , # test records 10193\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 61851 ,# val records 18821 , # test records 11176\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 66063 ,# val records 21369 , # test records 12945\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 71888 ,# val records 24121 , # test records 16010\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 78194 ,# val records 28955 , # test records 15949\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 84723 ,# val records 31959 , # test records 14847\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 94092 ,# val records 30796 , # test records 18389\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 104110 ,# val records 33236 , # test records 16233\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 112107 ,# val records 34622 , # test records 15449\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 123943 ,# val records 31682 , # test records 17642\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 133113 ,# val records 33091 , # test records 17980\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 139819 ,# val records 35622 , # test records 21590\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 148833 ,# val records 39570 , # test records 23521\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 156620 ,# val records 45111 , # test records 24470\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 167034 ,# val records 47991 , # test records 21949\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 177610 ,# val records 46419 , # test records 16767\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 186070 ,# val records 38716 , # test records 18170\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 192070 ,# val records 34937 , # test records 21578\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 193990 ,# val records 39748 , # test records 21516\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 193771 ,# val records 43094 , # test records 23877\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 199116 ,# val records 45393 , # test records 28640\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 205183 ,# val records 52517 , # test records 26461\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 211418 ,# val records 55101 , # test records 23187\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 222078 ,# val records 49648 , # test records 27102\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 226949 ,# val records 50289 , # test records 28421\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 226615 ,# val records 55523 , # test records 27271\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 229247 ,# val records 55692 , # test records 29168\n",
      "-------\n",
      "R2 1971-05-28 - 1970-12-31 training set 0.39169567485382006\n",
      "R2 1977-01-31 - 1977-12-30 validation set 0.5448079626562281\n",
      "-------\n",
      "R2 1975-12-31 - 1970-03-31 training set 0.3485844807503017\n",
      "R2 1978-01-31 - 1978-12-29 validation set 0.4921668228303816\n",
      "-------\n",
      "R2 1971-09-30 - 1967-10-31 training set 0.35575900529381865\n",
      "R2 1979-01-31 - 1979-12-31 validation set 0.6096579966595854\n",
      "-------\n",
      "R2 1969-12-31 - 1971-02-26 training set 0.46552409376605075\n",
      "R2 1980-01-31 - 1981-01-30 validation set 0.49660549034470247\n",
      "-------\n",
      "R2 1976-02-27 - 1976-02-27 training set 0.4082522941989526\n",
      "R2 1981-02-27 - 1982-01-29 validation set 0.7187442624548372\n",
      "-------\n",
      "R2 1973-12-31 - 1977-03-31 training set 0.44279115402912517\n",
      "R2 1982-02-26 - 1982-12-31 validation set 0.3655102721827751\n",
      "-------\n",
      "R2 1975-11-28 - 1973-11-30 training set 0.4983230315151319\n",
      "R2 1983-01-31 - 1983-12-30 validation set 0.4475228243154996\n",
      "-------\n",
      "R2 1976-03-31 - 1980-05-30 training set 0.5327366376241152\n",
      "R2 1984-01-31 - 1984-12-31 validation set 0.5842156944810842\n",
      "-------\n",
      "R2 1974-10-31 - 1980-02-29 training set 0.5846061974763885\n",
      "R2 1985-01-31 - 1985-12-31 validation set 0.10872874480092365\n",
      "-------\n",
      "R2 1980-07-31 - 1980-02-29 training set 0.532309219890722\n",
      "R2 1986-01-31 - 1987-01-30 validation set 0.0458190965631019\n",
      "-------\n",
      "R2 1980-10-31 - 1975-08-29 training set 0.5456040762651877\n",
      "R2 1987-02-27 - 1988-01-29 validation set 0.23527188270301358\n",
      "-------\n",
      "R2 1978-07-31 - 1982-11-30 training set 0.6076821862815811\n",
      "R2 1988-02-29 - 1988-12-30 validation set 0.3559715252646234\n",
      "-------\n",
      "R2 1977-06-30 - 1983-05-31 training set 0.4615045841120057\n",
      "R2 1989-01-31 - 1989-12-29 validation set 0.457259151545931\n",
      "-------\n",
      "R2 1982-09-30 - 1982-07-30 training set 0.45376166472228374\n",
      "R2 1990-01-31 - 1990-12-31 validation set 0.4370287655174532\n",
      "-------\n",
      "R2 1987-05-29 - 1984-04-30 training set 0.4442473743505654\n",
      "R2 1991-01-31 - 1991-12-31 validation set -0.21520143242431233\n",
      "-------\n",
      "R2 1985-05-31 - 1988-08-31 training set 0.41562865181019415\n",
      "R2 1992-01-31 - 1993-01-29 validation set -0.10025691158963967\n",
      "-------\n",
      "R2 1985-10-31 - 1986-02-28 training set 0.4179436031643251\n",
      "R2 1993-02-26 - 1993-12-31 validation set -0.04677743502391629\n",
      "-------\n",
      "R2 1991-07-31 - 1984-10-31 training set 0.34235874195326044\n",
      "R2 1994-01-31 - 1994-12-30 validation set 0.26295478666993866\n",
      "-------\n",
      "R2 1993-01-29 - 1987-12-31 training set 0.4310652535891889\n",
      "R2 1995-01-31 - 1995-12-29 validation set -0.040934147629678064\n",
      "-------\n",
      "R2 1985-12-31 - 1992-09-30 training set 0.2977335020257401\n",
      "R2 1996-01-31 - 1996-12-31 validation set 0.14363116977457402\n",
      "-------\n",
      "R2 1992-01-31 - 1993-05-28 training set 0.25849913419542425\n",
      "R2 1997-01-31 - 1998-01-30 validation set 0.11890837877947924\n",
      "-------\n",
      "R2 1990-03-30 - 1992-02-28 training set 0.25194177341214563\n",
      "R2 1998-02-27 - 1999-01-29 validation set 0.12354787173298154\n",
      "-------\n",
      "R2 1991-09-30 - 1994-02-28 training set 0.2404648285016271\n",
      "R2 1999-02-26 - 1999-12-31 validation set 0.05217609625605191\n",
      "-------\n",
      "R2 1988-09-30 - 1997-01-31 training set 0.21452640224249442\n",
      "R2 2000-01-31 - 2000-12-29 validation set 0.13188787161450255\n",
      "-------\n",
      "R2 1998-11-30 - 1997-04-30 training set 0.20673747440306867\n",
      "R2 2001-01-31 - 2001-12-31 validation set 0.09005493928379049\n",
      "-------\n",
      "R2 1993-02-26 - 1998-05-29 training set 0.15703304296578813\n",
      "R2 2002-01-31 - 2002-12-31 validation set 0.08518957581736608\n",
      "-------\n",
      "R2 1996-06-28 - 1998-07-31 training set 0.12887725359644642\n",
      "R2 2003-01-31 - 2004-01-30 validation set -0.4277872505487861\n",
      "-------\n",
      "R2 1995-04-28 - 1995-07-31 training set 0.2561726966684227\n",
      "R2 2004-02-27 - 2004-12-31 validation set -0.5819042772050269\n",
      "-------\n",
      "R2 2000-04-28 - 1998-05-29 training set 0.12126372231370841\n",
      "R2 2005-01-31 - 2005-12-30 validation set 0.04095891956796471\n",
      "-------\n",
      "R2 2003-08-29 - 2003-09-30 training set 0.09114398550691627\n",
      "R2 2006-01-31 - 2006-12-29 validation set 0.1577541458632742\n",
      "-------\n",
      "R2 1995-05-31 - 2004-09-30 training set 0.07592500647232225\n",
      "R2 2007-01-31 - 2007-12-31 validation set 0.1767047213159777\n",
      "-------\n",
      "R2 2003-01-31 - 1996-11-29 training set 0.12811158047470583\n",
      "R2 2008-01-31 - 2009-01-30 validation set 0.1329644629028267\n",
      "-------\n",
      "R2 1997-11-28 - 2005-08-31 training set 0.10052661666997897\n",
      "R2 2009-02-27 - 2010-01-29 validation set -0.2592142744160031\n",
      "-------\n",
      "R2 2006-08-31 - 2006-04-28 training set 0.22287003463262223\n",
      "R2 2010-02-26 - 2010-12-31 validation set -0.20501176919989406\n",
      "-------\n",
      "R2 2000-03-31 - 2008-07-31 training set 0.1969043763163556\n",
      "R2 2011-01-31 - 2011-12-30 validation set -0.08942805968417589\n",
      "-------\n",
      "R2 2004-02-27 - 2000-10-31 training set 0.07920061098070452\n",
      "R2 2012-01-31 - 2012-12-31 validation set -0.1123014681672887\n",
      "-------\n",
      "R2 2002-11-29 - 2009-01-30 training set 0.09751110207281366\n",
      "R2 2013-01-31 - 2013-12-31 validation set -0.3336872779420206\n",
      "-------\n",
      "R2 2005-02-28 - 2009-04-30 training set 0.05672050997317568\n",
      "R2 2014-01-31 - 2015-01-30 validation set -0.0030194938271723704\n",
      "-------\n",
      "R2 2009-10-30 - 2011-05-31 training set 0.05609408219593226\n",
      "R2 2015-02-27 - 2016-01-29 validation set 0.014272871493247186\n",
      "-------\n",
      "R2 2013-08-30 - 2008-06-30 training set 0.11720206750534856\n",
      "R2 2016-02-29 - 2016-12-30 validation set -0.04720562241900983\n",
      "-------\n",
      "R2 2011-02-28 - 2012-10-31 training set 0.08195822845221012\n",
      "R2 2017-01-31 - 2017-12-29 validation set -0.009054598918846635\n",
      "-------\n",
      "R2 2007-12-31 - 2009-07-31 training set 0.030995789432546217\n",
      "R2 2018-01-31 - 2018-12-31 validation set 0.01599528748996537\n",
      "-------\n",
      "R2 2008-01-31 - 2008-07-31 training set 0.08265719629422252\n",
      "R2 2019-01-31 - 2019-12-31 validation set 0.003003167903189885\n",
      "-------\n",
      "R2 2009-11-30 - 2010-09-30 training set 0.1620940102220586\n",
      "R2 2020-01-31 - 2021-01-29 validation set -0.11349023558946558\n",
      "R2OOS gradient boosted regression tree:  0.007980050049982257\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val = []\n",
    "y_val_list =[]\n",
    "r2_list = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "dic_max_depth_all = {}\n",
    "\n",
    "# Grid of prespecified values for each hyperparameter  \n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              \"max_features\": [\"sqrt\"]\n",
    "              }\n",
    "#convert grid to list containing all posible hyperparameter combinations to iterate over\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "# Empty container to save the objective loss function (huber loss error) for each hyperparameter combination\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.8, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.8, replace=False, random_state=42)\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "    #Loop over the list containing all pyperparameter combinations, fit on the training sample and use \n",
    "    #validation set to generate predictions\n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"])\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        #calculate huber loss for each hyperparameter combination\n",
    "        #set delta to 1.35 following Huber (2004)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    #The optimal combination of hyperparameters is the one that causes the lowest loss \n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    #Fit again using the train and validation set and the optimal value for each hyperparameter \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"])\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 {y_train.index[0][0].date()} - {y_train.index[-1][0].date()} training set {r2_train}')\n",
    "    \n",
    "    #Save predictions, dates and the true values of the dependent variable to list\n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    #Calculate OOS model performance the for current window\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "\n",
    "    print(f'R2 {y_test.index[0][0].date()} - {y_test.index[-1][0].date()} validation set {r2}')\n",
    "    #Save OOS model performance and the respective month to dictionary\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "    # Save the number of predictors randomly considered as potential split variables\n",
    "    dic_max_depth_all[\"feat.\" + str(y_test.index)]= optim_param[\"max_depth\"]\n",
    "\n",
    "    \n",
    "    \n",
    "#Concatenate to get results over the whole OOS test period (Jan 2010-Dec 2019)\n",
    "predictions_all= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "#Calculate OOS model performance over the entire test period in line with Gu et al (2020)\n",
    "R2OOS_GBR = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pickles/R200S_GBR', 'wb') as f:\n",
    "#     pickle.dump(R2OOS_GBR, f)\n",
    "\n",
    "# with open('pickles/predictions', 'wb') as f:\n",
    "#     pickle.dump(predictions_all, f)\n",
    "\n",
    "# with open('pickles/y_test_list_all', 'wb') as f:\n",
    "#     pickle.dump(y_test_list_all, f)\n",
    "\n",
    "# with open('pickles/dates_all', 'wb') as f:\n",
    "#     pickle.dump(dates_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
