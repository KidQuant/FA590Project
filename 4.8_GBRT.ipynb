{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('factors_2002.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546907   \n",
      "1   10401 1965-02-26  35392058.00  0.780829  0.609694 -0.063768  12.240330   \n",
      "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
      "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
      "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240330   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
      "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
      "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
      "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
      "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "\n",
      "   macro_smb  \n",
      "0       3.55  \n",
      "1       3.55  \n",
      "2       3.55  \n",
      "3       3.55  \n",
      "4       3.55  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "      <th>macro_hml</th>\n",
       "      <th>macro_smb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10145</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1498872.00</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>11.546906</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10401</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>35392056.00</td>\n",
       "      <td>0.780829</td>\n",
       "      <td>0.609694</td>\n",
       "      <td>-0.063768</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10786</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1695284.75</td>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.649827</td>\n",
       "      <td>-0.130519</td>\n",
       "      <td>12.005040</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10989</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1295887.75</td>\n",
       "      <td>1.199748</td>\n",
       "      <td>1.439395</td>\n",
       "      <td>0.073609</td>\n",
       "      <td>11.756961</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11260</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>2302001.25</td>\n",
       "      <td>1.257269</td>\n",
       "      <td>1.580725</td>\n",
       "      <td>-0.167320</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.185424</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546906   \n",
       "1   10401 1965-02-26  35392056.00  0.780829  0.609694 -0.063768  12.240331   \n",
       "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
       "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
       "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240331   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
       "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
       "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
       "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
       "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
       "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
       "\n",
       "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
       "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "\n",
       "   macro_smb  \n",
       "0       3.55  \n",
       "1       3.55  \n",
       "2       3.55  \n",
       "3       3.55  \n",
       "4       3.55  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])\n",
    "\n",
    "df['mvel12'] = df['mvel1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "df[features]= 2*df[features] -1\n",
    "\n",
    "df_large[features]=df_large.groupby(\"DATE\")[features].rank(pct=True)\n",
    "df_large[features]= 2*df_large[features] -1\n",
    "\n",
    "df_small[features]=df_small.groupby(\"DATE\")[features].rank(pct=True)\n",
    "df_small[features]= 2*df_small[features] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss_error(y_true, y_pred, delta=1.35):\n",
    "    res = []\n",
    "    for i in zip(y_true, y_pred):\n",
    "        if abs(i[0]-i[1])<=delta:\n",
    "            res.append(0.5*((i[0]-i[1])**2))\n",
    "        else:\n",
    "            res.append(delta*((abs(i[0]-i[1]) )-0.5*(delta**2)))\n",
    "    return np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 13670 ,# val records 3499 , # test records 1941\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 14434 ,# val records 3708 , # test records 2030\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 15118 ,# val records 3971 , # test records 2358\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 15843 ,# val records 4388 , # test records 3334\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 16573 ,# val records 5692 , # test records 3578\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 17432 ,# val records 6912 , # test records 2893\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 19634 ,# val records 6471 , # test records 4416\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 21888 ,# val records 7309 , # test records 4368\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 23087 ,# val records 8784 , # test records 4870\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 25581 ,# val records 9238 , # test records 6416\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 28417 ,# val records 11286 , # test records 6641\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 31555 ,# val records 13057 , # test records 5931\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 36204 ,# val records 12572 , # test records 6850\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 40904 ,# val records 12781 , # test records 6553\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 44805 ,# val records 13403 , # test records 7063\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 49297 ,# val records 13616 , # test records 8743\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 52516 ,# val records 15806 , # test records 8628\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 56001 ,# val records 17371 , # test records 10193\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 61851 ,# val records 18821 , # test records 11176\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 66063 ,# val records 21369 , # test records 12945\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 71888 ,# val records 24121 , # test records 16010\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 78194 ,# val records 28955 , # test records 15949\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 84723 ,# val records 31959 , # test records 14847\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 94092 ,# val records 30796 , # test records 18389\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 104110 ,# val records 33236 , # test records 16233\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 112107 ,# val records 34622 , # test records 15449\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 123943 ,# val records 31682 , # test records 17642\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 133113 ,# val records 33091 , # test records 17980\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 139819 ,# val records 35622 , # test records 21590\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 148833 ,# val records 39570 , # test records 23521\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 156620 ,# val records 45111 , # test records 24470\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 167034 ,# val records 47991 , # test records 21949\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 177610 ,# val records 46419 , # test records 16767\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 186070 ,# val records 38716 , # test records 18170\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 192070 ,# val records 34937 , # test records 21578\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 193990 ,# val records 39748 , # test records 21516\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 193771 ,# val records 43094 , # test records 23877\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 199116 ,# val records 45393 , # test records 28640\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 205183 ,# val records 52517 , # test records 26461\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 211418 ,# val records 55101 , # test records 23187\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 222078 ,# val records 49648 , # test records 27102\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 226949 ,# val records 50289 , # test records 28421\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 226615 ,# val records 55523 , # test records 27271\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 229247 ,# val records 55692 , # test records 29168\n",
      "-------\n",
      "R2 1971-05-28 - 1970-12-31 training set 0.3982237613274271\n",
      "R2 1977-01-31 - 1977-12-30 validation set 0.5402560142809175\n",
      "-------\n",
      "R2 1975-12-31 - 1970-03-31 training set 0.35326393732366135\n",
      "R2 1978-01-31 - 1978-12-29 validation set 0.4879912378193869\n",
      "-------\n",
      "R2 1971-09-30 - 1967-10-31 training set 0.3504149308660276\n",
      "R2 1979-01-31 - 1979-12-31 validation set 0.6099396609710944\n",
      "-------\n",
      "R2 1969-12-31 - 1971-02-26 training set 0.40718067720733975\n",
      "R2 1980-01-31 - 1981-01-30 validation set 0.49173312029473026\n",
      "-------\n",
      "R2 1976-02-27 - 1976-02-27 training set 0.4517000544928571\n",
      "R2 1981-02-27 - 1982-01-29 validation set 0.7299480509384109\n",
      "-------\n",
      "R2 1973-12-31 - 1977-03-31 training set 0.5094230138690381\n",
      "R2 1982-02-26 - 1982-12-31 validation set 0.29930870512495733\n",
      "-------\n",
      "R2 1975-11-28 - 1973-11-30 training set 0.49705308223689115\n",
      "R2 1983-01-31 - 1983-12-30 validation set 0.43468040776983896\n",
      "-------\n",
      "R2 1976-03-31 - 1980-05-30 training set 0.556540836172753\n",
      "R2 1984-01-31 - 1984-12-31 validation set 0.5549440360459514\n",
      "-------\n",
      "R2 1974-10-31 - 1980-02-29 training set 0.5602058024683831\n",
      "R2 1985-01-31 - 1985-12-31 validation set 0.048485986646515156\n",
      "-------\n",
      "R2 1980-07-31 - 1980-02-29 training set 0.5225664307218871\n",
      "R2 1986-01-31 - 1987-01-30 validation set -0.055838755219900005\n",
      "-------\n",
      "R2 1980-10-31 - 1975-08-29 training set 0.5337878006216326\n",
      "R2 1987-02-27 - 1988-01-29 validation set 0.24852250969288736\n",
      "-------\n",
      "R2 1978-07-31 - 1982-11-30 training set 0.5860803949486303\n",
      "R2 1988-02-29 - 1988-12-30 validation set 0.32288528346978795\n",
      "-------\n",
      "R2 1977-06-30 - 1983-05-31 training set 0.4677967686875474\n",
      "R2 1989-01-31 - 1989-12-29 validation set 0.45321350072178335\n",
      "-------\n",
      "R2 1982-09-30 - 1982-07-30 training set 0.4542040549788374\n",
      "R2 1990-01-31 - 1990-12-31 validation set 0.4222382684279965\n",
      "-------\n",
      "R2 1987-05-29 - 1984-04-30 training set 0.4650410903324623\n",
      "R2 1991-01-31 - 1991-12-31 validation set -0.44242575774801307\n",
      "-------\n",
      "R2 1985-05-31 - 1988-08-31 training set 0.4181976735999726\n",
      "R2 1992-01-31 - 1993-01-29 validation set -0.08773188661035047\n",
      "-------\n",
      "R2 1985-10-31 - 1986-02-28 training set 0.420921176449214\n",
      "R2 1993-02-26 - 1993-12-31 validation set -0.03497104093538361\n",
      "-------\n",
      "R2 1991-07-31 - 1984-10-31 training set 0.3519557911712736\n",
      "R2 1994-01-31 - 1994-12-30 validation set 0.23671632699340506\n",
      "-------\n",
      "R2 1993-01-29 - 1987-12-31 training set 0.3241218751073005\n",
      "R2 1995-01-31 - 1995-12-29 validation set 0.12174167718799989\n",
      "-------\n",
      "R2 1985-12-31 - 1992-09-30 training set 0.2790577277351587\n",
      "R2 1996-01-31 - 1996-12-31 validation set 0.14569398974452874\n",
      "-------\n",
      "R2 1992-01-31 - 1993-05-28 training set 0.2631667247950358\n",
      "R2 1997-01-31 - 1998-01-30 validation set 0.11895709181688408\n",
      "-------\n",
      "R2 1990-03-30 - 1992-02-28 training set 0.3060322435558124\n",
      "R2 1998-02-27 - 1999-01-29 validation set 0.10111791219595911\n",
      "-------\n",
      "R2 1991-09-30 - 1994-02-28 training set 0.2644889124982731\n",
      "R2 1999-02-26 - 1999-12-31 validation set 0.04760120529802858\n",
      "-------\n",
      "R2 1988-09-30 - 1997-01-31 training set 0.2377643560656315\n",
      "R2 2000-01-31 - 2000-12-29 validation set 0.08371360953224549\n",
      "-------\n",
      "R2 1998-11-30 - 1997-04-30 training set 0.20587944281191506\n",
      "R2 2001-01-31 - 2001-12-31 validation set 0.08222768116557211\n",
      "-------\n",
      "R2 1993-02-26 - 1998-05-29 training set 0.15788844557344162\n",
      "R2 2002-01-31 - 2002-12-31 validation set 0.0885737821173781\n",
      "-------\n",
      "R2 1996-06-28 - 1998-07-31 training set 0.1380077085658512\n",
      "R2 2003-01-31 - 2004-01-30 validation set -0.38689076438173386\n",
      "-------\n",
      "R2 1995-04-28 - 1995-07-31 training set 0.22479790821310408\n",
      "R2 2004-02-27 - 2004-12-31 validation set -0.3275714406673933\n",
      "-------\n",
      "R2 2000-04-28 - 1998-05-29 training set 0.1263861840841798\n",
      "R2 2005-01-31 - 2005-12-30 validation set 0.06816830126823115\n",
      "-------\n",
      "R2 2003-08-29 - 2003-09-30 training set 0.12546474374696304\n",
      "R2 2006-01-31 - 2006-12-29 validation set 0.15355546003883347\n",
      "-------\n",
      "R2 1995-05-31 - 2004-09-30 training set 0.11506814168145163\n",
      "R2 2007-01-31 - 2007-12-31 validation set 0.1702121295468536\n",
      "-------\n",
      "R2 2003-01-31 - 1996-11-29 training set 0.12719419734260107\n",
      "R2 2008-01-31 - 2009-01-30 validation set 0.15552091222260112\n",
      "-------\n",
      "R2 1997-11-28 - 2005-08-31 training set 0.1062991529890559\n",
      "R2 2009-02-27 - 2010-01-29 validation set -0.29267236358560744\n",
      "-------\n",
      "R2 2006-08-31 - 2006-04-28 training set 0.14827264375424343\n",
      "R2 2010-02-26 - 2010-12-31 validation set -0.17667901381876172\n",
      "-------\n",
      "R2 2000-03-31 - 2008-07-31 training set 0.1657099276647075\n",
      "R2 2011-01-31 - 2011-12-30 validation set -0.08479872920789222\n",
      "-------\n",
      "R2 2004-02-27 - 2000-10-31 training set 0.08647638033461591\n",
      "R2 2012-01-31 - 2012-12-31 validation set -0.1497586656741552\n",
      "-------\n",
      "R2 2002-11-29 - 2009-01-30 training set 0.0955372540572107\n",
      "R2 2013-01-31 - 2013-12-31 validation set -0.2728410750673451\n",
      "-------\n",
      "R2 2005-02-28 - 2009-04-30 training set 0.0622301628708396\n",
      "R2 2014-01-31 - 2015-01-30 validation set -0.0038523226245934516\n",
      "-------\n",
      "R2 2009-10-30 - 2011-05-31 training set 0.05958500602572203\n",
      "R2 2015-02-27 - 2016-01-29 validation set 0.007681710682224563\n",
      "-------\n",
      "R2 2013-08-30 - 2008-06-30 training set 0.17668262149512204\n",
      "R2 2016-02-29 - 2016-12-30 validation set -0.1720612476518839\n",
      "-------\n",
      "R2 2011-02-28 - 2012-10-31 training set 0.07920793663859305\n",
      "R2 2017-01-31 - 2017-12-29 validation set -0.002582610255607465\n",
      "-------\n",
      "R2 2007-12-31 - 2009-07-31 training set 0.07515168434165409\n",
      "R2 2018-01-31 - 2018-12-31 validation set 0.006975961713844292\n",
      "-------\n",
      "R2 2008-01-31 - 2008-07-31 training set 0.13253815127894808\n",
      "R2 2019-01-31 - 2019-12-31 validation set -0.07602057024961084\n",
      "-------\n",
      "R2 2009-11-30 - 2010-09-30 training set 0.11694223225051725\n",
      "R2 2020-01-31 - 2021-01-29 validation set -0.09023377156207246\n",
      "R2OOS gradient boosted regression tree:  0.00205670715874251\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val = []\n",
    "y_val_list =[]\n",
    "r2_list = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "dic_max_depth_all = {}\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              }\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.8, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.8, replace=False, random_state=42)\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "    \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            n_iter_no_change=3,\n",
    "                                            tol=0.01,\n",
    "                                            validation_fraction=0.2)\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    n_iter_no_change=3,\n",
    "                                    tol=0.01)\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 {y_train.index[0][0].date()} - {y_train.index[-1][0].date()} training set {r2_train}')\n",
    "    \n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "\n",
    "    print(f'R2 {y_test.index[0][0].date()} - {y_test.index[-1][0].date()} validation set {r2}')\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "    dic_max_depth_all[\"feat.\" + str(y_test.index)]= optim_param[\"max_depth\"]\n",
    "\n",
    "    \n",
    "    \n",
    "predictions_all= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all= np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "#Calculate OOS model performance over the entire test period in line with Gu et al (2020)\n",
    "R2OOS_GBR = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/R200S_GBR', 'wb') as f:\n",
    "    pickle.dump(R2OOS_GBR, f)\n",
    "\n",
    "with open('pickles/predictions', 'wb') as f:\n",
    "    pickle.dump(predictions_all, f)\n",
    "\n",
    "with open('pickles/y_test_list_all', 'wb') as f:\n",
    "    pickle.dump(y_test_list_all, f)\n",
    "\n",
    "with open('pickles/dates_all', 'wb') as f:\n",
    "    pickle.dump(dates_all, f)\n",
    "\n",
    "with open('pickles/dic_max_depth_all', 'wb') as f:\n",
    "    pickle.dump(dic_max_depth_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 4042 ,# val records 1040 , # test records 577\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 4271 ,# val records 1103 , # test records 603\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 4478 ,# val records 1180 , # test records 704\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 4696 ,# val records 1307 , # test records 995\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 4915 ,# val records 1699 , # test records 1068\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 5175 ,# val records 2063 , # test records 862\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 5835 ,# val records 1930 , # test records 1320\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 6510 ,# val records 2182 , # test records 1304\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 6871 ,# val records 2624 , # test records 1458\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 7622 ,# val records 2762 , # test records 1919\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 8473 ,# val records 3377 , # test records 1987\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 9417 ,# val records 3906 , # test records 1777\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 10810 ,# val records 3764 , # test records 2049\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 12220 ,# val records 3826 , # test records 1959\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 13394 ,# val records 4008 , # test records 2113\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 14739 ,# val records 4072 , # test records 2619\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 15703 ,# val records 4732 , # test records 2583\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 16748 ,# val records 5202 , # test records 3051\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 18505 ,# val records 5634 , # test records 3348\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 19768 ,# val records 6399 , # test records 3879\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 21515 ,# val records 7227 , # test records 4797\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 23405 ,# val records 8676 , # test records 4780\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 25365 ,# val records 9577 , # test records 4451\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 28175 ,# val records 9231 , # test records 5511\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 31178 ,# val records 9962 , # test records 4865\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 33580 ,# val records 10376 , # test records 4631\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 37132 ,# val records 9496 , # test records 5287\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 39884 ,# val records 9918 , # test records 5390\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 41896 ,# val records 10677 , # test records 6472\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 44600 ,# val records 11862 , # test records 7051\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 46939 ,# val records 13523 , # test records 7335\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 50063 ,# val records 14386 , # test records 6578\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 53235 ,# val records 13913 , # test records 5023\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 55773 ,# val records 11601 , # test records 5446\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 57571 ,# val records 10469 , # test records 6469\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 58143 ,# val records 11915 , # test records 6450\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 58078 ,# val records 12919 , # test records 7158\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 59682 ,# val records 13608 , # test records 8585\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 61501 ,# val records 15743 , # test records 7934\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 63372 ,# val records 16519 , # test records 6952\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 66567 ,# val records 14886 , # test records 8126\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 68029 ,# val records 15078 , # test records 8521\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 67930 ,# val records 16647 , # test records 8175\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 68721 ,# val records 16696 , # test records 8745\n",
      "-------\n",
      "R2 training set 0.44248558732247323\n",
      "R2 validation set 0.6045918563629227\n",
      "-------\n",
      "R2 training set 0.3843124741065659\n",
      "R2 validation set 0.5106142544560531\n",
      "-------\n",
      "R2 training set 0.42099380310068846\n",
      "R2 validation set 0.621076152815722\n",
      "-------\n",
      "R2 training set 0.5213249104319002\n",
      "R2 validation set 0.4805882217910451\n",
      "-------\n",
      "R2 training set 0.44574969607175075\n",
      "R2 validation set 0.718573674331959\n",
      "-------\n",
      "R2 training set 0.5127001842695479\n",
      "R2 validation set 0.4929797723782603\n",
      "-------\n",
      "R2 training set 0.5151608881219514\n",
      "R2 validation set 0.4103873138855093\n",
      "-------\n",
      "R2 training set 0.5608586188659912\n",
      "R2 validation set 0.6228362443066153\n",
      "-------\n",
      "R2 training set 0.624986895665004\n",
      "R2 validation set 0.10026683669677461\n",
      "-------\n",
      "R2 training set 0.5663748462467936\n",
      "R2 validation set 0.005061870026246695\n",
      "-------\n",
      "R2 training set 0.5654056514392501\n",
      "R2 validation set 0.3105079557430914\n",
      "-------\n",
      "R2 training set 0.6084671354869926\n",
      "R2 validation set 0.5352178976208989\n",
      "-------\n",
      "R2 training set 0.5383665329956395\n",
      "R2 validation set 0.4680814482523262\n",
      "-------\n",
      "R2 training set 0.4967941188935353\n",
      "R2 validation set 0.5123833253746956\n",
      "-------\n",
      "R2 training set 0.4883771841610296\n",
      "R2 validation set -0.0740711794942801\n",
      "-------\n",
      "R2 training set 0.44740038926060277\n",
      "R2 validation set -0.03778067733229418\n",
      "-------\n",
      "R2 training set 0.5569746654465677\n",
      "R2 validation set -0.0005695965962029259\n",
      "-------\n",
      "R2 training set 0.43846728105151067\n",
      "R2 validation set 0.2977649905894426\n",
      "-------\n",
      "R2 training set 0.389636646584988\n",
      "R2 validation set 0.09614983876375371\n",
      "-------\n",
      "R2 training set 0.36676456862398155\n",
      "R2 validation set 0.18778838954866817\n",
      "-------\n",
      "R2 training set 0.30140166238213806\n",
      "R2 validation set 0.09560390966004217\n",
      "-------\n",
      "R2 training set 0.37796993148305835\n",
      "R2 validation set 0.06907829716111336\n",
      "-------\n",
      "R2 training set 0.2841727011584383\n",
      "R2 validation set 0.07040350511065463\n",
      "-------\n",
      "R2 training set 0.2662758072644641\n",
      "R2 validation set 0.12390910265168797\n",
      "-------\n",
      "R2 training set 0.21475625466864667\n",
      "R2 validation set 0.13695648538221605\n",
      "-------\n",
      "R2 training set 0.18547659715703113\n",
      "R2 validation set 0.09986795080096578\n",
      "-------\n",
      "R2 training set 0.1718389966935676\n",
      "R2 validation set -0.635182978503898\n",
      "-------\n",
      "R2 training set 0.14452283654664788\n",
      "R2 validation set -0.23397725231147848\n",
      "-------\n",
      "R2 training set 0.13753258563219573\n",
      "R2 validation set 0.0977288285307697\n",
      "-------\n",
      "R2 training set 0.1282932908329274\n",
      "R2 validation set 0.1926189403890819\n",
      "-------\n",
      "R2 training set 0.08956754474053863\n",
      "R2 validation set 0.18323125302520427\n",
      "-------\n",
      "R2 training set 0.13765536099767384\n",
      "R2 validation set 0.15719001899154394\n",
      "-------\n",
      "R2 training set 0.14216641046226441\n",
      "R2 validation set -0.22366977314390368\n",
      "-------\n",
      "R2 training set 0.16369035157476042\n",
      "R2 validation set -0.22137822896473835\n",
      "-------\n",
      "R2 training set 0.27205192294566083\n",
      "R2 validation set -0.29194903081541623\n",
      "-------\n",
      "R2 training set 0.15179689684549602\n",
      "R2 validation set -0.08725623359035262\n",
      "-------\n",
      "R2 training set 0.14297618394978606\n",
      "R2 validation set -0.3547320337240334\n",
      "-------\n",
      "R2 training set 0.14232144666495283\n",
      "R2 validation set -0.012663213931354944\n",
      "-------\n",
      "R2 training set 0.24194847842976863\n",
      "R2 validation set -0.015565995273935762\n",
      "-------\n",
      "R2 training set 0.14477501704349383\n",
      "R2 validation set -0.133438412776977\n",
      "-------\n",
      "R2 training set 0.05081740209024055\n",
      "R2 validation set -0.028954999871475096\n",
      "-------\n",
      "R2 training set 0.044267253736056666\n",
      "R2 validation set 0.020592900478007437\n",
      "-------\n",
      "R2 training set 0.16370209071622088\n",
      "R2 validation set -0.010423287420857852\n",
      "-------\n",
      "R2 training set 0.11540063936811629\n",
      "R2 validation set -0.0016365315661019952\n",
      "R2OOS gradient boosted regression tree:  0.00205670715874251\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "\n",
    "X = df_large[features]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val_top = []\n",
    "y_val_list =[]\n",
    "r2_list_top = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions_top = []\n",
    "y_test_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_all_top = {}\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              \"max_features\": [\"sqrt\"]\n",
    "              }\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "\n",
    "    X_test  = X.loc[test_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_test  = y.loc[test_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=10, random_state=42)\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=10, random_state=42)\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list_top.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 training set {r2_train}')\n",
    "    \n",
    "    predictions_top.append(preds)\n",
    "    dates_top.append(y_test.index)\n",
    "    y_test_list_top.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 validation set {r2}')\n",
    "    \n",
    "predictions_all_top = np.concatenate(predictions_top, axis=0)\n",
    "y_test_list_all_top = np.concatenate(y_test_list_top, axis=0) \n",
    "dates_all= np.concatenate(dates_top, axis=0)\n",
    "\n",
    "R2OOS_GBR_Top = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR_Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/R200S_GBR_Top', 'wb') as f:\n",
    "    pickle.dump(R2OOS_GBR_Top, f)\n",
    "\n",
    "with open('pickles/predictions_top', 'wb') as f:\n",
    "    pickle.dump(predictions_all_top, f)\n",
    "\n",
    "with open('pickles/y_test_list_all_top', 'wb') as f:\n",
    "    pickle.dump(y_test_list_all_top, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1965-01-31 - 1975-01-31 ,val period: 1975-01-31 - 1977-01-31 , Test period 1977-01-31 - 1978-01-31 # train records 4042 ,# val records 1040 , # test records 577\n",
      "Train period: 1966-01-31 - 1976-01-31 ,val period: 1976-01-31 - 1978-01-31 , Test period 1978-01-31 - 1979-01-31 # train records 4271 ,# val records 1103 , # test records 603\n",
      "Train period: 1967-01-31 - 1977-01-31 ,val period: 1977-01-31 - 1979-01-31 , Test period 1979-01-31 - 1980-01-31 # train records 4478 ,# val records 1180 , # test records 704\n",
      "Train period: 1968-01-31 - 1978-01-31 ,val period: 1978-01-31 - 1980-01-31 , Test period 1980-01-31 - 1981-01-31 # train records 4696 ,# val records 1307 , # test records 995\n",
      "Train period: 1969-01-31 - 1979-01-31 ,val period: 1979-01-31 - 1981-01-31 , Test period 1981-01-31 - 1982-01-31 # train records 4915 ,# val records 1699 , # test records 1068\n",
      "Train period: 1970-01-31 - 1980-01-31 ,val period: 1980-01-31 - 1982-01-31 , Test period 1982-01-31 - 1983-01-31 # train records 5175 ,# val records 2063 , # test records 862\n",
      "Train period: 1971-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 5835 ,# val records 1930 , # test records 1320\n",
      "Train period: 1972-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 6510 ,# val records 2182 , # test records 1304\n",
      "Train period: 1973-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 6871 ,# val records 2624 , # test records 1458\n",
      "Train period: 1974-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 7622 ,# val records 2762 , # test records 1919\n",
      "Train period: 1975-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 8473 ,# val records 3377 , # test records 1987\n",
      "Train period: 1976-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 9417 ,# val records 3906 , # test records 1777\n",
      "Train period: 1977-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 10810 ,# val records 3764 , # test records 2049\n",
      "Train period: 1978-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 12220 ,# val records 3826 , # test records 1959\n",
      "Train period: 1979-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 13394 ,# val records 4008 , # test records 2113\n",
      "Train period: 1980-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 14739 ,# val records 4072 , # test records 2619\n",
      "Train period: 1981-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 15703 ,# val records 4732 , # test records 2583\n",
      "Train period: 1982-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 16748 ,# val records 5202 , # test records 3051\n",
      "Train period: 1983-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 18505 ,# val records 5634 , # test records 3348\n",
      "Train period: 1984-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 19768 ,# val records 6399 , # test records 3879\n",
      "Train period: 1985-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 21515 ,# val records 7227 , # test records 4797\n",
      "Train period: 1986-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 23405 ,# val records 8676 , # test records 4780\n",
      "Train period: 1987-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 25365 ,# val records 9577 , # test records 4451\n",
      "Train period: 1988-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 28175 ,# val records 9231 , # test records 5511\n",
      "Train period: 1989-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 31178 ,# val records 9962 , # test records 4865\n",
      "Train period: 1990-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 33580 ,# val records 10376 , # test records 4631\n",
      "Train period: 1991-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 37132 ,# val records 9496 , # test records 5287\n",
      "Train period: 1992-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 39884 ,# val records 9918 , # test records 5390\n",
      "Train period: 1993-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 41896 ,# val records 10677 , # test records 6472\n",
      "Train period: 1994-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 44600 ,# val records 11862 , # test records 7051\n",
      "Train period: 1995-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 46939 ,# val records 13523 , # test records 7335\n",
      "Train period: 1996-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 50063 ,# val records 14386 , # test records 6578\n",
      "Train period: 1997-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 53235 ,# val records 13913 , # test records 5023\n",
      "Train period: 1998-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 55773 ,# val records 11601 , # test records 5446\n",
      "Train period: 1999-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 57571 ,# val records 10469 , # test records 6469\n",
      "Train period: 2000-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 58143 ,# val records 11915 , # test records 6450\n",
      "Train period: 2001-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 58078 ,# val records 12919 , # test records 7158\n",
      "Train period: 2002-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 59682 ,# val records 13608 , # test records 8585\n",
      "Train period: 2003-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 61501 ,# val records 15743 , # test records 7934\n",
      "Train period: 2004-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 63372 ,# val records 16519 , # test records 6952\n",
      "Train period: 2005-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 66567 ,# val records 14886 , # test records 8126\n",
      "Train period: 2006-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 68029 ,# val records 15078 , # test records 8521\n",
      "Train period: 2007-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 67930 ,# val records 16647 , # test records 8175\n",
      "Train period: 2008-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 68721 ,# val records 16696 , # test records 8745\n",
      "-------\n",
      "R2 training set 0.38647019315535913\n",
      "R2 validation set 0.49598372796308254\n",
      "-------\n",
      "R2 training set 0.3457815234214774\n",
      "R2 validation set 0.45017759638705424\n",
      "-------\n",
      "R2 training set 0.3467076701842825\n",
      "R2 validation set 0.525910878405517\n",
      "-------\n",
      "R2 training set 0.37408204510303233\n",
      "R2 validation set 0.46409206970422046\n",
      "-------\n",
      "R2 training set 0.36599361793009266\n",
      "R2 validation set 0.673862030043332\n",
      "-------\n",
      "R2 training set 0.38344982045530784\n",
      "R2 validation set 0.4988552850606285\n",
      "-------\n",
      "R2 training set 0.4904226086883302\n",
      "R2 validation set 0.36548966707895214\n",
      "-------\n",
      "R2 training set 0.488143685127031\n",
      "R2 validation set 0.5593942132618072\n",
      "-------\n",
      "R2 training set 0.5534864064681546\n",
      "R2 validation set 0.1744753005331392\n",
      "-------\n",
      "R2 training set 0.5033379899442767\n",
      "R2 validation set -0.05388381935027042\n",
      "-------\n",
      "R2 training set 0.516458210462207\n",
      "R2 validation set 0.23171274120111818\n",
      "-------\n",
      "R2 training set 0.5731151925110507\n",
      "R2 validation set 0.3899623676692634\n",
      "-------\n",
      "R2 training set 0.46685030056461796\n",
      "R2 validation set 0.498083477213883\n",
      "-------\n",
      "R2 training set 0.4359363460506912\n",
      "R2 validation set 0.39315991766038505\n",
      "-------\n",
      "R2 training set 0.4147330782556481\n",
      "R2 validation set -0.259768100142318\n",
      "-------\n",
      "R2 training set 0.3956853712664721\n",
      "R2 validation set -0.12819931976670862\n",
      "-------\n",
      "R2 training set 0.4934039438338683\n",
      "R2 validation set 0.0012352503895960432\n",
      "-------\n",
      "R2 training set 0.3797464064975761\n",
      "R2 validation set 0.22440031714625053\n",
      "-------\n",
      "R2 training set 0.28790353215677755\n",
      "R2 validation set 0.09255745593869213\n",
      "-------\n",
      "R2 training set 0.30381083588216207\n",
      "R2 validation set 0.12689265169544284\n",
      "-------\n",
      "R2 training set 0.2272178926043552\n",
      "R2 validation set 0.13957465067567043\n",
      "-------\n",
      "R2 training set 0.2102235158114868\n",
      "R2 validation set 0.11010757135956284\n",
      "-------\n",
      "R2 training set 0.21131335408817542\n",
      "R2 validation set 0.021051221318050595\n",
      "-------\n",
      "R2 training set 0.22386110894490518\n",
      "R2 validation set 0.16028731349483205\n",
      "-------\n",
      "R2 training set 0.17819073813141795\n",
      "R2 validation set 0.06514202853239592\n",
      "-------\n",
      "R2 training set 0.2072408269655972\n",
      "R2 validation set 0.060796205837761685\n",
      "-------\n",
      "R2 training set 0.22388404333298018\n",
      "R2 validation set -0.4870367688889734\n",
      "-------\n",
      "R2 training set 0.14281669755952175\n",
      "R2 validation set -0.3051137685144718\n",
      "-------\n",
      "R2 training set 0.11333834444409063\n",
      "R2 validation set 0.06540464088543718\n",
      "-------\n",
      "R2 training set 0.0831105970926237\n",
      "R2 validation set 0.10995607966397336\n",
      "-------\n",
      "R2 training set 0.07003369663168502\n",
      "R2 validation set 0.17125107717081256\n",
      "-------\n",
      "R2 training set 0.11992540107708805\n",
      "R2 validation set 0.10824086785673193\n",
      "-------\n",
      "R2 training set 0.12317020791622524\n",
      "R2 validation set -0.16704127439661942\n",
      "-------\n",
      "R2 training set 0.13369254552737486\n",
      "R2 validation set -0.07943967253197282\n",
      "-------\n",
      "R2 training set 0.09287978910664263\n",
      "R2 validation set -0.0045096122902603675\n",
      "-------\n",
      "R2 training set 0.14246448729252126\n",
      "R2 validation set -0.11952651940134928\n",
      "-------\n",
      "R2 training set 0.07269826774923316\n",
      "R2 validation set -0.2596891392498015\n",
      "-------\n",
      "R2 training set 0.18084070853900658\n",
      "R2 validation set 0.002300322071749128\n",
      "-------\n",
      "R2 training set 0.04878064616589228\n",
      "R2 validation set 0.010122610694735967\n",
      "-------\n",
      "R2 training set 0.03646911199664926\n",
      "R2 validation set -0.05126981234682404\n",
      "-------\n",
      "R2 training set 0.03268291439422155\n",
      "R2 validation set -0.0077302938782877195\n",
      "-------\n",
      "R2 training set 0.05176429301072005\n",
      "R2 validation set 0.011653187241589591\n",
      "-------\n",
      "R2 training set 0.050475394358487136\n",
      "R2 validation set 0.0015569964747751408\n",
      "-------\n",
      "R2 training set 0.060469039122176604\n",
      "R2 validation set -0.02557896172776153\n",
      "R2OOS gradient boosted regression tree:  0.00205670715874251\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=120,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "\n",
    "\n",
    "X = df_small[features]\n",
    "y = df_small[['risk_premium']]\n",
    "\n",
    "###########################################\n",
    "# Validation\n",
    "###########################################\n",
    "\n",
    "pred_val_bottom = []\n",
    "y_val_list =[]\n",
    "r2_list_bottom = []\n",
    "\n",
    "###########################################\n",
    "# Testing\n",
    "###########################################\n",
    "\n",
    "predictions_bottom = []\n",
    "y_test_list_bottom =[]\n",
    "dates_bottom = []\n",
    "dic_r2_all_bottom = {}\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 1000], \n",
    "              \"learning_rate\": [0.01,0.1], \n",
    "              \"max_features\": [\"sqrt\"]\n",
    "              }\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1975,1,31), second_split_date= datetime.date(1985,1,31)):\n",
    "\n",
    "    print('-------')\n",
    "    X_train = X.loc[train_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_train = y.loc[train_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_val = y.loc[val_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "\n",
    "    X_test  = X.loc[test_index].drop('DATE', axis=1).sample(frac=0.5, replace=False, random_state=42)\n",
    "    y_test  = y.loc[test_index].sample(frac=0.5, replace=False, random_state=42)\n",
    "    \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=3, random_state=42)\n",
    "    \n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Yval_predict=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val['risk_premium'],Yval_predict, delta=1.35)\n",
    "\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "\n",
    "    \n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=3, random_state=42)\n",
    "\n",
    "    \n",
    "    GBR.fit(X_train, y_train)\n",
    "    y_train_preds = GBR.predict(X_train)\n",
    "    r2_train = 1-np.sum(pow(y_train['risk_premium']-y_train_preds,2))/np.sum(pow(y_train['risk_premium'],2))\n",
    "\n",
    "    r2_list_bottom.append(r2_train)\n",
    "    \n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds=GBR.predict(X_test)\n",
    "\n",
    "    print(f'R2 training set {r2_train}')\n",
    "    \n",
    "    predictions_bottom.append(preds)\n",
    "    dates_bottom.append(y_test.index)\n",
    "    y_test_list_bottom.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    print(f'R2 validation set {r2}')\n",
    "    \n",
    "predictions_all_bottom = np.concatenate(predictions, axis=0)\n",
    "y_test_list_all_bottom = np.concatenate(y_test_list, axis=0) \n",
    "dates_all= np.concatenate(dates, axis=0)\n",
    "\n",
    "R2OOS_GBR_bottom = r2_score(y_test_list_all, predictions_all)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [44, 95457]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m R2OOS_GBR_Top \u001b[38;5;241m=\u001b[39m r2_score(y_test_list_top, predictions_all_top)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2OOS gradient boosted regression tree: \u001b[39m\u001b[38;5;124m\"\u001b[39m, R2OOS_GBR_Top)\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1204\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m   1198\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[0;32m   1199\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[0;32m   1200\u001b[0m )\n\u001b[0;32m   1202\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1204\u001b[0m _, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m   1205\u001b[0m     y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m   1206\u001b[0m )\n\u001b[0;32m   1207\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [44, 95457]"
     ]
    }
   ],
   "source": [
    "R2OOS_GBR_Top = r2_score(y_test_list_top, predictions_top)\n",
    "print(\"R2OOS gradient boosted regression tree: \", R2OOS_GBR_Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25267780937981454\n"
     ]
    }
   ],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'macro_mkt-rf', 'macro_hml', 'macro_smb','risk_premium', 'year'])].tolist()\n",
    "df['year'] = df['DATE'].dt.year\n",
    "\n",
    "X_train = df[features].loc[(df[\"year\"]>=2013) & (df[\"year\"]<=2018)]\n",
    "y_train = df[\"risk_premium\"].loc[(df[\"year\"]>=2013) & (df[\"year\"]<=2018)]\n",
    "\n",
    "X_val = df[features].loc[(df[\"year\"]>=2019) & (df[\"year\"]<=2020)]\n",
    "y_val = df[\"risk_premium\"].loc[(df[\"year\"]>=2019) & (df[\"year\"]<=2020)]\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 100], \n",
    "              \"learning_rate\": [0.01, 0.1], \n",
    "              \"max_features\": [\"sqrt\"]}\n",
    "\n",
    "\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(grid)):\n",
    "    GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=3)\n",
    "    \n",
    "    \n",
    "    GBR_val.fit(X_train, y_train)\n",
    "    Ypred_val=GBR_val.predict(X_val)\n",
    "    huber_loss[i,0]= huber_loss_error(y_val,Ypred_val, delta=1.35)\n",
    "\n",
    "optim_param = grid[np.argmin(huber_loss)]\n",
    "GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=3)\n",
    "\n",
    "GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "preds = GBR.predict(np.concatenate((X_train, X_val)))\n",
    "R2OOS_all = 1-sum(pow(np.concatenate((y_train, y_val))-preds,2))/sum(pow(np.concatenate((y_train, y_val)),2))\n",
    "print(R2OOS_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in features:\n",
    "    globals()['df_' + str(j)] =  df.copy()\n",
    "    globals()['df_' + str(j)][str(j)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mvel1\n",
      "beta\n",
      "betasq\n",
      "chmom\n",
      "dolvol\n",
      "idiovol\n",
      "indmom\n",
      "mom1m\n",
      "mom6m\n",
      "mom12m\n",
      "mom36m\n",
      "pricedelay\n",
      "turn\n",
      "absacc\n",
      "acc\n",
      "age\n",
      "agr\n",
      "bm\n",
      "bm_ia\n",
      "cashdebt\n",
      "cashpr\n",
      "cfp\n",
      "cfp_ia\n",
      "chatoia\n",
      "chcsho\n",
      "chempia\n",
      "chinv\n",
      "chpmia\n",
      "convind\n",
      "currat\n",
      "depr\n",
      "divi\n",
      "divo\n",
      "dy\n",
      "egr\n",
      "ep\n",
      "gma\n",
      "grcapx\n",
      "grltnoa\n",
      "herf\n",
      "hire\n",
      "invest\n",
      "lev\n",
      "lgr\n",
      "mve_ia\n",
      "operprof\n",
      "orgcap\n",
      "pchcapx_ia\n",
      "pchcurrat\n",
      "pchdepr\n",
      "pchgm_pchsale\n",
      "pchquick\n",
      "pchsale_pchinvt\n",
      "pchsale_pchrect\n",
      "pchsale_pchxsga\n",
      "pchsaleinv\n",
      "pctacc\n",
      "ps\n",
      "quick\n",
      "rd\n",
      "roic\n",
      "salecash\n",
      "saleinv\n",
      "salerec\n",
      "securedind\n",
      "sgr\n",
      "sin\n",
      "sp\n",
      "tang\n",
      "tb\n",
      "baspread\n",
      "ill\n",
      "maxret\n",
      "retvol\n",
      "std_dolvol\n",
      "std_turn\n",
      "zerotrade\n",
      "macro_dp\n",
      "macro_ep\n",
      "macro_bm\n",
      "macro_ntis\n",
      "macro_tbl\n",
      "macro_tms\n",
      "macro_dfy\n",
      "macro_svar\n"
     ]
    }
   ],
   "source": [
    "dic = {}    \n",
    "param_grid = {'max_depth': [1,2], \n",
    "              'n_estimators': [100, 300, 500, 100], \n",
    "              \"learning_rate\": [0.01, 0.1], \n",
    "              \"max_features\": [\"sqrt\"]}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "huber_loss = np.full((len(grid),1),np.nan, dtype = np.float32)\n",
    "    \n",
    "for j in features:\n",
    "    print(j)\n",
    "    df_var = globals()['df_' + str(j)]\n",
    "    \n",
    "    X_train = df_var[features].loc[(df_var[\"year\"]>=2013) & (df_var[\"year\"]<=2018)].sample(frac=0.3, replace=False, random_state=42)\n",
    "    y_train = df_var[\"risk_premium\"].loc[(df_var[\"year\"]>=2013) & (df_var[\"year\"]<=2018)].sample(frac=0.3, replace=False, random_state=42)\n",
    "\n",
    "    X_val = df_var[features].loc[(df_var[\"year\"]>=2019) & (df_var[\"year\"]<=2020)].sample(frac=0.4, replace=False, random_state=42)\n",
    "    y_val = df_var[\"risk_premium\"].loc[(df_var[\"year\"]>=2019) & (df_var[\"year\"]<=2020)].sample(frac=0.4, replace=False, random_state=42)\n",
    " \n",
    "    for i in range(len(grid)):\n",
    "        GBR_val = GradientBoostingRegressor(loss='huber',\n",
    "                                            max_depth=grid[i][\"max_depth\"], \n",
    "                                            learning_rate=grid[i][\"learning_rate\"],\n",
    "                                            n_estimators = grid[i][\"n_estimators\"],\n",
    "                                            max_features= grid[i][\"max_features\"],\n",
    "                                            n_iter_no_change=3)\n",
    "\n",
    "\n",
    "        GBR_val.fit(X_train, y_train)\n",
    "        Ypred_val=GBR_val.predict(X_val)\n",
    "        huber_loss[i,0]= huber_loss_error(y_val,Ypred_val, delta=1.35)\n",
    "\n",
    "    optim_param = grid[np.argmin(huber_loss)]\n",
    "    GBR = GradientBoostingRegressor(loss='huber',\n",
    "                                    max_depth=optim_param[\"max_depth\"], \n",
    "                                    learning_rate=optim_param[\"learning_rate\"],\n",
    "                                    n_estimators = optim_param[\"n_estimators\"],\n",
    "                                    max_features= optim_param[\"max_features\"],\n",
    "                                    n_iter_no_change=3)\n",
    "\n",
    "    GBR.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = GBR.predict(np.concatenate((X_train, X_val)))\n",
    "    R2OOS_var = 1-sum(pow(np.concatenate((y_train, y_val))-preds,2))/sum(pow(np.concatenate((y_train, y_val)),2))\n",
    "    dic['R2OOS_' + str(j)] = R2OOS_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>R2OOS</th>\n",
       "      <th>red_R2OOS</th>\n",
       "      <th>var_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.038455</td>\n",
       "      <td>0.214223</td>\n",
       "      <td>0.064131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pchcurrat</td>\n",
       "      <td>0.039538</td>\n",
       "      <td>0.213140</td>\n",
       "      <td>0.063807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>macro_svar</td>\n",
       "      <td>0.040289</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.063582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>depr</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>0.211849</td>\n",
       "      <td>0.063420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>idiovol</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.210894</td>\n",
       "      <td>0.063135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mve_ia</td>\n",
       "      <td>0.284538</td>\n",
       "      <td>-0.031860</td>\n",
       "      <td>-0.009538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pchgm_pchsale</td>\n",
       "      <td>0.284895</td>\n",
       "      <td>-0.032217</td>\n",
       "      <td>-0.009645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mom1m</td>\n",
       "      <td>0.285214</td>\n",
       "      <td>-0.032536</td>\n",
       "      <td>-0.009740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tb</td>\n",
       "      <td>0.286530</td>\n",
       "      <td>-0.033853</td>\n",
       "      <td>-0.010134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>lev</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>-0.035122</td>\n",
       "      <td>-0.010514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature     R2OOS  red_R2OOS   var_imp\n",
       "14            acc  0.038455   0.214223  0.064131\n",
       "48      pchcurrat  0.039538   0.213140  0.063807\n",
       "84     macro_svar  0.040289   0.212389  0.063582\n",
       "30           depr  0.040829   0.211849  0.063420\n",
       "5         idiovol  0.041783   0.210894  0.063135\n",
       "..            ...       ...        ...       ...\n",
       "44         mve_ia  0.284538  -0.031860 -0.009538\n",
       "50  pchgm_pchsale  0.284895  -0.032217 -0.009645\n",
       "7           mom1m  0.285214  -0.032536 -0.009740\n",
       "69             tb  0.286530  -0.033853 -0.010134\n",
       "42            lev  0.287800  -0.035122 -0.010514\n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic.items())\n",
    "imp=pd.DataFrame(dic.items(), columns=['Feature', 'R2OOS'])\n",
    "imp[\"Feature\"] = imp[\"Feature\"].str[6:]\n",
    "\n",
    "imp[\"red_R2OOS\"] = R2OOS_all -imp[\"R2OOS\"]\n",
    "imp[\"var_imp\"] = imp[\"red_R2OOS\"]/sum(imp[\"red_R2OOS\"])\n",
    "imp=imp.sort_values(by = ['var_imp'], ascending = False)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fea_imp_graph = imp.sort_values(['var_imp', 'Feature'], ascending=[True, False]).iloc[-20:]\n",
    "_ = fea_imp_graph.plot(kind='barh', x='Feature', y='var_imp', figsize=(20, 10))\n",
    "plt.title('GBRT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_net=imp[[\"Feature\", \"var_imp\"]]\n",
    "var_imp_net.to_csv(r'var_imp_GBRT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predictions_all.tolist()\n",
    "y_true = y_test_list_all.tolist()\n",
    "i = dates_all.tolist()\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'identifier': i,\n",
    "     'yhat': yhat,\n",
    "     'y_true': y_true\n",
    "    })\n",
    "\n",
    "results[\"identifier\"]= results[\"identifier\"].astype(\"str\")\n",
    "results[\"date\"] = results[\"identifier\"].str[12:22]\n",
    "results[\"id\"] = results[\"identifier\"].str[35:40]\n",
    "results.drop([\"identifier\"],axis = 1, inplace=True)\n",
    "results['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n",
    "results['MonthYear'] = results['date'].dt.to_period('M')\n",
    "results = results.sort_values(by = ['date', 'id'], ascending = True)\n",
    "results = results.set_index(['MonthYear','id'])\n",
    "results\n",
    "\n",
    "# results['yhat'] = results['yhat'].apply(lambda x: x[0])\n",
    "results['y_true'] = results['y_true'].apply(lambda x: x[0])\n",
    "\n",
    "data = df[['mvel12', 'macro_tbl', 'macro_svar']].copy()\n",
    "data.reset_index(inplace=True)\n",
    "data['permno2'] = data['permno2'].astype('str')\n",
    "data['MonthYear'] = data['DATE2'].dt.to_period('M')\n",
    "data.drop('DATE2', axis=1, inplace=True)\n",
    "data.rename(columns={'permno2': 'id'}, inplace=True)\n",
    "data.rename(columns={'mvel12': 'market_cap'}, inplace=True)\n",
    "data.rename(columns={'macro_tbl': 'risk_free_rate'}, inplace=True)\n",
    "data = data.set_index(['MonthYear','id'])\n",
    "\n",
    "bigdata = pd.merge(results, data,left_index=True, right_index=True)\n",
    "bigdata.reset_index(inplace=True)\n",
    "bigdata\n",
    "bigdata['returns'] = bigdata['y_true'] + bigdata['risk_free_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "       508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n",
       "       521, 522, 523, 524, 525, 526, 527, 528, 529], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata['MonthYear1'] = bigdata['MonthYear'].copy()\n",
    "bigdata['MonthYear'] = bigdata['MonthYear'].astype('int64')\n",
    "bigdata['NumMonth'] = bigdata['MonthYear'] - 83\n",
    "bigdata['NumMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata.to_csv('predictions/GBR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bigdata = pd.read_csv('predictions/GBR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = bigdata.sort_values(['NumMonth','yhat'], ascending=[True, True]).groupby(['MonthYear'],\n",
    "                                                                  as_index=False,\n",
    "                                                                  sort=False).tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = top_100[['date', 'NumMonth','MonthYear', 'id', 'yhat', 'y_true', 'risk_free_rate', 'MonthYear1']]\n",
    "portfolio.reset_index(inplace=True)\n",
    "portfolio.drop(columns=['index'],inplace=True)\n",
    "portfolio['eq_weights'] = 1/portfolio.groupby('MonthYear')['id'].transform('size')\n",
    "portfolio['excess_return_stock_ew'] = portfolio['y_true'] *portfolio['eq_weights']\n",
    "portfolio['pred_excess_return_stock_ew'] = portfolio[\"yhat\"]*portfolio[\"eq_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred_return = portfolio.groupby('MonthYear')['pred_excess_return_stock_ew'].transform('sum').mean()\n",
    "mean_port_return = portfolio.groupby('MonthYear')['excess_return_stock_ew'].transform('sum').mean()\n",
    "port_vol =  portfolio.groupby('MonthYear')[\"pred_excess_return_stock_ew\"].transform('sum').std()\n",
    "sharp_ratio = (mean_pred_return/port_vol)*np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS Regression</th>\n",
       "      <td>-3.57%</td>\n",
       "      <td>-4.38%</td>\n",
       "      <td>3.64%</td>\n",
       "      <td>-4.17%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Real    Pred    Std  Sharpe\n",
       "PLS Regression  -3.57%  -4.38%  3.64%  -4.17%"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_np = np.array([[mean_port_return, mean_pred_return, port_vol, sharp_ratio]])\n",
    "\n",
    "ew_df = pd.DataFrame(chart_np, columns=['Real', 'Pred', 'Std', 'Sharpe'],\n",
    "                                index=['PLS Regression'])\n",
    "\n",
    "ew_df['Real'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Real']], index= ew_df.index)\n",
    "ew_df['Pred'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Pred']], index= ew_df.index)\n",
    "ew_df['Std'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Std']], index= ew_df.index)\n",
    "ew_df['Sharpe'] = pd.Series(['{0:.2f}%'.format(val) for val in ew_df['Sharpe']], index= ew_df.index)\n",
    "ew_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1977-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1978-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1979-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1980-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1981-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1982-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1983-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1984-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1985-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1986-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1987-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1988-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1989-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1990-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1991-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1992-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1993-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1994-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1996-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1997-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1998-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1999-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2002-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2004-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2005-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth        time\n",
       "0           1  1977-01-31\n",
       "1           1  1978-01-31\n",
       "2           1  1979-01-31\n",
       "3           1  1980-01-31\n",
       "4           1  1981-02-27\n",
       "5           2  1982-02-26\n",
       "6           1  1983-01-31\n",
       "7           2  1984-01-31\n",
       "8           2  1985-01-31\n",
       "9           1  1986-01-31\n",
       "10          1  1987-02-27\n",
       "11          1  1988-02-29\n",
       "12          1  1989-01-31\n",
       "13          1  1990-01-31\n",
       "14          2  1991-01-31\n",
       "15          1  1992-01-31\n",
       "16          1  1993-02-26\n",
       "17          1  1994-01-31\n",
       "18          1  1995-01-31\n",
       "19          1  1996-01-31\n",
       "20          1  1997-01-31\n",
       "21          2  1998-02-27\n",
       "22          2  1999-02-26\n",
       "23          2  2000-01-31\n",
       "24          1  2001-01-31\n",
       "25          1  2002-01-31\n",
       "26          1  2003-01-31\n",
       "27          2  2004-02-27\n",
       "28          1  2005-01-31\n",
       "29          2  2006-01-31\n",
       "30          2  2007-01-31\n",
       "31          1  2008-01-31\n",
       "32          1  2009-02-27\n",
       "33          1  2010-02-26\n",
       "34          1  2011-01-31\n",
       "35          1  2012-01-31\n",
       "36          1  2013-01-31\n",
       "37          1  2014-01-31\n",
       "38          1  2015-02-27\n",
       "39          2  2016-02-29\n",
       "40          1  2017-01-31\n",
       "41          2  2018-01-31\n",
       "42          1  2019-01-31\n",
       "43          1  2020-01-31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert dictionary containing the Number of predictors randomly considered as potential split variables over time in dataframe\n",
    "pd.DataFrame(dic_max_depth_all.items())\n",
    "max_depth =pd.DataFrame(dic_max_depth_all.items(), columns=['Identifier', 'max_depth'])\n",
    "max_depth['Identifier'] = max_depth['Identifier'].astype(str)\n",
    "max_depth[\"time\"] = max_depth[\"Identifier\"].str[19:29]\n",
    "max_depth.drop([\"Identifier\"], axis = 1, inplace = True)\n",
    "\n",
    "# #Plot time-varying model complexity\n",
    "max_depth.set_index('time').plot();\n",
    "plt.xticks(rotation=45);\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth.to_csv('comp_grbt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
