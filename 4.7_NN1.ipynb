{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from TimeBasedCV import TimeBasedCV\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/factors_1965.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
      "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546907   \n",
      "1   10401 1965-02-26  35392058.00  0.780829  0.609694 -0.063768  12.240330   \n",
      "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
      "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
      "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240330   \n",
      "\n",
      "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
      "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
      "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
      "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
      "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
      "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
      "\n",
      "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
      "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
      "\n",
      "   macro_smb  \n",
      "0       3.55  \n",
      "1       3.55  \n",
      "2       3.55  \n",
      "3       3.55  \n",
      "4       3.55  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# with open('data/features_1965.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open('data/features_1965.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>macro_ep</th>\n",
       "      <th>macro_bm</th>\n",
       "      <th>macro_ntis</th>\n",
       "      <th>macro_tbl</th>\n",
       "      <th>macro_tms</th>\n",
       "      <th>macro_dfy</th>\n",
       "      <th>macro_svar</th>\n",
       "      <th>macro_mkt-rf</th>\n",
       "      <th>macro_hml</th>\n",
       "      <th>macro_smb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10145</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1498872.00</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>11.546906</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10401</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>35392056.00</td>\n",
       "      <td>0.780829</td>\n",
       "      <td>0.609694</td>\n",
       "      <td>-0.063768</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10786</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1695284.75</td>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.649827</td>\n",
       "      <td>-0.130519</td>\n",
       "      <td>12.005040</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10989</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>1295887.75</td>\n",
       "      <td>1.199748</td>\n",
       "      <td>1.439395</td>\n",
       "      <td>0.073609</td>\n",
       "      <td>11.756961</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11260</td>\n",
       "      <td>1965-02-26</td>\n",
       "      <td>2302001.25</td>\n",
       "      <td>1.257269</td>\n",
       "      <td>1.580725</td>\n",
       "      <td>-0.167320</td>\n",
       "      <td>12.240331</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.185424</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936836</td>\n",
       "      <td>0.471399</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno       DATE        mvel1      beta    betasq     chmom     dolvol  \\\n",
       "0   10145 1965-02-26   1498872.00  0.983510  0.967291  0.105988  11.546906   \n",
       "1   10401 1965-02-26  35392056.00  0.780829  0.609694 -0.063768  12.240331   \n",
       "2   10786 1965-02-26   1695284.75  0.806119  0.649827 -0.130519  12.005040   \n",
       "3   10989 1965-02-26   1295887.75  1.199748  1.439395  0.073609  11.756961   \n",
       "4   11260 1965-02-26   2302001.25  1.257269  1.580725 -0.167320  12.240331   \n",
       "\n",
       "    idiovol    indmom     mom1m  ...  macro_ep  macro_bm  macro_ntis  \\\n",
       "0  0.022307  0.035075  0.104116  ...  2.936836  0.471399    0.014823   \n",
       "1  0.013395  0.335139 -0.007326  ...  2.936836  0.471399    0.014823   \n",
       "2  0.024366  0.104106  0.060498  ...  2.936836  0.471399    0.014823   \n",
       "3  0.022717  0.118513  0.068807  ...  2.936836  0.471399    0.014823   \n",
       "4  0.035883  0.185424 -0.036885  ...  2.936836  0.471399    0.014823   \n",
       "\n",
       "   macro_tbl  macro_tms  macro_dfy  macro_svar  macro_mkt-rf  macro_hml  \\\n",
       "0     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "1     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "2     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "3     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "4     0.0393    -0.0379     0.0055    0.000393          0.44       0.11   \n",
       "\n",
       "   macro_smb  \n",
       "0       3.55  \n",
       "1       3.55  \n",
       "2       3.55  \n",
       "3       3.55  \n",
       "4       3.55  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort observations by date and stock id\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype('float32')\n",
    "df = df.sort_values(by = ['DATE', 'permno'], ascending = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['permno2'] = df['permno'].copy()\n",
    "df['DATE2'] = df['DATE'].copy()\n",
    "\n",
    "#Make a copy of  the \"me\" variable (market equity) before rank standartization to use afterwards for value weighting\n",
    "df['mvel12'] = df['mvel1'].copy()\n",
    "df = df.set_index(['DATE2','permno2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_10904\\2840026024.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n",
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_10904\\2840026024.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "p=0.3 \n",
    "df_large= df.groupby('DATE').apply(lambda x: x.nlargest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n",
    "df_small = df.groupby('DATE').apply(lambda x: x.nsmallest(int(len(x)*p),'mvel1')).reset_index(drop=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[~df.columns.isin(['DATE', 'DATE2', \"mvel2\",'sic2' ,'permno',\"permno2\",'risk_premium'])].tolist()\n",
    "df[features]=df.groupby('DATE')[features].rank(pct=True)\n",
    "\n",
    "df[features] = 2*df[features] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 1976-01-31 - 1981-01-31 ,val period: 1981-01-31 - 1983-01-31 , Test period 1983-01-31 - 1984-01-31 # train records 11430 ,# val records 6471 , # test records 4416\n",
      "Train period: 1977-01-31 - 1982-01-31 ,val period: 1982-01-31 - 1984-01-31 , Test period 1984-01-31 - 1985-01-31 # train records 13241 ,# val records 7309 , # test records 4368\n",
      "Train period: 1978-01-31 - 1983-01-31 ,val period: 1983-01-31 - 1985-01-31 , Test period 1985-01-31 - 1986-01-31 # train records 14193 ,# val records 8784 , # test records 4870\n",
      "Train period: 1979-01-31 - 1984-01-31 ,val period: 1984-01-31 - 1986-01-31 , Test period 1986-01-31 - 1987-01-31 # train records 16579 ,# val records 9238 , # test records 6416\n",
      "Train period: 1980-01-31 - 1985-01-31 ,val period: 1985-01-31 - 1987-01-31 , Test period 1987-01-31 - 1988-01-31 # train records 18589 ,# val records 11286 , # test records 6641\n",
      "Train period: 1981-01-31 - 1986-01-31 ,val period: 1986-01-31 - 1988-01-31 , Test period 1988-01-31 - 1989-01-31 # train records 20125 ,# val records 13057 , # test records 5931\n",
      "Train period: 1982-01-31 - 1987-01-31 ,val period: 1987-01-31 - 1989-01-31 , Test period 1989-01-31 - 1990-01-31 # train records 22963 ,# val records 12572 , # test records 6850\n",
      "Train period: 1983-01-31 - 1988-01-31 ,val period: 1988-01-31 - 1990-01-31 , Test period 1990-01-31 - 1991-01-31 # train records 26711 ,# val records 12781 , # test records 6553\n",
      "Train period: 1984-01-31 - 1989-01-31 ,val period: 1989-01-31 - 1991-01-31 , Test period 1991-01-31 - 1992-01-31 # train records 28226 ,# val records 13403 , # test records 7063\n",
      "Train period: 1985-01-31 - 1990-01-31 ,val period: 1990-01-31 - 1992-01-31 , Test period 1992-01-31 - 1993-01-31 # train records 30708 ,# val records 13616 , # test records 8743\n",
      "Train period: 1986-01-31 - 1991-01-31 ,val period: 1991-01-31 - 1993-01-31 , Test period 1993-01-31 - 1994-01-31 # train records 32391 ,# val records 15806 , # test records 8628\n",
      "Train period: 1987-01-31 - 1992-01-31 ,val period: 1992-01-31 - 1994-01-31 , Test period 1994-01-31 - 1995-01-31 # train records 33038 ,# val records 17371 , # test records 10193\n",
      "Train period: 1988-01-31 - 1993-01-31 ,val period: 1993-01-31 - 1995-01-31 , Test period 1995-01-31 - 1996-01-31 # train records 35140 ,# val records 18821 , # test records 11176\n",
      "Train period: 1989-01-31 - 1994-01-31 ,val period: 1994-01-31 - 1996-01-31 , Test period 1996-01-31 - 1997-01-31 # train records 37837 ,# val records 21369 , # test records 12945\n",
      "Train period: 1990-01-31 - 1995-01-31 ,val period: 1995-01-31 - 1997-01-31 , Test period 1997-01-31 - 1998-01-31 # train records 41180 ,# val records 24121 , # test records 16010\n",
      "Train period: 1991-01-31 - 1996-01-31 ,val period: 1996-01-31 - 1998-01-31 , Test period 1998-01-31 - 1999-01-31 # train records 45803 ,# val records 28955 , # test records 15949\n",
      "Train period: 1992-01-31 - 1997-01-31 ,val period: 1997-01-31 - 1999-01-31 , Test period 1999-01-31 - 2000-01-31 # train records 51685 ,# val records 31959 , # test records 14847\n",
      "Train period: 1993-01-31 - 1998-01-31 ,val period: 1998-01-31 - 2000-01-31 , Test period 2000-01-31 - 2001-01-31 # train records 58952 ,# val records 30796 , # test records 18389\n",
      "Train period: 1994-01-31 - 1999-01-31 ,val period: 1999-01-31 - 2001-01-31 , Test period 2001-01-31 - 2002-01-31 # train records 66273 ,# val records 33236 , # test records 16233\n",
      "Train period: 1995-01-31 - 2000-01-31 ,val period: 2000-01-31 - 2002-01-31 , Test period 2002-01-31 - 2003-01-31 # train records 70927 ,# val records 34622 , # test records 15449\n",
      "Train period: 1996-01-31 - 2001-01-31 ,val period: 2001-01-31 - 2003-01-31 , Test period 2003-01-31 - 2004-01-31 # train records 78140 ,# val records 31682 , # test records 17642\n",
      "Train period: 1997-01-31 - 2002-01-31 ,val period: 2002-01-31 - 2004-01-31 , Test period 2004-01-31 - 2005-01-31 # train records 81428 ,# val records 33091 , # test records 17980\n",
      "Train period: 1998-01-31 - 2003-01-31 ,val period: 2003-01-31 - 2005-01-31 , Test period 2005-01-31 - 2006-01-31 # train records 80867 ,# val records 35622 , # test records 21590\n",
      "Train period: 1999-01-31 - 2004-01-31 ,val period: 2004-01-31 - 2006-01-31 , Test period 2006-01-31 - 2007-01-31 # train records 82560 ,# val records 39570 , # test records 23521\n",
      "Train period: 2000-01-31 - 2005-01-31 ,val period: 2005-01-31 - 2007-01-31 , Test period 2007-01-31 - 2008-01-31 # train records 85693 ,# val records 45111 , # test records 24470\n",
      "Train period: 2001-01-31 - 2006-01-31 ,val period: 2006-01-31 - 2008-01-31 , Test period 2008-01-31 - 2009-01-31 # train records 88894 ,# val records 47991 , # test records 21949\n",
      "Train period: 2002-01-31 - 2007-01-31 ,val period: 2007-01-31 - 2009-01-31 , Test period 2009-01-31 - 2010-01-31 # train records 96182 ,# val records 46419 , # test records 16767\n",
      "Train period: 2003-01-31 - 2008-01-31 ,val period: 2008-01-31 - 2010-01-31 , Test period 2010-01-31 - 2011-01-31 # train records 105203 ,# val records 38716 , # test records 18170\n",
      "Train period: 2004-01-31 - 2009-01-31 ,val period: 2009-01-31 - 2011-01-31 , Test period 2011-01-31 - 2012-01-31 # train records 109510 ,# val records 34937 , # test records 21578\n",
      "Train period: 2005-01-31 - 2010-01-31 ,val period: 2010-01-31 - 2012-01-31 , Test period 2012-01-31 - 2013-01-31 # train records 108297 ,# val records 39748 , # test records 21516\n",
      "Train period: 2006-01-31 - 2011-01-31 ,val period: 2011-01-31 - 2013-01-31 , Test period 2013-01-31 - 2014-01-31 # train records 104877 ,# val records 43094 , # test records 23877\n",
      "Train period: 2007-01-31 - 2012-01-31 ,val period: 2012-01-31 - 2014-01-31 , Test period 2014-01-31 - 2015-01-31 # train records 102934 ,# val records 45393 , # test records 28640\n",
      "Train period: 2008-01-31 - 2013-01-31 ,val period: 2013-01-31 - 2015-01-31 , Test period 2015-01-31 - 2016-01-31 # train records 99980 ,# val records 52517 , # test records 26461\n",
      "Train period: 2009-01-31 - 2014-01-31 ,val period: 2014-01-31 - 2016-01-31 , Test period 2016-01-31 - 2017-01-31 # train records 101908 ,# val records 55101 , # test records 23187\n",
      "Train period: 2010-01-31 - 2015-01-31 ,val period: 2015-01-31 - 2017-01-31 , Test period 2017-01-31 - 2018-01-31 # train records 113781 ,# val records 49648 , # test records 27102\n",
      "Train period: 2011-01-31 - 2016-01-31 ,val period: 2016-01-31 - 2018-01-31 , Test period 2018-01-31 - 2019-01-31 # train records 122072 ,# val records 50289 , # test records 28421\n",
      "Train period: 2012-01-31 - 2017-01-31 ,val period: 2017-01-31 - 2019-01-31 , Test period 2019-01-31 - 2020-01-31 # train records 123681 ,# val records 55523 , # test records 27271\n",
      "Train period: 2013-01-31 - 2018-01-31 ,val period: 2018-01-31 - 2020-01-31 , Test period 2020-01-31 - 2021-01-31 # train records 129267 ,# val records 55692 , # test records 29168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\drebi\\miniconda3\\envs\\statclass\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017733963551429643"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'sic2', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions = []\n",
    "y_test_list =[]\n",
    "dates = []\n",
    "dic_r2_all = {}\n",
    "\n",
    "learning = np.linspace(start=0.01, stop=0.001, num=20)\n",
    "mse = np.full((len(learning),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    model = MLPRegressor(learning_rate_init=0.00001, hidden_layer_sizes=32, activation='relu',\n",
    "                            batch_size=250, early_stopping=True, n_iter_no_change=10, random_state=42)\n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    predictions.append(preds)\n",
    "    dates.append(y_test.index)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    dic_r2_all[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_full= np.concatenate(predictions, axis=0)\n",
    "y_test_list_all_full= np.concatenate(y_test_list, axis=0) \n",
    "dates_all_full= np.concatenate(dates, axis=0)\n",
    "\n",
    "# R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "# print(\"R2OOS Linear Regression: \", R2FULL)\n",
    "R2FULL = r2_score(y_test_list_all_full, predictions_all_full)\n",
    "R2FULL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'sic2', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df_large[features]\n",
    "y = df_large[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions_top = []\n",
    "y_test_list_top =[]\n",
    "dates_top = []\n",
    "dic_r2_top = {}\n",
    "\n",
    "learning = np.linspace(start=0.01, stop=0.001, num=20)\n",
    "mse = np.full((len(learning),1),np.nan, dtype = np.float32)\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    model = MLPRegressor(learning_rate_init=0.00001, hidden_layer_sizes=32, activation='relu',\n",
    "                             early_stopping=True, n_iter_no_change=10, random_state=42)\n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    predictions_top.append(preds)\n",
    "    dates_top.append(y_test.index)\n",
    "    y_test_list_top.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    dic_r2_top[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_top = np.concatenate(predictions_top, axis=0)\n",
    "y_test_list_all_top= np.concatenate(y_test_list_top, axis=0) \n",
    "dates_all_top= np.concatenate(dates_top, axis=0)\n",
    "\n",
    "# R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "# print(\"R2OOS Linear Regression: \", R2FULL)\n",
    "R2TOP = r2_score(y_test_list_all_top, predictions_all_top)\n",
    "R2TOP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tscv = TimeBasedCV(train_period=60,\n",
    "                   val_period=24,\n",
    "                   test_period=12,\n",
    "                   freq='months')\n",
    "\n",
    "features = df.columns[~df.columns.isin(['permno', 'permno2', 'mvel12', 'sic2', 'DATE2', 'risk_premium'])].tolist()\n",
    "\n",
    "X = df[features]\n",
    "y = df[['risk_premium']]\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "\n",
    "#Empty containers to save results from each window\n",
    "predictions_bottom = []\n",
    "y_test_list_bottom =[]\n",
    "dates_bottom = []\n",
    "dic_r2_bottom = {}\n",
    "\n",
    "for train_index, val_index, test_index in tscv.split(X, first_split_date= datetime.date(1981,1,31), second_split_date= datetime.date(1991,1,31)):\n",
    "\n",
    "    X_train   = X.loc[train_index].drop('DATE', axis=1)\n",
    "    y_train = y.loc[train_index]\n",
    "    \n",
    "    X_val   = X.loc[val_index].drop('DATE', axis=1)\n",
    "    y_val = y.loc[val_index]\n",
    "\n",
    "    X_test    = X.loc[test_index].drop('DATE', axis=1)\n",
    "    y_test  = y.loc[test_index]\n",
    "\n",
    "    model = MLPRegressor(learning_rate_init=0.00001, hidden_layer_sizes=32, activation='relu',\n",
    "                            batch_size=250, early_stopping=True, n_iter_no_change=10, random_state=42)\n",
    "    model.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    predictions_bottom.append(preds)\n",
    "    dates_bottom.append(y_test.index)\n",
    "    y_test_list_bottom.append(y_test)\n",
    "\n",
    "    r2 = 1-np.sum(pow(y_test['risk_premium']-preds,2))/np.sum(pow(y_test['risk_premium'],2))\n",
    "    dic_r2_top[\"r2.\" + str(y_test.index)] = r2\n",
    "\n",
    "predictions_all_bottom = np.concatenate(predictions_bottom, axis=0)\n",
    "y_test_list_all_bottom= np.concatenate(y_test_list_bottom, axis=0) \n",
    "dates_all_bottom= np.concatenate(dates_bottom, axis=0)\n",
    "\n",
    "# R2FULL = 1-np.sum(pow(y_test_list_all_full-predictions_all_full,2))/np.sum(pow(y_test_list_all_full,2))\n",
    "# print(\"R2OOS Linear Regression: \", R2FULL)\n",
    "R2BOTTOM = r2_score(y_test_list_bottom, predictions_all_bottom)\n",
    "R2BOTTOM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R2TOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m chart \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[R2FULL],\n\u001b[1;32m----> 2\u001b[0m                   [R2TOP],\n\u001b[0;32m      3\u001b[0m                   [R2BOTTOM]])\n\u001b[0;32m      5\u001b[0m NN1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(chart, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENet Regression\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m                      index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull Sample\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLarge Firms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmall Firms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m NN1\n",
      "\u001b[1;31mNameError\u001b[0m: name 'R2TOP' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "chart = np.array([[R2FULL],\n",
    "                  [R2TOP],\n",
    "                  [R2BOTTOM]])\n",
    "\n",
    "NN1 = pd.DataFrame(chart, columns=['ENet Regression'],\n",
    "                     index=['Full Sample', 'Large Firms', 'Small Firms'])\n",
    "\n",
    "NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN1.to_csv(r'r2_NN1_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = predictions_all_full.tolist()\n",
    "y_true = y_test_list_all_full.tolist()\n",
    "i = dates_all_full.tolist()\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {'identifier': i,\n",
    "     'yhat': yhat,\n",
    "     'y_true': y_true\n",
    "    })\n",
    "\n",
    "\n",
    "results[\"identifier\"]= results[\"identifier\"].astype(\"str\")\n",
    "results[\"date\"] = results[\"identifier\"].str[12:22]\n",
    "results[\"id\"] = results[\"identifier\"].str[35:40]\n",
    "results.drop([\"identifier\"],axis = 1, inplace=True)\n",
    "results['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n",
    "results['MonthYear'] = results['date'].dt.to_period('M')\n",
    "results = results.sort_values(by = ['date', 'id'], ascending = True)\n",
    "results = results.set_index(['MonthYear','id'])\n",
    "results.head()\n",
    "nnet = results.reset_index()\n",
    "nnet.to_csv('predictions/nnet.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results['y_true'] = results['y_true'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df[['mvel12', 'macro_tbl', 'macro_svar']].copy()\n",
    "data.reset_index(inplace=True)\n",
    "data['permno2'] = data['permno2'].astype('str')\n",
    "data['MonthYear'] = data['DATE2'].dt.to_period('M')\n",
    "data.drop('DATE2', axis=1, inplace=True)\n",
    "data.rename(columns={'permno2': 'id'}, inplace=True)\n",
    "data.rename(columns={'mvel12': 'market_cap'}, inplace=True)\n",
    "data.rename(columns={'macro_tbl': 'risk_free_rate'}, inplace=True)\n",
    "data = data.set_index(['MonthYear','id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = pd.merge(results, data,left_index=True, right_index=True)\n",
    "bigdata.reset_index(inplace=True)\n",
    "bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata['returns'] = bigdata['y_true'] + bigdata['risk_free_rate']\n",
    "bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata['MonthYear1'] = bigdata['MonthYear'].copy()\n",
    "bigdata['MonthYear'] = bigdata['MonthYear'].astype('int64')\n",
    "bigdata['NumMonth'] = bigdata['MonthYear'] - 179\n",
    "bigdata['NumMonth'].unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
